# 데이터베이스(DB)
1. 데이터베이스 환경
- 데이터 : 현실 세계로부터 단순한 관찰이나 측정을 통해 수집된 사실이나 값
- 정보 : 어떤 상황에 대한 적절한 결정을 할 수 있게 하는 지식으로 데이터의 유효한 해석이나 데이터 상호간의 관계
- 정보가 유용성을 갖기 위해서 정확성과 현재성을 가지고 있어야함
  -> 정확성과 현재성을 갖기 위해서는 데이터가 정확하고 현재의 것이어야함
- 정보시스템 : 한 조직체의 활동에 필요한 데이터를 수집, 조직, 저장해 두었다 필요시 처리해 의사 결정에 유효한 정보를 생성해 분배하는 수단
  - 목적 : 현재의 정확한 정보를 적시에 제공하여 조직체로 하여 유용한 의사 결정을 하도록 하는 것
- 데이터 웨어하우스 : 다양한 소스의 데이터를 별도로 추출해 관리하는 것
- 데이터 마이닝 : 데이터 웨어하우스 규모가 대형화되고 복잡하게 될 때 관련된 데이터를 찾아내고 필요한 정보, 지식을 생성하는 과정

- 일괄 처리 시스템
  - 유사한 트랜잭션을 한데 모아 일정 시간에 한꺼번에 처리하여 사용자의 요구를 만족시키고 시스템 효율성을 높이는데 목적이 있음
  - 트랜잭션 : 논리적 작업 단위로 하나의 단위로 처리되어야 하는 분리될 수 없는 연산 그룹
  - 장점 : 각 트랜잭션 당 처리 비용이 적게 들게 되고 시스템 성능을 높일 수 있다
  - 단점 : 대기 시간이 길어지고 사전작업을 거쳐야함
- 온라인 처리 시스템
  - 곧바로 데이터를 처리하는 방식
  - 대기시간이 없어 사용자는 편리 -> 사용자 중심 처리 방식
  - 응답시간을 최소화 해야함 -> 시스템을 계속 가동 상태 유지하고 이는 작업 당 처리 비용을 높게 만듦
  - 테스트, 유지보수가 어렵게되고 회복도 매우 복잡
  - 시스템 오보헤드로 연결되어 시스템 성능 저하의 직접적 원인
- 분산 처리 시스템
  - 지리적으로 분산되어 있는 처리기와 데이터베이스를 네트워크로 연결시켜 사용자는 마치 하나의 시스템을 사용하는 것처럼 데이터 처리해주는 시스템
  - 분산 데이터베이스 : 지리적으로 분산 저장되어 있는 형태의 데이터베이스
  - 신속한 조치, 지역 업무에 대한 책임 구분, 모듈식 구축의 용이, 다원적 재편성을 통한 신뢰성 증대 등 이점이 있음
  
- 데이터 베이스 : 어느 한 조직의 여러 응용 시스템이 공용할 수 있도록 통합, 저장된 운영 데이터 집합
  - 통합 데이터 : 원칙적으로 중복되어 있지 않음
  - 저장 데이터 : 컴퓨터가 접근 할 수 있는 저장 매체에 저장된 데이터
  - 운영 데이터 : 기능을 수행하기 위해 반드시 유지해야 할 데이터
  - 공용 데이터 : 여러 응용 시스템들이 공동으로 소유, 이용하는 공용 데이터, 서로 다른 목적으로 데이터베이스의 데이터를 공동으로 이용한다는 것
  - 데이터베이스 특성
    - 실시간 접근성 : 응답 시간은 단 몇 초를 넘지 않아야 함
    - 계속적인 변환 : 변화 속에서 현재의 정확한 데이터를 유지해야함
    - 동시 공용 : 여러 사용자가 동시에 원하는 데이터에 접근하여 이용할 수 있어야함
    - 내용에 의한 참조 : 사용자가 요구하는 데이터의 내용, 데이터가 가지는 값에 따라 참조
  - 개체 : 데이터베이스에서 표현하려고 하는 유형, 무형의 객체로 서로 구별되는 것
    - 하나 이상이 속성(애트리뷰트)으로 구성되고 각 속성은 개체의 특성이나 상태를 기술
    - 속성은 이름을 가진 데이터의 가장 논리적 단위
    - 개체 인스턴스 : 개체를 구성하고 있는 속성들이 어떤 구체적인 값을 가진 상태 -> 인스턴스 집합을 개체 집합이라함
  - 관계
    - 속성 관계 : 어느 한 개체를 기술하는 속성들 간의 관계(개체 내 관계)
    - 개체 관계 : 개체 집합과 개체 집합 사이의 관계(개체 간 관계)
  - 데이터베이스 구조 
    - 논리적 구조 : 사용자가 생각하는 데이터의 논리적 표현 (일반 사용자나 응용 프로그래머의 입장에서 보는 구조, 가상적인 구조)
    - 논리적 구조에서 취급하는 데이터 레코드 -> 논리적 레코드
    - 물리적 구조 : 저장 장치 위에 물리적으로 저장 되어 있는 데이터의 실제 구조
    - 물리적 구조에서 취급하는 데이터 레코드 -> 저장 레코드

2. 데이터베이스 관리 시스템
- 데이터 종속성 : 응용 프로그램과 데이터 간의 상호 의존 관계, 데이터 구성 방법이나 접근 방법을 변 경시 자연히 이것을 기초로 한 응요 프로그램도 같이 변경해야 하는 데 이것을 데이터 종속성이라 함
- 데이터 중복성 : 한 시스템 내에 내용이 같은 데이터가 중복되게 저장 관리 되는 것
  - 데이터 중복성으로 인해 야기되는 문제점
    - 데이터 일관성 : 동일성을 유지하기 어렵고 데이터 간 불일치 발생
    - 보안성 : 같은 내용의 데이터에 대해 같은 수준의 데이터 보안이 유지 되어야함
    - 경제성 : 중복 시 추가적으로 필요한 저장 공간에 대한 비용이 더 들게 됨
    - 무결성 : 중복 시 제어가 분산되게 되어 데이터의 정확성 유지가 어려움
- 데이터베이스 관리 시스템(DBMS) : 응용 프로그램과 데이터의 중재자로 모든 응용 프로그램들이 데이터베이스를 공용할 수 있게 관리해주는 SW 시스템
  - DBMS 필수 기능
    - 정의 기능 : 다양한 응용 프로그램과 데이터베이스가 서로 인터페이스 할 수 있는 방법 제공
      - DB의 논리적 구조와 특성이 DBMS가 지원하는 데이터 모델에 맞게 기술되어야함
      - DB를 물리적 저장 장치에 저장하기 위한 데이터의 물리적 구조의 명세도 포함되어야함
      - 데이터의 논리적 구조와 물리적 구조 사이에 상호 변환이 가능하도록 구조 사이의 사상을 명세해야함
    - 조작 기능 : 사용자와 인터페이스 사이의 인터페이스를 위한 수단 제공
      - 모든 사용자에게 사용하기 쉽고 자연스러워야 함
      - 명확하게 명세할 수 있어야하고,  합법적인 범위내에서 완전히 명세할 수 있어야함
      - 효율적이어야 함
    - 제어 기능 : DB의 내용에 대해 항상 정확성과 안정성을 유지할 수 있는 데이터 제어 기능을 가져야함
      - 데이터의 무결성이 파괴되지 않도록 제어할 수 있어야함
      - 권한 검사하고 보안을 유지할 수 있어야 함
      - 여러 사용자가 동시에 접근해 처리하더라도 DB와 처리결과는 항상 정확성이 유지되도록 병행 제어 기능을 가져야함
  - DBMS의 장점 
    - 데이터 중복 최소화 / 데이터 공용 / 데이터 일관성 유지 / 데이터 무결성 유지 / 데이터 보안 보장 / 표준화 / 전체 데이터 요구의 조정
  - DBMS 단점
    - 운영비 증대 / 특정 응용 프로그램의 복잡화 / 복잡한 백업과 회복 / 시스템 취약성 
  - 데이터 독립성 : 논리적 구조나 물리적 구조가 변경 되더라도 응요 프로그램이 영향 받지 않도록 제공해야함
    - 논리적 데이터 독립성 : DBMS가 DB의 논리적 구조를 변경하더라도 기존 응용 프로그램들에 아무런 영향을 주지 않는 것
    - 물리적 데이터 독립성 : 기존 응용 프로그램, 논리적 구조에 아무런 영향을 주지 않고 DBMS이 DB의 물리적 구조를 변경할 수 있는 것

3. 데이터베이스 시스템의 구성
- 1) 3단계 데이터 베이스

    ![ex_screenshot](/res/db1.png)
    
  - 스키마 : DB 구조와 제약조건에 대한 명세를 기술 한 것(개체, 관계, 제약 조건, 속성에 대한 정의 포함)
  - 외부 스키마(외부 단계)
    - 데이터베이스의 개인 사용자나 응용 프로그래머가 접근하는 데이터베이스를 정의한 것
    - 데이터베이스 전체의 한 논리적 부분이 되는 것이기에 서브 스키마라고도 함
    - 하나의 데이터베이스 시스템은 여러 외부 스키마가 존재
  - 개념 스키마
    - 범 기관적 입자에서 데이터베이스를 정의한 것
    - 응용 시스템들이나 사용자들이 필요로 하는 데이터를 통합한 조직 전체의 데이터베이스를 기술한 것
  - 내부 스키마
    - 저장 장치의 입장에서 데이터베이스 전체가 저장되는 방법을 명세한 것
    - 개념 스키마에 대한 저장 구조를 정의한 것
  - 외부/개념 사상
    - 특정 외부 스키마와 개념 스키마간의 대응 관계 정의 (응용 인터페이스) -> 논리적 데이터 독립성 제공
  - 개념/내부 사상
    - 개념 스키마와 내부 스키마간의 대응 관계 정의(저장 인터페이스) -> 개체의 각 속성이 내부 필드와 어떻게 대응 되는가를 정의 -> 물리적 데이터 독립성 제공
  - 시스템 카탈로그 : 데이터베이스에 저장되어 있는 모든 데이터 개체들에 대한 정의나 명세에 관한 정보를 유지하는 시스템
  - 데이터 디렉토리 : 데이터베이스에 수록된 데이터로 접근하는 데 필요한 위치 정보를 관리하는 시스템
  -> 두 개다 시스템 데이터베이스이지만, 시스템 카탈로그는 사용자가 접근해 검색 가능하지만 데이터 디렉토리는 시스템만 접근 가능
  
- 2) DBMS
  - 사용자의 데이터베이스 사이에 위치해 데이터베이스를 관리하고 사용자가 요구하는 연산을 수행해 정보를 생성해주는 소프트웨어
  
    ![ex_screenshot](/res/dbms.png)
    
    - DDL 컴파일러 : DDL로 명세된 스키마 정의를 내부 형태로 변환해 시스템 카탈로그에 저장
    - 질의어 처리기 : 사용자가 제출한 고급 질의문 처리(질의문 팡싱하고 분석해 컴파일)
    - DML 예비 컴파일러 : 응용 프로그램 속에 삽입된 DML 명령문들을 추출하고 그 자리에 함수 호출문 삽입
    - DML 컴파일러 : DML 명령문을 파싱하고 컴파일하여 효율적인 목적 코드 생성
    - 런타임 데이터베이스 처리기 : 실행 시간에 데이터베이스 접근을 관리함
    - 트랜잭션 관리자 : 무결성 제약조건이 만족하는지 검사, 권한 검사, 병행제어, 회복 작업 수행
    - 저장 데이터 관리자 : 디스크에 저장된 사용자가 데이터베이스나 시스템 카탈로그 접근을 책임 
    
- 3) 데이터 언어
  - 데이터 정의어 : 데이터베이스를 정의하거나 정의를 수정할 목적으로 사용하는 언어
    - 기술된 데이터 스키마는 DDL 컴파일러가 컴파일하여 시스템 카탈로그에 저장해 놓고 필요한 경우 시스템이 활용
  - 데이터 조작어 : 사용자가 DBMS로 하여금 원하는 데이터를 처리하게끔 명세하는 도구로 사용자와 DBMS 간 인터페이스 제공
    - 절차적 데이터 조작어 : 사용자가 모슨 데이터를 원하고 어떻게 접근해야 하는지 명세해야되는 저급 데이터 언어
      - 한번에 하나의 레코드를 검색해 호스트 언어와 함께 처리 -> 응용 프로그램 속에 삽입되어 사용됨
    - 비 절차적 데이터 조작어 : 사용자가 무슨 데이터를 원하는지만 명세하고 어떻게 접근해 처리할지는 명세할 필요 없이 DBMS에 위임하는 고급 데이터 언어 
      - 선언적 언어라고하며 한번에 여러 개의 레코드를 검색해 처리함
  - 데이터 제어어 : 데이터 제어에 관해 정의하고 기술하는 언어
    - 데이터 보안, 무결성, 회복, 병행 수행 제어를 명세할 수 있는 명령어 포함
  - 데이터 언어의 완정성 : 사용자가 원하는 데이터베이스의 어떤 객체도 추출하고 처리할 수 있어며 어떤 연산도 표현할 수 있는 데이터 언어의 능력

4. 관계 데이터베이스
- 1) 관계 데이터 모델

  ![ex_screenshot](/res/db2.png)
  
  - 테이블의 열은 속성(Attribute), 행은 튜플(tuple)
  - 데이터의 가장 작은 논리적 단위는 Attribute 값 -> 원자값만 허용
  - 하나의 Attribute가 취할 수 있는 같은 타입의 모든 원자 값들의 집합을 Attribute의 Domain이라 함
  - 각 Attribute는 어는 한 Domain으로부터만 값을 취할 수 있음
- 2) Relation(릴레이션)
  - Relation Schema는 이름과 Attribute 집합으로 구성되어 있음
  - Relation Schema는 한 릴레이션의 논리적 구조를 정의한 것
  - 관계 데이터 베이스 스키마는 한 관계 데이터베이스의 논리적 구조를 정의한 것, 하나 이상의 릴레이션 스키마가 포함 된다
  - 릴레이션, 데이터베이스 인스턴스는 동적 성질을 가지고 릴레이션, 데이터베이스 스키마는 정적 성질을 가짐
  - 카티션 프로덕트를 기술하는 도메인 순서는 결과에 영향을 주기에 중요함
  - 릴레이션 정의에 사용된 도메인 개수를 차수, 투플의 수를 카디널리티라 함
- 3) 릴레이션의 특성 
  - 투플의 유일성
  - 투플의 무순서성 
  - 애트리뷰트의 무순서성
  - 애트리뷰트의 원자성 
  - 널 값도 관계 데이터 모델에서는 원자 값으로 취급
- 4) 관계 데이터베이스 개념
  - 관계 데이터베이스 스키마는 릴레이션 스키마 집합과 무결성 제약 조건으로 구성
  - 관계 데이터베이스 인스턴스는 관계 데이터베이스 스키마에 정의된 릴레이션 인스턴스들의 집합
- 5) 데이터베이스 키 
  - 투플을 유일하게 식별할 수 있는 애트리뷰트 집합을 릴레이션의 키라고 함
  - 유일성 : 릴레이션에 있는 모든 투플에 대해 값이 상이하고 유일하다
  - 최소성 : 유일성을 가진 k가 둘 이상의 애트리뷰트로 구성되어 있을 때 어느 한 애튜리뷰트라도 제외하는 경우 유일성이 깨진다
    - k는 모든 투플을 유일하게 식별하는 뎅 필요한 애트리뷰트들로만 구성
    
  - 슈퍼키 : 유일성만 만족하고 최소성을 만족하지 못한 경우
  - 기본키 : 투플을 식별하기 위한 도구로 db 설계자가 지정한 하나의 후보키 -> 널 값을 가질 수 없다
  - 대체키 : 기본키로 지정되지 않은 나머지 후보키들
  - 외래키 : 릴레이션 R에 속한 어떤 애트리뷰트 집합 FK가 있을 때 FK 값은 반드시 어떤 릴레이션 S의 기본키 값이어야 할 때 FK를 릴레이션 R의 외래키라 함 ( R을 참조 릴레이션, S를 피참조 릴레이션)
    - 외래키와 기본키의 도메인은 같아야함
- 6) 무결성 제약
  - 무결성 종류 
    - 널 무결성 : 릴레이션 특정속성 값이 NULL이 될 수 없도록 하는 규정
    - 고유 무결성 : 릴레이션의 특정 속성에 대해 각 튜플이 갖는 값들이 서로 달라야하는 규정
    - 참조 무결성 : 외래키 값은 NULL이거나 참조 릴레이션의 기본 키 값과 동일해야 한다는 규정
    - 도메인 무결성 : 특정 속성 값이 그 속성이 정의된 도메인에 속한 값이어야 한다는 규정
    - 키 무결성 : 하나의 테이블에는 적어도 하나의 키가 존재해야 한다는 규정
  - 널 값
    - 알려지지 않은(모르는 값)
    - 값이 있지만 아직 모름
    - 해당 없음 등
    - 이러한 이유로 정보 부재를 명시적으로 표시하기 위해 사용하는 특수 데이터 값
  - 개체 무결성 제약 : 기본 키에 속해 있는 애트리뷰트는 널 값을 가질 수 없음
  - 참조 무결성 제약 : 참조할 수 없는 외래 키 값을 가져서는 안된다는 것을 의미
    - 널이 아니면서 참조된 릴레이션의 어떤 기본 키값과도 일치하지 않는 값을 의미

5. 관계 대수와 관계 해석
- 1) 관계 대수 : 원하는 목표 데이터를 얻기 위해 어떻게 해야 되는지 일련의 연산을 순서대로 명세해야 하는 절차 언어
  
  ![ex_screenshot](/res/db3.png)
  - 일반 집합 연산자     
    - 합집합 : 차수는 r or s의 차수, 카디널리티는 r+s 보다 크지 않아야함
    - 교집합 : 차수는 r or s의 차수, 카디널리티는 r과 s의 카디널리티보다 크지 않음
    - 차집합 : 차수는 r or s의 차수, 카디널리티는 r의 카디널리티보다 크지 않음
    - 카티션 프로덕트 : 차수는 r+s, 카디널린티는 r*s
    - 합,교,차 집합은 합병 가능해야함 ( 합병 가능은 두 릴레이션의 차수가 같고 대응 애트리뷰트별로 도메인이 같음)
    - 합/교집합, 카티션 프로덕트는 결합적이고 교환적
  - 순수 관계 연산자 
    - 실렉트 : 수평적 부분 집합
    - 프로젝트 : 수직적 부분 집합
    - 조인 
      - ⍬로 표현될 수 있는 조인을 세타조인
      - ⍬가 =인 동일 조인
      - 동일 조인 결과에서 중복 애트리뷰트 제거하는 연산을 자연 조인
    - 디비전 : s의 모든 투플에 연관된 r의 투플을 선택
    - 개명 연산 
  - 기본 연산과 복합 연산 
    - 기본 연산 : 합, 차집합, 카티션 프로덕트, 실렉트, 프로젝트
    - 복합 연산 : 조인, 교집합, 디비전
  - 관계 대수 확장
    - 세미 조인 : s와 자연조인에 참여할 수 있는 r의 투플만 선택하는 것을 의미
    - 외부 조인 : 조인 상대 릴레이션에 대응되는 투플이 없을 경우 이를 제외않고 상대를 널 투플로 만들어 결과 릴레이션에 포함하는 연산
    - 외부 합집합 : 완전하게 합병 가능하지 않은 두 릴레이션을 합집합으로 만드는 것
      - 확장 애트리뷰트에 해당되는 값이 없는 경우 널 값으로 채움
    - 집계 연산 : SUM, AVG, MAX, MIN, COUNT 등이 있고 특별히 지정한 애트리뷰트 값에 따라 투플들을 그룹 짓게하는 GROUP이 있음
    
- 2) 관계 해석 : 원하는 정보가 무엇이라는 것만 선언하는 비절차적 언어
  - 투플 관계 해석
  - 도메인 관계 해석

6. SQL
- 1) SQL 데이터 정의문 
  - 스키마와 카탈로그 
    - SQL 스키마 : 스키마 이름을 식별되고 허가권자와 스키마의 각 요소에 대한 기술자 포함
      - 테이블, 뷰, 도메인, 기타 허가권이나 무결성 등에 관한 요소 포함
      - CREATE SCHEMA UNIVERSITY AUTHORIZATION SHLEE; -> 이름이 UNIVERSITY이고 허가권자가 SHLEE인 스키마 생성
    - 카탈로그 : 한 SQL 시스템 내의 스키마들의 집합 
      - 각 카탈로그는 반드시 INFORMATION_SCHEMA라는 스키마를 포함하며 카탈로그에 포함된 모든 스키마들의 정보와 스키마들의 모든 요소들에 대한 정보를 제공하기 위한 것
  - 도메인 정의문   
    - SQL이 지원하는 데이터 타입으로만 정의
		
    - CREATE DOMAIN 도메인_이름 데이타 타입
             [기정_값_정의]                
								=> DEFAULT 값 OR NULL											
             [도메인_제약조건_정의리스트]   
								=> 무결성 제약 조건, CONSTRAINT, CHECK로 명세
											
    - EX) CREATE DOMAIN DEPT CHAR(4)
                 DEFAULT '???'
                 CONSTRAINT VALID_DEPT
                 CHECK( VALUE INT
                   ('COMP', 'ME', 'EE','ARCH','???'));
									 
    - ALTER DOMAIN 으로 변경 가능 -> 도메인 수정
    - DROP DOMAIN 도메인_이름 옵션; -> 도메인 삭제
      - 옵션 RESTRICT : 이 도메인을 참조하고 있는 것이 없을 때만 삭제
      - CASCADE : 도메인을 참조하고 있는 뷰나 제약조건도 함께 삭제되지만 참조 열은 삭제되지 않고 다른 형태의 타입으로 변경
  - 기본 테이블 생성
    - 기본 테이블 : CREATE TABLE로 만들어지는 테이블로 독자적으로 존재하는 테이블
    - 가상 테이블 : CREATE VIEW로 만들어지는 테이블로 독자적 존재 불가, 기본 테이블로 유도되어 만들어 지는 테이블
    - 임시 테이블 : 질의문 처리 과정의 중간 결과로 만들어 지는 테이블
    - CREATE TABLE SQL문
    
    	     CREATE TABLE 기본 테이블
             ({열_이름 데이타 타입 [NOT NULL] [DEFAULT 값],}+   
			=> [] 생략 가능, {} 중복 가능 '+'는 1번 이상, * 는 0번 이상								
             [PRIMARY KEY(열_이름_리스트),]                   
			=> 기본키 명세, 개체 무결성 정의								
             {[UNIQUE (열_이름_리스트).]}                    
			=> 대체키(후보키 명세)							
             {[FOREIGN KEY(열_이름_리스트)
                  REFERENCES 기본테이블[(열_이름_리스트)]
                  [ON DELETE 옵션]
                  [ON UPDATE 옵션],]}*
                  [CONSTRAINT 이름] [CHECK(조건식)]);          
			=> 외래키로 참조 무결성 유지
			   옵션 NO ACTION, CASCADE, SET NULL, SET DEFAULT
			   CHECK절은 행 갱신, 삽입 시 유지되어야 할 무결성 제약 조건
											
    - 예제
    	CREATE TABLE ENROL(Sno INT NOT NULL,
         		Cno CHAR(6) NOT NULL,
         		Grade INT,
         PRIMARY KEY(Sno, Cno),
         FOREIGN KEY(Sno) REFERENCES STUDENT(Sno)
                ON DELETE CASCADE
                ON UPDATE CASCADE,
         FOGEIGN KEY(Cno) RREFERENCES COURSE 
                ON DELETE CASCADE
                ON UPDATE CASCADE,
         CHECK(Grade>=0 AND Grade<=100));
         
  - 기본 테이블 제거와 변경 
    - DROP TABLE COURSE CASCADE;
      - CASCADE : 참조하는 다른 뷰 정의, 제약조거너이 있으면 함께 자동 삭제
      - RESTRICT : 다른 뷰 정의에서나 조약조건에서 참조되고 있는 경우 실행되지 않음
			
    - DROP SCHEMA UNIVERSITY CASCADE;
      - CASCADE : 스키마뿐 아니라 연관 객체들 모두 삭제
      - RESTRICT : 스키마가 공백인 경우에만 삭제
			
    - ALTER TABLE ENROL ADD Final CHAR DEFAULT 'F';
    - ALTER TABLE ENROL ALTER Grade SET DEFAULT '0'; -> 기정 값 변경
    - DROP CONSTRAINT 이름 -> 제약 조건 삭제
		
- 2) SQL 데이타 조작문
  - 데이타 갬색
    - SELECT [ALL|DISTINCT] 열_리스트
      FROM 테이블_리스트
      [WHERE 조건]
      [GROUP BY 열_리스트]
      [HAVING 조건]
      [ORDER BY 열_리스트] ASC|DESC]];
    
    - SELECT Sno AS 학번, '중간시험 =' AS 시험, Midtern+3 AS 점수
      FROM ENROL
      WHERE Cno='c312';
      
      SELECT S.Sname, S.Dept, E.Grade
      FROM STUDENT S, ENROL E
      WHERE S.Sno = E.Sno and E.Cno = 'C413';
      
    - 조인 조건의 3가지 형식
      - 테이블1 JOIN 테이블2 ON 조건식
      - 테이블1 JOIN 테이블2 USING(열_리스트)
      - 테이블1 NATURAL JOIN 테이블2
    
      - SELECT Sname, Dept, Grde
        1)FROM STUDNET JOIN ENROL ON(STUDENT.Sno = ENROL.Sno)
        2)FROM STUDNET JOIN ENROL USING(Sno)
        3)FROM STUDNET NATURAL JOIN ENROL
        WHERE ENROL.Cno ='C413;
				
    - GROUP BY 이용 검색 
      - SELECT Cno, AVG(Final) AS 기말평균
        FROM ENROL
        GROUP BY Cno                       
					=> GROUP BY 절에 명세된 열의 값에 따라 그룹으로 분할 
					
        HAVING COUNT(*)>=3         
					=> 각 그룹의 구성 요건 명세 
				
    - Subquery 사용 검색
      - SELECT Sname 
        FROM STUDENT 
        WHERE Sno IN (SELECT Sno FROM ENROL WHERE Cno =’C413’);
      - SELECT Sname 
        FROM STUDENT 
        WHERE Sno NOT IN (SELECT Sno FROM ENROL WHERE Cno =’C413’);
      - SELECT Sname, Dept 
        FROM STUDENT 
        WHERE Dept = (SELECT Dept FROM STUDENT WHERE Sname =’정기태‘); 
				
    - Like 사용 검색
      - SELECT Cno, Cname 
        FROM COURSE
        WHERE Cno LIKE ‘C%’;
      - LIKE 프레디킷은 서브 스트링 패턴을 비교하는 비교 연산자 
        - %는 서브 스트링 패턴을 명세 
        - C% -> C로 시작, S__ -> S로 시작 세문자 스트링, LIKE '$S$' -> S포함 스트링
				
    - NULL 사용 검색
      - SELECT Sno, Sname
        FROM STUDENT
        WHERE Dept IS NULL;
				
    - EXISTS 사용 검색
      - SELECT Sname
        FROM STUDENT
        WHERE EXISTS(NOT EXIST도 가능) 
          (SELECT * 
           FROM ENROL
           WHERE Sno = STUDENT.Sno AND Cno = ‘C413’);
					 
  - 데이타 갱신 
    - UPDATE 테이블 
      SET {열_이름 = 산술식}`+
      [WHERE 조건];
			
    - UPDATE ENORL
      SET Final = Final + 5
      WHERE Sno IN (SELECT Sno 
                    FROM STUDENT
                    WHERE Dept = ‘컴퓨터’);
										
  - 데이터 삽입
    - INSERT
      INTO 테이블[(열_이름_리스트)]
      VALUES (열_값_리스트);
			
    - INSERT
      INTO 테이블[(열_이름_리스트)]
      SELECT문;
			
    - INSERT
      INTO STUDENT(Sno, Sname, Year, Dept)
      VALUE(600, ‘박상철’, 1, ‘컴퓨터’);
			
    - INSERT
      INTO COMPUTER(Sno, Sname, Year)
        SELECT Sno, Sname, Year
        FROM STUDENT
        WHERE Dept= ‘컴퓨터’;
				
  - 데이터 삭제
    - DELETE
      FROM 테이블
      [WHERE 조건];
			=> WHERE 절 없으면 투플이 모두 삭제 된 빈 테이블이 됨.
			
    - DELETE
      FROM STUDENT
      WHERE Sno = 100; 
			
    - DELETE
      FROM ENROL; 
			=> 빈 테이블이 됨.
			
    - DELETE
      FROM ENROL
      WHERE Cno = ‘C413’ AND Final <60 AND ENROL.Sno IN 
                                                     (SELECT Sno 
                                                      FROM STUDENT 
                                                      WHERE Dept = ‘컴퓨터’);
  
- 3) SQL 뷰
  - 뷰는 다른 테이블로부터 유도된 이름을 가진 가상 테이블
  - 뷰 정의만 시스템 내에 저장해 두었다가 필요시 실행 시간에 테이블을 구축
  - ALTER문 을 이용한 변경 불가
  - 뷰 생성 
    - CREATE VIEW 뷰_이름[(열_이름_리스트)] 
          AS SELECT문                       
        [WITH CHECK OPTION];                
					=> 뷰에 대한 갱신, 삽입 연산 시 뷰 정의 조건 위반 시 실행 거부 되는 제약 조건
					
			=> AS SELECT문에 UNION, ORDER BY 사용 불가
			
    - CREATE VIEW CSTUDENT 
          AS SELECT Sno, Sname, Year 
             FROM STUDENT 
             WHERE Dept = ‘컴퓨터’ WITH CHECK OPTION;
    - CREATE VIEW HONOR(Sname, Dept, Grade)
          AS SELECT STUDENT.Sname, STUDENT.Dept, ENROL.Final      
             FROM STUDENT, ENROL 
             WHERE STUDENT.Sno = ENROL.Sno AND ERNOL.Final >90;  
  - 뷰 제거 
    - DROP VIEW 뷰_이름 {RESTRICT | CASCADE};
      - RESTRICT -> 다른곳에 참조되고 있지 않는 한 데이터베이스에서 제거되어 없어진다.
      - CASCADE -> 해당 뷰 뿐만 아니라 뷰가 사용된 다른 모든 뷰나 제약 조건이 함께 제거
   
  - 뷰의 조작 연산
    - 뷰는 검색문을 사용할 수 있으나 삽입, 삭제, 갱신문에는 제한이 있다
    - 기본키를 포함하지 않는 뷰일 경우 삽입 불가
    - 둘 이상의 테이블로 동일 조인으로 정의되었다면 갱신 시 많은 문제점 발생 가능
    - 통계요약을 위해 정의된 경우에 변경 연산은 많은 문제점을 야기 할 수 있다
    
    - 변경이 허용되지 않는 경우
      - 뷰의 열이 상수, 산술연산자, 함수가 사용된 산술 식으로 만들어지면 변경 불가
      - 집계함수가 관련되어 정의된 뷰는 변경 불가
      - DISTINCT, GROUP BY, HAVING이 사용되어 정의된 뷰는 변경 불가
      - 두 개 이상의 테이블이 관련되어 정의된 뷰는 변경 불가
      - 변경할 수 없는 뷰를 기초로 정의된 뷰는 변경 불가 
  - 뷰의 장단점
    - 데이터의 논리적 독립성을 어느 정도 제공할 수 있다.
    - 데이터의 접근을 제어함으로써 보안을 제공할 수 있다.
    - 사용자의 데이터 관리를 간단하고 쉽게 해준다.
    - 여러 사용자의 상이한 응용이나 요구를 지원해 줄 수 있다.
    - 뷰의 정의를 변경할 수 없다.
    - 삽입, 삭제, 갱신 연산에 많은 제한을 가지고 있다. 
    
- 4) 삽입 SQL
  - 응용 프로그램 특징 
    - 삽입 SQL문은 명령문 앞에 ‘EXEC SQL’을 붙여 다른 호스트 언어의 명령문과 쉽게 구별, 끝에는 세미콜론과 같은 특별한 종료 심벌을 붙여 표시
    - 삽입 SQL 실행문은 호스트 언어의 실행문이 사용되는 곳이면 어디나 나타날 수 있고 실행문, 비 실행문이 있는데 DECLARE CURSOR, BEGIN, END, DECLARE SECTION은 비실행문이다.
    - 삽입 SQL문은 호스트 변수를 포함 할 수 있고 다른 SQL 필드 이름과 구별하기위해 콜론을 앞에 붙인다. 호스트 변수는 검색 결과를 저장하는 장소를 나타내기 위해 INTO 절에 나타날 수 있다.
    - SQL문에서 사용할 호스트 변수는 사용전 반드시 삽입 SQL 선언부인 BEGIN/END DECLARE SECTION속에서 선언되어야 한다. 여러개 있어도 무방하다
    - SQLSTATE라는 스트링 타입의 호스트 변수를 포함한다. 실행 상태 표시가 SQLSTATE 변수를 통해 프로그램에 전달된다.
      - 변수 값이 “00000” -> 성공적으로 실행, “02000” -> 실행 했지만 아무런 데이터도 검색하지 못함을 의미
    - 삽입 SQL문의 호스트 변수의 데이터 타입은 이에 대응하는 데이터베이스 필드의 SQL 데이터 타입과 일치해야한다. 
    - 호스트 변수와 데이터베이스 필드 이름은 같아도 된다.
    - SQL문 실행 후 SQLSTATE 변수에 반환된 값을 검사해야한다.
      - EXEC SQL WHENEVER <조건> <행동>;
      - 조건은 SQLERROR이거나 NOT FOUND, 행동은 CONTINUE, GOTO문
  - 커서 
    - SQL 레코드 집합 단위 처리와 호스트 언어의 개별 레코드 단위 처리 사이에 어떤 교량 시설
    - 응용 프로그램의 삽입 SQL에만 사용되는 새로운 객체, 레코드 집합을 처리하는 데 사용되는 일종의 포인터
  - 커서가 필요 없는 데이터 조작
    - 단일 레코드 검색
      - EXEC SQL SELECT Sname, Dept 
             INTO :sname, :dept 
             FROM STUDENT
             WHERE Sno = :sno;
    - 갱신 
      - EXEC SQL UPDATE ENROL
                 SET Final = Final + :new 
                 WHERE Cno = ‘C413’; 
    - 삭제
      - EXEC SQL DELETE
                 FROM ENROL
                 WHERE SNO = :sno
    - 삽입		
			- EXEC SQL INSERT
                 INTO STUDENT(Sno, Sname, Dept)
                 VALUES(:sno, :sname, :dept); 
		                 
  - 커서를 이용하는 데이터 조작
  
    - EXEC SQL DECLARE C1 CURSOR FOR 
    	=> 커서 C1 정의, 커서를 FOR 뒤의 SELECT 문과 연결				
               SELECT Sno, Sname, Year 
 	             FROM STUDENT
               WHERE DEPT= :dept;
	       		=> 커서가 OPEN 될 때 실행							
      EXEC SQL OPEN C1;                     
      	=> C1으로 접근되는 모든 레코드에 대해 질의문 실행									
              DO                
	      	EXEC SQL FETCH C1 INTO :sno, :sname, :year; .....
               		=>  활동 세트 내의 다음레코드를 지시하게 하고 레코드의 필드 값을 호스트 변수들에 각각 저장 								
              END
      EXEC SQL CLOSE C1;
      	=> 커서 C1 활동 종료 
      
    - EXEC SQL UPDATE SUTDENT
               SET Year = :year
               WHERE CURRENT OF C1;  
				=> 현재 가리키고 있는 레코드의 Year 값을 호스트변수가 가진 값으로 변경
    - EXEC SQL DELETE
  	       FROM STUDENT
	       WHERE CURRENT OF C1;
				=> 현재 가리키고 있는 레코드를 삭제 
		
  - 다이내믹 SQL
    - 온라인 응용을 실행 시간에 구성할 수 있는 삽입 SQL			
		
    	```sql		
			varchar dynamicSQL[256]; ( 문자 스트링 변수로 SQL문을 저장함 )
			dynamicSQL = “DELETE FROM ENROL 
    	              WHERE Cno = ‘C413’ AND Final <= 60”;
			EXEC SQL PREPARE objSQL FROM :dynamicSQL;
			(dynamicSQL에 저장된 SQL문 예비컴파일 후 바인드 해 목적 코드 생성해 objSQL에 저장 )
			EXEC SQL EXECUTE objSQL;                         		
			(objSQL에 자장된 목적 코드의 SQL문을 실행)			
			```
			
      - PREPARE문과 EXECUTE문을 하나의 IMMEDIATE문으로 표현 가능
        - EXEC SQL EXECUTE IMMEDIATE :dynamicSQL;
        
      - 스트링으로 표현되는 SQL문에는 호스트 변수를 포함 시킬 수 없음							
			```sql
      		dynamicSQL = “DELETE FROM ENROL WHERE Cno = ? AND Final <= ?”;
        	EXEC SQL PREPARE objSQL FROM :dynamicSQL;
	          	  	cno = “C413”; 
		            	grade= 60;
					( ?인 값들인 터미널로부터 입력 받을 수 있음)
	    	EXEC SQL EXECUTE objSQL USING :cno, :grade;
				( ?를 가진 매개변수가 포함된 명령문 실행 시 USING절을 가진 EXECUTE 문에 이자 값을 명세 )
			```
			
7. 데이터 종속성과 정규화
- 데이터베이스 설계에서 중요한 사항 : 현실 세계를 가장 정확하게 표현할 수 있는 데이터의 논리적 구조를 결정하는 것
- 고려사항
	- 애트리뷰트들 사이 존재하는 관계성 (데이타 종속성)
	- 효율적인 데이타 처리
	- 데이터의 일관성 유지
- 데이터 논리적 표현
	- 삭제 이상 : 한 투플을 삭제함으로써 유지해야 될 정보까지 삭제되는 연쇄 삭제 현상이 일어나게 되어 정보 손실이 발생하게 되는 현상
		- 삭제해야하는 정보가 기본 키의 일부 값이라 투플 전체를 삭제하는 경우
	- 삽입 이상 : 데이터 삽입 시 불필요하고 원하지 않는 데이터도 함께 삽입해야만 되고 그러지 않으면 삽입되지 않은 현상
	- 갱신 이상 : 중복된 투플들 중 일부 투플의 애트리뷰트 값만을 갱신시킴으로써 정보의 모순성이 생기는 현상
- 이러한 이상이 생기는 이유
	- 여러 가지 상이한 종류의 정보를 하나의 릴레이션으로 표현하려 하기 때문에 발생
	- 애트리뷰트 간 존재하는 여러 데이터 종속 관계를 무리하게 하나의 릴레이션으로 표현하려는 데서 발생하게 된 것
	-> 정규화 과정을 통해 하나의 릴레이션에 하나의 종속성이 표현되도록 분해하는 것으로 해결
	
- 스키마 변환 : 만들어진 릴레이션들 보다 바람직한 형태의 릴레이션들로 다시 변환하는 것
	- 정보 표현의 무손실 : 변환 시 정보 손실이 있어서 안됨
	- 최소의 데이타 중복성
	- 분리의 원칙 : 하나의 독립된 관계성은 별도 릴레이션으로 분리시켜 표현

- 함수 종속 : 어떤 릴레이션 R에서 X,Y를 각각 R의 애트리뷰트 집합의 부분집합이라 할 때 애트리뷰트 X의 값 각각에 대해 시관과 관계없이 항상 애트리뷰트 Y값이 오직 하나만 연관되었을 때 Y를 X에 함수종속 이라함
	- 기본 키라면 릴레이션 R의 모든 애트리뷰트 Y는 반드시 X에 함수 종속이어야 한다
	- X->Y 관계에서 X를 결정자, Y를 종속자라 함
	
	![ex_screenshot](/res/db4.png)
	- {학번, 과목번호} -> 성적
		- 성적 애트리뷰트는 학번, 과목번호 애트리뷰트에 완전 함수 종속
	- {학번} -> {학년} 
		- 학년 애트리뷰트는 학번 애트리뷰트에 완전 함수 종속이지만 학번, 과목번호 애트리뷰트에는 부분 함수 종속
	- 완전 함수 종속 : 릴레이션 R의 어던 애트리뷰트 Y가 다른 애트리뷰트 X에 함수 종속이며 X의 진부분 집합에는 함수 종속이 아닐 때 Y는 X에 완전 함수 종속 
		- 결정자가 두 개 이상의 애트리뷰트로 구성된 경우 완전 함수 종속 문제가 발생할 수 있음
		
- 기본 정규형 
- 제1 정규형 : 어떤 릴레이션 R에 속한 모든 도메인이 원자값만으로 되어 있다면 제1 정규형에 속한다

	![ex_screenshot](/res/db5.png)
	- 지도교수와 학과 애트리뷰트 값들에 불필요하게 많은 데이타의 중복을 포함하고 있어 문제를 야기 시키고 있음
	- 키가 아닌 애트리뷰트들이 기본 키에 완전 함수 종속되지 못하고 부분 함수 종속이 되어 있기에 발생
	
	![ex_screenshot](/res/db6.jpg)
	
- 제2 정규형 : 어떤 릴레이션 R이 제1 정규형이고 키에 속하지 않은 애트리뷰트 모두가 기본 키에 완전 함수 종속이면 제2 정규형에 속한다
	- 학과는 학번에 완전 함수 종속이면서 지도교수를 통해 이행적 함수 종속 되고 있어 이상이 발생할 수 있다
	- 두 개의 상이한 정보를 하나의 릴레이션으로 혼합해 표현하려고 하는 데서 발생
	- 이행적 함수 종속을 제거해 두 개의 릴레이션으로 분해하여 해결
	
	![ex_screenshot](/res/db7.png)
	
- 제3 정규형 : 어떤 릴레이션 R이 2정규형이고 기본 키에 속하지 않은 모든 애트리뷰트들이 기본 키에 이행적 함수 종속이 아닐 때 제3 정규형에 속한다
	- 복수의 후보키를 가지고 있고 후보 키들이 두개 이상의 애트리뷰트로 구성되고 후보 키의 애트리뷰트가 서로 중첩되는 경우 적용할 수 없다
	- BCNF에 속하는 릴레이션은 모두 제3 정규형에 속하지만 역은 성립하지 않음
- 보이스/코드 정규형 : 릴레이션 R의 결정자가 모두 후보키이면 릴레이션 R은 보이스/코드 정규형에 속한다
	
	![ex_screenshot](/res/db8.png)

- 제4 정규형 : 릴레이션 R에 다치 종속을 만족하는 애트리뷰트 부분 집합 A,B가 존재할 때 R의 모든 애트리뷰트들이 A에 함수 종속(R의 모든 애트리뷰트 X에 대해 A->X이고 A가 후부키)이면 R은 제4 정규형에 속한다
	- 다치 종속 : A,B,C를 릴레이션 R의 애트리뷰트 부분집합이라 할 때 애트리뷰트 쌍 (A,C)-값에 대응되는 B-값의 집합이 A-값에만 종속되고 C-값에는 독립이면 B는 A에 다치종속이라 하고 A->>B로 표기
	- 애트리뷰트 값 하나를 경정하는 것이 아니라 몇 개의 값, 집합을 결정한다는 의미
	- R(A,B,C)에서 A->>B가 성립하면 A->>C도 동시 성립 (A->>B|C)
	
- 제5 정규형 : 릴레이션 R에 존재하는 모든 조인 종속이 릴레이션 R의 후부키를 통해서만 만족된다면 R은 제 5정규형 or PI/NF에 속한다
	- 조인 종속 : 어떤 릴레이션 R의 애트리뷰트에 대한 n개의 부분집합이 있을 때 이 릴레이션 R이 프로젝션을 모두 조인한 결과와 똑같게 된다면 R은 조인 종속을 만족
	- 릴레이션 R(A,B,C)가 조인 종속 *(AB,AC)를 만족하기만 하면 릴레이션 R은 두개의 다치종속 A->>B|C를 만족
	- 다치 종속은 조인 종속의 한 특수한 경우
	
- 정규형 간 관계

	![ex_screenshot](/res/db9.png)

8. 데이터 모델링
- 데이터 모델 : 컴퓨터에 저장할 데이터의 구조를 논리적으로 표현하기 위해 사용하는 지능적 도구

	![ex_screenshot](/res/db11.png)
	
	![ex_screenshot](/res/db10.png)
	- 개념적 모델링 : 현실 세계에 대한 인식을 추상적 개념으로 표현하는 과정, 개념적 모델링으로부터 얻은 결과를 개념적 구조라 함
	- 데이터 모델링 : 레코드 타입을 기초로 한 논리적 개념을 이용해 어떤 논리적 구조, 즉 데이터 모델로 표현하는 것이 필요한데 이 변환 과정을 데이터 모델링이라 함
	- 데이터 구조화 : 논리적 데이터 구조가 결정되면 컴퓨터가 접근할 수 있는 저장 장치 위에 데이터가 표현될 수 있도록 물리적 데이터 구조로 변환하는 과정 

- 데이터 모델 개념
	- 개념적 데이터 모델 : 속성들로 기술된 개체 타입과 개체 타입들 간 관계를 이용해 현실 세계를 표현하는 방법
	- 논리적 데이터 모델 : 데이터 필드로 기술된 레코드 타입과 레코드 타입 간 관계를 이용해 현실 세계 표현하는 방법
- 데이터 모델은 데이터 구조, 연산, 제약조건에 대해 명세를 기술한 것
	- 구조 : 데이터베이스에 표현될 대상으로 개체타입과 관계를 명세한 것, 데이터베이스의 정적 성질
	- 연산 : 데이터베이스에 표현된 개체 인스턴스를 처리하는 작업에 대한 명세, 데이터베이스의 동적 성질
	- 제약조건 : 데이터베이스에 허용될 수 있는 개체 인스턴스에 대한 논리적 제약을 명세한 것
		- 구조적 제약과 의미상 제약이 모두 포함
- 개체 타입 : 이름과 애트리뷰트로 정의되고 애트리뷰트들은 개체의 특성을 기술
	- 개체 집합 : 특정 개체타입에 대한 인스턴스들의 집합
		- 공통 애트리뷰트들을 갖지만 각 애트리뷰트에 대해 자신의 값을 가진
	- 단순 애트리뷰트 : 더 이상 작은 구성요소로 분해할 수 없는 애트리뷰트
	- 복합 애트리뷰트 : 몇 개의 기본적인 단순 애트리뷰트로 분해할 수 있는 애트리뷰트
	- 단일 값 애트리뷰트 : 특정 개체에 대해 하나의 값을 갖는 애트리뷰트
	- 다중 값 애트리뷰트 : 어느 한 개체에 대해 몇 개의 값을 가지는 애트리뷰트
	- 유도 애트리뷰트 : 다른 관련된 애트립류트나 개체가 가지고 있는 값으로부터 유도되어 결정되는 애트리뷰트
	- 저장 애트리뷰트
	- 널 애트리뷰트 : 어떤 개체 인스턴스가 특정 애트리뷰트에 대한 값을 가지고 있지 않을 때 명시적으로 표시하기 위해 사용
		- 해당 되지 않는 경우, 알수 없는 경우, 누락된 경우, 모르는 경우 등..
- 관계 타입 : 개체 타입의 모든 인스턴스들, 개체 집합들 사이의 대응, 사상을 말함
	- 개체 타입과 개체 타입 간 성립할 수 있는 관계
	- 관계 집합은 개체 집합과 개체 집합 간에 실제로 나타나 있는 관계 인스턴스
	- 유형 : 1:1 / 1:N / N:1 / N:M
	- 특성
		- 개체 집합 A와 B 사이에 정의된 A-B 관계에서 개체 집합 A의 모든 개체가 A-B 관계에 참여해야 된다면 개체 집합 A-B 관계에서 전체 참여, 일부 개체만 참여해도 되면 부분 참여라 함
		- 어떤 개체 b의 존재가 개체 a의 존재에 달려 있다면 b는 a에 존재 종속이라 하며 a를 주개체, b를 종속 개체라 함

- E-R 모델 
	- 개체 집합 내에서 각 개체들이 서로 상이한 값만을 갖는 애트리뷰트가 있어야 한다 -> 키 애트리뷰트
	- 키는 각 개체 인스턴스를 유일하게 식별하는 데 사용
	- 약한 개체 타입 : 자기 자신의 애트리뷰트만으로 키를 명세할 수 없는 개체 타입
	- 강한 개체 타입 : 자신의 애트리뷰트로 구성된 키를 가진 개체 타입
	- 강한, 약한 개체 타입은 주 개체와 종속 개체 간의 존재 종속과 관련
	- 강한 개체 타입이 주 개체, 약한 개체 타입 개체가 종속 개체가 된다
	- 약한 개체 타입에 키가 없더라도 강한 개체가 지정되면 연관된 약한 개체를 식별할 수 있지만 약한 개체 집합 내에 개체를 서로 구별할 수 있는 방법이 필요함
		- 약한 개체 타입의 구별자는 강한 개체가 주어졌을 때 연관된 약한 개체들을 서로 구별할 수 있게 하는 애트리뷰트이며 부분키라고도 함
		
	- 다이어그램 표기법
	
	![ex_screenshot](/res/db12.jpg)
		
- 논리적 데이터 모델 
	- 관계 데이터 모델 : 데이터 베이스를 구성하는 개체, 관계 모두 테이블로 표현된다는 특성을 가짐
		- 개체, 관계에 대한 릴레이션을 명세한 릴레이션 스키마 
		
	![ex_screenshot](/res/db13.png)
	
	- 네트워크 데이터 모델 : 데이터 구조도 형태가 네트워크, 그래프라는 의미
		- 일대다 관계에 연관된 두 레크드 타입을 오너, 멤버라고 함 (오너-멤버 관계)
	- 계층 데이터 모델 : 데이터 구조도가 트리 형태 인 것
		- 루트 레코드 타입을 가지고 타입 간 하나의 관계만 허용
		- 사이클이 허용되지 않으며 레코드 타입 간 상하위 레벨 관계가 성립
		- 일대다 관계를 맺는 레코드 타입을 부모, 자식 레코드 타입이라 함(부모-자식 관계)
		
9. 데이터베이스 설계
- 데이터베이스 설계 환경
- 데이터베이스 생명 주기
	![ex_screenshot](/res/db14.png)
	
	- 요구조건 분석 단계 : 데이터베이스에 저장할 데이터 범위를 정의하기 위해 사용자와 응용을 식별하고 필요로 하는 요구 사항을 분석하는 것
	- 설계 단계 : 개념적 설계에서 시작해 논리적 설계를 거쳐 목표 DBMS에 구현할 수 있는 물리적 설계까지 모두 포함
		- 사용자의 요구조건에서 데이터베이스 구조를 도출해 내는 과정
		- 데이터베이스의 논리적 물리적 구조를 어떻게 설계하느냐 하는 것이 근본적 문제
		- 데이터베이스 설계 5 단계
		![ex_screenshot](/res/db15.png)
			- 요구 조건 분석 : 데이터 및 처리 요구 조건
			- 개념적 설계 : DBMS 독립적 개념 스키마 설계, 트랜잭션 모델링
			- 논리적 설계 : DBMS에 맞는 스키마 설계, 트랜잭션 인터페이스 설계
			- 물리적 설계 : DBMS에 맞는 물리적 구조 설계, 트랜잭션 세부 설계
			- 구현 : DBMS DDL로 스키마 작성, 트랜잭션(응용 프로그램) 작성
		- 데이터베이스 설계는 데이터베이스의 내용과 구조 설계와 데이터의 처리와 응용 소프트웨어 설계에 관한 활동으로 병행 수행
			- 데이터베이스 내용과 구조에 치중한 설계 -> 데이터 중심 데이터베이스 설계
			- 데이터의 처리와 응용에 치중한 설계 -> 처리 중심 데이터베시으 설계
	- 구현 단계 : 데이터베이스 스키마 정의, 파일 생성, 응용 소프트퉤어를 목표 DBMS 환경에 맞도록 구현
	- 운영 단계 : 데이터베이스 시스템과 응용 시스템을 실제로 운영하고 관리해 사용자 요구에 따라 서비스 제공
	- 감시 및 개선 단계 : 시스템 운영 과정에서 발생하는 새로운 요구조건이나 응용에 대처하고 부문별 시스템 활용도의 변동에 따라 저하될 지 모르는 성능 향상
	- 데이터 베이스 설계 고려사항
		- 데이터베이스 무결성
			- 일관성 : 저장된 두 데이타 값 사이나 특정 질의 응답들에 모순성이 없이 일치해야 함
			- 회복 : 장애 발생 직전의 일관된 데이터베이스 상태로 복구하는 것
			- 보안 : 의도적이거나 우연을 불문하고 불법적 데이터 변경이나 손실 OR 노출에 대한 보호 (접근제어와 밀접!!)
			- 효율성 : 응답 시간 단축, 저장 공간 최적화, 시스템 생산성 등
			- 데이터베이스 확장 : 시스템 운영에 영향 주지 않으며 새로운 데이타를 계속적으로 추가해 나갈 수 있는 기법이 있어야 함
			
- 요구조건 분석
	- 사용자의 요구조건을 수집하고 분석해 공식적인 요구조건 명세를 생성하는 것
		- 정적 정보 구조에 대한 요구 조건 : 개체, 애트리뷰트, 관계, 제약 조건 등
	 	- 동적 데이터베이스 처리 요구조건 : 트랜잭션 유형, 트랜잭션 실행 빈도 등
	 	- 범 기관적 제약 조건
	- 정보의 내용과 처리 요구 조건 수집	
		- 기능, 데이터 종류, 데이터 용도, 처리 형태, 데이터 흐름, 제약조건 및 요구조건 정보 수집
		- 트랜잭션에 대한 입출력 데이터 식별
		- 설문지, 인터뷰, 회의를 통해 문서화 ( 주요 관리자와 이용자의 의견을 빠뜨리면 안됨 )
- 개념적 설계
	- 개념적 스키마 모델링(데이터 중심 설계)과 트랜잭션 모델링(처리 중심 설계)을 병행적으로 수행
	- 개념적 스키마 모델링
		- 요구조건 분석 결과를 E-R 다이어그램 같은 개념적 데이타 모델, 즉 DBMS에 독립적이고 고차원적 표현 기법으로 기술하는 것
		- 표현 결과를 개념적 구조 OR 개념적 스키마 라고 함
		- 스키마의 구성 요소가 되는 개체 타입, 애트리뷰트, 관계성을 식별해 결ㄹ정해야 함
		- 요구 조건 분석 결과로부터 개념적 스키마를 유도하는 기본 원리는 추상화
			- 집단화 : 여러 애트리뷰트들을 그룹지어 하나의 개체로 만드는 것
			- 일반화 : 공통 성질을 가진 여러 부류의 개체들을 일반적이고 포괄적 개체로 만드는 것
	- 개념적 스키마 설계 방법
		- 뷰 통합 방법(하향식 방법)
			- 요구조건 분석 단계에서 식별된 응용, 사용자 그룹을 기초로 각 부문별 뷰를 식별하고 모델링
				- 개체를 식별하고 각 개체에 대해 키 애트리뷰트를 결정
				- 관계성 식별하고 명세하고 개체의 특성을 표현하는 설명 애트리뷰트 첨가
			- 완성된 부문별 뷰들을 하나로 통합해 전체 개념 스키마 작성
				- 집단화, 일반화 개념 이용 
		- 애트리뷰트 합성 방법 ( 상향식 방법 )
			- 작업과 데이터 관계에 기초하고 있음
			- 애트리뷰트들을 먼저 식별하고 분류
				- 애트리뷰트는 유일성 가진 애트리뷰트와 아닌 것으로 분류
			- 분류 완료 후 개체를 정의하고 키 애트리뷰트, 설명 애트리뷰트로 구성
			- 관계성 식별후 정의 
				- 개체 간 관계성, 개체와 애트리뷰트 관계성, 애트리뷰트들 간 관계성을 식별해 정의
			- E-R 다이어그램을 ㅗ전체 개념 스키마를 다이어그램 형태로 표현해 정보 구조 생성
			- 정보 구조를 분석 확인
				- 각 개체가 의존하는 것, 관계의 카디널리티, 각 개체의 종속 정보 등을 검사 확인, 누락 정보나 잘못 표현된 관계성 검사 등
	- 트랜잭션 모델링
		- 요구조건 분석 결과로 식별된 응용을 검토해 구현해야 될 트랜잭션을 고차원 명세로 정의
		- 트랜잭션을 식별하고 이들에 대한 기능적 특성을 데이터베이스 설계 단계 초기에 명세해 놓는 것
		- 트랜잭션의 입출력과 기능적 행태만 주로 정의
			- 입,출력 데이타와 내부적 제어 흐름을 명세함으로 트랜잭션을 개념적이고 시스템 독립적으로 정의
		- 검색, 갱신, 검색과 갱신 혼합 트랜잭션으로 구분
		- 모두 병행적으로 수행해 스키마와 트랜잭션 관계가 완전히 식별되고 명세될 때까지 피드백을 통해 정재해야 한다
- 논리적 설계
	- 논리적 데이터 모델로 변환
		- 개념적 스키마를 목표 DBMS에 맞는 스키마, 논리적 데이터 모델로 변환하는 과정을 데이터 모델링이라 함
		- 생성된 결과는 DBMS의 DLL로 기술된스키마
	- 트랜잭션 인터페이스 설계
		- 입출력과 기능적 행태로만 정의된 응용프로그램 즉, 트랜잭션 인터페이스를 설계
		- 트랜잭션의 전체적 골격을 개발하고 인터페이스를 정의
	- 스키마 평가 및 정제
		- 설계된 스키마를 정량적 정보, 성능 평가 기준에 따라 평가
		- 정략적 정보 : 데이터 양, 처리 빈도스, 처리 작업량 등
		- 성능 평가 기준 : 논리적 레코드 접근, 데이터 전송량, 데이터베이스 크기 등
- 물리적 설계
	- 논리적 스키마로부터 효율적인 내부 스키마를 설계하는 것
	- 논리적 데이터 모델롭루터 효율적이고 구현 가능한 물리적 데이터베이스 구조를 생성하는 것
	- 트랜잭션의 상세 설계를 병행
	- 데이터베이스가 실제 저장 장치에 구현되고 접근 되는 것은 물리족 구조 여하에 달려 있다 -> 하드웨어와 운영 체제의 특성을 고려 해야함
	- 물리적 데이터베이스 기본적 단위는 저장 레코드
	- 저장 레코드 양식 설계
		- 저장 레코드 양식은 데이타 타입, 데이터 값의 분포, 사용될 응용, 접근 빈도 등을 고려해 결정
		- 데이터 표현과 압축에 대한 양식 포함
	- 레코드 집중의 분석 및 설계 
		- 물리적으로 집중 저장되도록 할당함으로써 물리적 순차성을 이용할 수 있도록 해야함
		- 연속된 저장 공간에 할당하는 것, 효율적 검색을 위한 블록 크기 선정이 중요 -> 레코드의 크기와 물리적 저장 장치 특성에 의존
		- 데이터 레코드의 순차 처리가 주이면 큰 블록이 유리, 임의 접근 처리가 주이면 작은 블록 사용이 유리
	- 접근 경로 설계
		- 물리적 저장 장치 위에 저장된 데이타의 접근과 처리를 가능하게 하는 절차
		- 저장 구조와 탐색 기법이 기본 요소
			- 저장 구조는 인덱스를 통합 접근 방법과 저장 레코드를 정의하는 것
			- 탐색 기법은 주어진 응용을 위해 취해야 될 적절한 접근 경로를 정의하는 것
		- 접근 경로 설계(기본 접근 경로 / 보조 접근 경로)
			- 기본 접근 경로 : 기본 키를 기초로 기본 인덱스를 이용
				- 초기 레코드 적재, 레코드 물리적 위치, 기본키를 통한 검색 등과 밀접
			- 보조 접근 경로 : 보조키를 기초로 한 보조 인덱스를 통해 접근
				- 보조 인덱스를 통하면 접근 시간을 줄일 수 있으나 인덱스를 위한 저장공간, 인덱스 관리 오버헤드가 뒤따름
	- 물리적 설계 고려 사항
		- 응답 시간 : 트랜잭션이 참조하는 데이타에 대한 데이터베이스 접근 시간과 운영체제 스케줄링과 통신 지연에 영향을 받음
		- 저장 공간의 효율화 : 저장 하기위해 최소환의 저장 공간을 사용하느 것
		- 트랜잭션 처리도 : 단위 시간에 데이터베이스 시스템이 처리할 수 있는 평균 트랜잭션 수를 처리도 -> 시스템 부학가 절정을 이루는 시간대를 고려
		- 레코드 확장이나 레코드 수 증가에 따른 화일 확장 평가도 고려 대상
- 데이터베이스 구현
	- 목표 DBMS의 DLL로 기술된 명령문 컴파일하고 실행하여 데이터베이스 스키마와 공백 데이터베이스 파일 생성
	- 데이터베이스에 데이타를 적재
	- 트랜잭션은 응용 프로그래머에 의해 실행 트랜잭션으로 구현
		- 트랜잭션의 개념적 명세 검토하고 삽입 DML 명령문을 가진 프로그램 코드가 작성되어 검사됨
	- 트랜잭션 작성 후 시리제 데이타가 적재되면 설계 및 구현이 끝나고 운영 데이터베이스가 ㅗ안성

- 데이터베이스 설계 과정

	![ex_screenshot](/res/db16.png)
	![ex_screenshot](/res/db16_2.png)
		

10. 데이터베이스의 저장과 접근
- 데이터베이스의 저장
	- 물리적으로 직접 접근 저장 장치, 디스크에 대부분 저장
	- 트랙 : 디스크 원반에 여러 개 동심원, 여기에 데이터를 저장
	- 실린더 : 디스크 팩에 있는 트랙들 가운데 지름이 같은 트랙을 총칭하는 말
	- 판독/기록 헤드 : 디스크에 저장된 데이타를 실제로 판독하고 기록하는 물리적 장치
	- 탐구 시간 : 헤드가 판독이나 기록할 데이터가 있는 트랙까지 이동하는데 걸리는 시간
	- 회전 지연 시간 : 트랙에서 원하는 레코드가 회전해 헤드 밑까지 오기를 기다리는 시간
	- 접근 시간 : 헤드가 임의 장소에서 원하는 트랙에 있는 레코드를 찾아 메인 메모리의 버퍼로 데이터를 전송하는데 걸리는 시간
		- 탐구 시간, 회전 지연 시간, 실제 데이터 전송 시간 포함
	- 성능 개선 초점은 디스크 접근 횟수를 최소화 하는 것
	- 저장 구조는 디스크에 배치되어 저장되는 형태이다
	- 데이터베이스에 적절한 저장 방식을 선정하는 과정 -> 데이터 베이스의 물리적 설계

- 데이터베이스 접근
	
	![ex_screenshot](/res/db17.png)
	
	- 페이지는 블록으로서 입출력 단위가 된다
		- 디스크와 메인 메모리 사이 한 번의 디스크 접근으로 데이터가 전송되는 양
		- 보통 1KB, 2KB, 4KB 크기의 페이지
		
	- 디스크 관리자
		- 운영체제의 한 구성요소로 모든 물리적 입출력 연산에 대해 책임을 지고 있다
		- 반드시 물리적 디스크 주소에 대해 알고 있어야 함
		- 파일 관리자는 디스크를 단순히 일정한 크기의 페이지로 구성된 페이지 세트들으리 논리적 집합으로 취급
			- 페이지 세트는 유일한 페이지 세트 ID로 식별
			- 각 페이지는 디스크 내에서 유일한 페이지 번호로 식별
		- 디스크 관리자는 페이지 번호를 물리적 디스크 주소로 변환하는사상을 수행
		- 디스크의 페이지들은 서로 중첩되지 않은 페이지 세트로 분할
			- 페이지 세트 중에는 하나의 커다란 자유 공간 페이지 세트가 있음 -> 예비 페이지 기능 수행
			- 페이지 세트에 대한 페이지 할당과 회수는 디스크 관리자가 수행
				- 페이지 세트에서 페이지 검색, 교체, 첨가, 제거 등
	- 파일 관리자
		- DBMS가 디스크에 저장된 저장 데이터베이스를 저장 파일들의 집합으로 취급할 수 있도록 지원
		- 저장 파일은 한 레코드 타입의 저장 레코드 어커런스들의 집합을 말함
		- DBMS는 페이지 세트의 존재와 두 저장 파일이 같은 페이지 세트에 저장되어 있는지, 어떤 두 저장 레코드가 같은 페이지에 저장되어 있는지를 알아야함
		- 각 저장 파일은 화일 ID로 식별
			- 이 파일을 포함하고 있는 페이지 세트 내에서 유일해야 한다
		- 각 저장 레코드도 레코드 id로 식별되며 저장 파일 내에서 유일하다
		- 레코드 id는 파일뿐만 아니라 전체 디스크 내에서 유일하다
			- 레코드 ID는 페이지 번호와 페이지 내 유일한 값인 오프셋(슬롯 번호)으로 구성
		- DBMS가 파일 관리자에게 명령할 수 있는 연산
			- 저장 파일에서 저장 레코드 검색, 대체, 제거, 첨가(새로운 RID 반환)
			- 저장 파일 생성 / 제거

- 페이지 세트와 파일
	- 디스크 관리자 주요 기능 : 파일 관리자가 물리적 디스크 입출력이 아니라 논리적 페이지 입출력으로 데이터를 관리할 수 있게 지원하는 것
	
	![ex_screenshot](/res/db18.png)
	![ex_screenshot](/res/db19.png)
	- 한 페이지 세트 내에서 페이지의 논리적 순서는 포인터를 이용해 표현 할 수 밖에 없음
	- 각 페이지는 페이지 헤드를 갖게 하여 모든 제어 정보를 저장
		- 논리적 순서에 의한 다음 페이지의 물리적 디스크 주소가 포함
		- 페이지 헤드에 있는 다음 페이지 포인터는 디스크 관리자가 관리
	- 디스크 디렉터리(페이지 세트 디렉터리)에는 현재 디스크에 있는 모든 페이지 세트 리스트와 각 페이지 세트의 첫 번째 페이지에 대한 포인터가 저장되어 있음
	- 디스크 관리자는 파일 관리자로 하여 논리적 페이지로만 동작할 수 있도록 지원, 파일 관리자는 DBMS로 하여 저장 파일과 저장 레코드만으로 동작하게 한다 -> 저장 레코드 관리
	
	- 페이지와 페이지 사이의 논리적 순서는 페이지 관리에서 설명한 대로 해당 페이지 세트 내의 다음 페이지 번호로 유지한다
	
	![ex_screenshot](/res/db20.png)
	- 저장 레코드는 내부적으로 RID로 식별
		- r이 저장 되어 있는 페이지의 페이지 번호 p
		- 페이지 처음부터 몇 번째 바이트에 레코드 r이 실제 저장되어 있다는 것을 나타내는 오프셋(슬롯 번호)
			- 페이지 밑에서부터 할당된슬롯을 가리키는데 레코드 r이 페이지 p의 시작에서 몇 번째 바이트에 저장되었는가를 나타내는ㄴ 바이트 값
		- 이 두 부분으로 구성 
		- 레코드가 한 페이지안에서 RID 변경 없이 해당 슬롯의 내용만 변경해주면 되는 이점이 있음
	- 저장 레코드는 사용자 데이터 필드, 시스템 제어 정보를 포함하고 있으며 레코드의 접두부에 저
	- DBMS는 주어진 레코드의 내부 구조를 알고 있지만 파일 관리자은 파일을 기본적으로 단순히 바이트 스트링이라고만 알고 있음
	
- 파일 조직 방법
	- 파일 조직은 파일의 레코드들을 물리적 저장 장치에 저장시키기 위한 배치 방법, 데이터베이스의 물리적 저장 방법
	- 레코드의 저장과 접근 방법을 결정해 주기 때문에 매우 중요!
	
	![ex_screenshot](/res/db21.jpg)
	- 순차 방법 : 레코드들의 물리적 순서가 그 레코드들의 논리적 순서와 같게 순차적으로 저장하는 방법
		- 엔트리 순차파일 : 레코드가 시스템에 삽입되는 순서대로 만들어지는 파일
		- 키 순차 파일 : 레코드들의 키 값으리 크기 순으로 만들어 지는 파일
	- 인덱스 방법 : 해당 인덱스를 찾아 인덱스가 가리키는 주소를 따라가 원하는 레코드를 접근 할 수 있도록 데이타를 저장하는 압법
		- 인덱스된 파일은 인덱스 파일과 데이터 파일로 구성 (하나의 인덱스를 사용하는 인덱스된 순차 파일)
			- 인덱스 파일은 <키 값, 주소> 쌍으로 구성
			- 순차 데이터 파일은 레코드 집합 전체에 대한 순차 접근 요구를 지원하는 데 사용
		- 다중키 파일 : 하나의 데이타 파일에 여러 개의 상이한 접근 방법을 지원하는 구조
			- 여러 개의 인덱스를 동시에 사용
			- 다중 접근 경로를 제공하려는 것
				- 역파일 : 각 응용에 적절한 인덱스를 만들어 구현
				- 다중 리스트 파일 : 하나의 인덱스 값마다 하나의 데이타 레코드 리스트 구축
				![ex_screenshot](/res/db22.png)
		- 인덱스 : 어떤 파일의 레코드에 대한 효율적 접근을 위해 <레코드 키 값, 레코드 주소(포인터)> 쌍을 체계적으로 수집하여 관리하는 보조 데이타 구조
			- 기본 인덱스 : 기본 키를 포함하고 있는 인덱스
			- 보조 인덱스 : 기본 인덱스 이외의 인덱스들
			- 집중 인덱스 : 데이터 레코드의 물리적 순서가 파일에 대한 어떤 인덱스의 엔트리 순서와 동일하게 유지하도록 구성된 인덱스
				- 같은 인덱스 키 값을 가진 레코드는 물리적으로 인접하게 되어 효율적인 검색을 수행토록 만든다
				- 하나의 파일은 최대 하나의 탐색 키에 대해서만 집중될 수 있다 -> 하나의 데이터 파일에 대해 하나의 집중 인덱스를 생성할 수 있다
			- 비집중 인덱스 : 집중형태가 아닌 인덱스, 하나의 뎅리타 파일에 대해 여러개가 만들어 질 수 있다
			- 밀집 인덱스 : 데이타 레코드 하나에 대해 하나의 인덱스 엔트리가 만들어 지는 인덱스
			- 희소 인덱스 : 데이타 화일의 레코드 그룹 또는 데이타 블록에 하나의 엔트리가 만들어 지는 인덱스
			- 역 인덱스는 보통 밀집 인덱스 형태로 만들어 진다.
		- 인덱스 구조
			- B-트리 : m-원 균형 탐색 트리로서 효율적인 균형 알고리즘 제공
				- 차수가 m인 m차 B-트리는 다음과 같은 특성을 가짐
				 - B-트리는 공백이거나 높이가 1이상인 m-원 탐색 트리 이다
				 - 루프와 리프를 제외한 내부 노드는 최소 [m/2], 최대 m개의 서브 트리를 갖는다. (최소 [m/2] -1 개의 키를 갖는다)
				 - 루트는 그 자체가 리프가 아닌 이상 적어도 두 개의 서브트리를 갖는다 (트리가 공백이 아닌 이상 처음부터 분기해야 함)
				 - 모든 리프는 같은 레벨에 있다 (트리가 균형을 유지해야 한다는 것을 의미)
				- B-트리는 항상 균형 상태를 유지하면서 키 값의 삽입이나 삭제 뒤에도 B-트리 정의에 명세된 성질을 유지해야 한다
				- B-트리에서의 삽입과 삭제는 연산이 완료된 뒤에도 다시 트리의 균형을 유지해야 한다는데 어려움이 있다
			- B+ 트리 : B-트리의 변형
				- 리프가 아닌 노드로 구성되는 인덱스 세트
				- 리프 노드로만 구성된 순차 세트
				- 인덱스 세트에 모든 키값들은 리프노드에 있는 키 값을 찾아가는 경로만 제공하기 위해 사용되고 있다
				- 순차 세트의 모든 노드가 순차적으로 서로 연결된 연결 리스트로 되어있다
					- 키 값을 순서에 따라 효율적으로 접근할 수 있도록 함
				- 차수가 m인 m차 B+ 트리는 다음과 같은 특징을 갖는다
					- 루트는 0이거나 2에서 m개 사이의 서브트리를 갖는다
					- 루트와 리프를 제외한 모든 내부 노드는 최소 [m/2]개, 최대 m개의 서브트리를 갖는다
					- 리프가 아닌 노드에 있는 키 값 수는 그 노드의 서브트리 수보다 하나 적다
					- 모든 리프 노드는 같은 레벨에 있다
					- 한 노드 안에 있는 키 값들은 오름차순으로 저장 된다.
					- 리프 노드는 파일 레코드들의 순차 세트를 나타내며 모두 링크로 연결되어 있다
				- B+ 트리에서 키 값의 검색 작업은 항상 순차 세트, 즉 리프 노드까지 가야만 종료 된다.

- 해싱 방법
	- 다른 어떤 레코드도 참조하지 않고 원하는 목표 레코드를 직접 접근할 수 있게 하는 기법
	- 이 방법을 기초로 만들어진 파일을 직접 파일이라 한다
	- 직접 파일에서는 레코드를 식별하기 위한 키 값과 저장 장치에 저장되어 있는 레코드 주소 사이 사상, 즉 대응 관계가 성립되어야 한다
	- 해싱 함수 : 주어진 키 값을 레코드의 물리적 주소로 사상시키는 사상 함수 
		- 해시 필드 or 해시 키 : 레코드 주소를 계산하기 위해 사용하는 레코드의 키 값
		- 해시 주소 : 계산 결과로 나온 주소
		- 버킷 해싱 : 해싱 함수가 레코드의 키 값(해시 키)을 가지고 그 레코드가 저장되어 있는 버킷 주소로 사상하는 것
			- 버킷 : 하나의 주소를 가지고 있으며 하나 이상의 레코드를 저장할 수 있는 파일의 한 구역
			- 해시 키와 버킷 주소 간의 사상은 보통 다대일의 관계가 되기 때문에 서로 다른 레코드들이 같은 주소로 사상되는 경우 발생 -> 충돌
			- 동거자 : 해싱 함수에 의해 같은 주소로 변환된 모든 레코드들
				- 충돌은 바로 동거자가 된다는 것
				- 버킷이 만원이라면 오버플로 -> 접근 시간 길어짐 -> 파일 성능 저하
			- 충돌로 인한 오버플로를 어떻게 처리하는지가 가장 큰 관심사 
			
	![ex_screenshot](/res/db24.png)
	
	- 확장성 해싱 : 디렉터리와 버킷 집합을 사용 
		- 디렉터리 : 현재 디렉터리 깊이 d를 유지하는 헤더와 2^d 개의 버킷을 지시할 수 있는 포인터 엔트리로 구성
			- d를 전역 깊이라 함
		- 버킷은 레코드들을 저장할 수 있는 공간과 현재 버킷 깊이 p를 유지하는 헤더로 구성
			- p를 지역 깊이
		- 확장성 해싱 함수
			- 레코드의 키를 일정 길이의 비트 스트링으로 변환하는데 모조키라 한다
			- 각 버킷의 깊이는 그 벗킷에 저장되어 있는 레코드들의 모조 키들이 공통으로 시작하는 비트 스트링 길이
			- 어떤 레코드를 검색하기 위해 모조키의 처음 d 비트를 디렉터리 인덱스로 사용
			- 이 인덱스를 가진 디렉터리 엔트리는 목표 버킷에 대한 포인터 제공
		- 레코드를 저장할 때는 먼저 저장할 레코드 모조키의 처음 d비트를 이용해 디렉터리에 접근하고 포인터가 지시하는 버킷을 찾아 레코드를 저장
			- 버킷이 만원이면 오버플로 -> 새로운 버킷 생성		
				
	![ex_screenshot](/res/db23.png)

11. 객체 데이타베이스
- 데이터 시스템의 목적은 공용의 대량 정보를 관리하는 것
- 전통적 응용들 특성
	- 통일성 : 크기가 같고 유사한 구조의 많은 데이타 아이템을 처리
	- 레코드 중심 : 기본 데이터 아이템들은 고정 길이의 레코드들로 구성
	- 작은 데이터 아이템 : 각 레코드 키기는 몇 백 바이트를 넘지 않는다
	- 원자 필드 : 레코드내의 필드는 고정 길이의 작은 원자 값을 갖는다
	- 단기 트랜잭션 : 트랜잭션들은 실행 시간이 1초도 안되는 매우 작은 프로그램
	- 정적 스키마
- 새로은 응용
	- 컴퓨터 이용 설계
	- 컴퓨터 이용 소프트웨어 공학
	- 멀티미디어 데이터베이스
	- 사무 정보 시스템
	- 하이퍼텍스트

- 객체 데이타 모델
	- 객체 데이타베이스 : 객체 데이타 모델에 따라 객체의 상태와 행태, 관계가 정의되는 객체의 집합
	- 객체 데이터베이스 관리 시스템 : 객체 데이타 모델을 직접 지원하는 데이터베이스 관리 시스템
	- 객체 : 유일한 식별, 내포된 성질, 다른 객체 or 자기 자신과 상호작용을 할 수 있는 실세계 개체를 추상적으로 표현한 것
		- 개체 : 데이터 구성요소와 관계성으로 정의
		- 객체는 연산자도 함께 정의
		- 객체의 식별성은 객체 식별자(OID)로 표현, 객체마다 유일한 값
	- 객체 간 관계는 객체에 대한 참조 관계로 표현되고 한 객체의 애트리뷰트 값으로 피 참조 객체 식별자를 갖도록 함
	- 애트리뷰트와 메소드
		- 한 객체를 기술하는 애트리뷰트 집합을 객체구조라 함
		- 각 애트리뷰트는 유일한 이름과 애트리뷰트가 취할 수 있는 값의 집합으로서 도메인을 나타내는 하나의 데이터 타입을 가짐
		- 객체는 애트리뷰트를 통해 다른 객체를 참조할 수 있다
		- 어느 한 시점에서 한 객체의 애트리뷰트들이 가지고 있는 값들을 객체 상태라 하고 항상 변할 수 있다(OID는 변경 불가)
		- 객체 애트리뷰트를 변경하기 위해서 메시지를 보내 메시지가 해당 메소드를 기동시키도록 만들어야 함
		- 한 객체에 명세된 메소드들의 집합을 객체 행태라고 함
		- 메소드는 객체의 애트리뷰트 변경이나 특정 애트리뷰트 값 검색 시 사용
		- 메시지는 수신 객체, 메소드 이름, 매개 변수를 명세함으로써 전송된다
		- 객체 내부 구조는 메시지를 보내는 전송자가 직접 접근 불가 -> 객체 상태의 무결성 보장, 내부 구조를 은닉
	- 클래스
		- 클래스는 객체 시스템과 데이터베이스를 연결하는 가장 중요한 개념
		- 인스턴스와 그 인스턴스가 속하는 사이 instance-of 관계를 표현하며 질의문이 구성되는 기반 제공
		- 객체 데이터베이스의 다양한 의미적 무결성 규칙들을 표현할 수 있음
		- 애트리뷰트와 메소드의 명세와 같은 스키마 정보를 저장하는 역할 수행
		- 클래스 자체를 객체로 취급하는 경우 시스템의 다른 클래스들은 메타 클래스라함
			- 특수한 논리적 클래스 인스턴스로 간주
		- 클래스 애트리뷰트는 요약 정보를 표현하기 위해 사용하기도 함
	- 클래스 계층과 상속
		- 애트리뷰트 즉 인스턴스 변수를 상속 받는 것을 구조 상속, 메소드를 상속받는 것을 행태 상속이라 함
		- 하나의 클래스에 하나의 직속 슈퍼클래스만 존재할 수 있는 클래스 계층에서는 단일 상속
		- 하나의 클래스에 두 개이상의 직속 슈퍼 클래스가 존재할 수 있는 클래스 격자에서는 다중 상속이 있게됨
	- 복합 객체
		- 어느 한 객체의 애트리뷰트가 그 값으로 다른 객체를 참조하는 객체
		- 한 객체의 어느 애트리뷰트 도메인으로 사용자 정의 클래스가 사용되는 객체

13. XML과 데이터베이스
14. 질의어 처리
- 질의어 처리 단계
	![ex_screenshot](/res/db25.png)
	- 검사기 : 질의문에 나온 언어의 요소들을 식별
	- 파서 : 질의문을 분석해 질의어의 구문법에 맞는지 여부 검사
	- 질의문 트리, 질의문 그래프 : 트리나 그래프 자료구조의 내부 표현으로 반환
	- 질의문 계횎 : 질의문을 실행하고 데이터를 접근하고 중간 결과를 저장하는 데 필요한 계획
	- 질의어 최적화 : 질의문 실행 계획 중 가장 적절한 계획
	- 질의어 최적기 : 질의문 계회 생성, 선정
	- 코드 생성기 : 계획을 실행시키기 위한 코드 생성 -> 직접 실행 시킬 수 있는 번역 형태이거나 저장해 두었다 필요시 실행시킬 수 있는 컴파일 형태
	- 런타임 데이터베이스 처리기 : 코드를 실행시켜 질의문의 처리 결과를 생성
	- 질의어 최적화라 하지만 실행 전략의 제한적 최적이 적절한 표현!
	
	- 질의어 최적화는 고급 질의어를 지원하는 관계 데이타베이스 시스템과 같은 데에서 필요한 것
		- DBMS로 하여금 주어진 질의문을 실행 할 수 있는 여러 전략들을 체계적으로 평가해 하나의 최적 전략을 선택하는 시스템 레벨 최적화
- 질의어 최적화
	- 질의어 최적화 과정은 크게 4단계로 나눌 수 있음
	- 질의문의 내부 표현
		- 질의문을 작성하기 편하도록 첨가시킨 부수적 구문, 필요하지 않는 것을 제거하는 작업도 포함
		- 어떤 형식론을 기반으로 내부 표현하느냐가 중요!
			- 질의어로 표현할 수 있는 것은 모두 이 형식으로 표현할 수 있어야 함
		- 이론적 기반을 제공해야 하고 편향된 영향을 주지않고 중립적인 것이어야함
			- 관계 대수나 관계 해석 등 여러가지 가능
		- 질의문 내부 표현 형태는 질의문 트리라고 한다
		
			![ex_screenshot](/res/db26.png)
	- 효율적 내부 형태로 변환
		- 앞단계에서 생성된 표준 내부 형태를 저장 데이터베이스에 존재하는 실제 데이터 값이나 접근 경로에 무관하게 어떤 정립된 변환 규칙에 따라 처리면에서 효율적인 내부 형태로 변환하는 작업 수행
			- 질의문 트리 변환(질의문 트리 최적화)라고 함
		- 파서가 만들어낸 질의문의 내부 표현을 동등하면서도 처리에 효율적인 형태로 변환하기 위해 어떤 정립된 변환 규칙이 있어야함
	- 후보 프로시저 선정
		- 최적기는 최종 내부 표현을 실제로 어떻게 실행시 킬 것인가 질의문 계획을 결정해야 한다
		- 주어진 최종 내부 표현을 일련의 저급 연산, 조인 프로시저, 실렉트 프로시저 등으로 명세하는 것이 질의문 계획의 기본 전략
		- 저급 연산에 대해 최적기는 미리 구현시켜 놓은 몇 개의 프로시저들을 가지고 있다
		- 최적기는 내부 표현에 사용된 각 연산자에 대해 하나 이상의 후보 프로시저를 선정할 수 있다
			- 어떤 프로시저가 더 효율적이며, 효율적이라 해도 일련의 프로시저들 전체로 볼때도 효율적인지 간단히 결정할 수 없기 때문
	- 질의문 계획의 평가 및 결정
		- 질의문을 실행할 수 있는 후보 질의문 계획을 평가하고 그중 최상의 즉 치소 비용 계획을 결정하는 것
		- 각 연산에 대해 하나의 실행 프로시저를 골라 이들을 모두 조합해 구성하는 것
			- 모든 가능 질의문 계획을생성하는 것은 문제가 있다
		- 자습적 기법에 따라 적당한 수의 질의문 계획을 생성하고 평가하는 것이 바람직
			- 적당한 수로 제한 -> 탐생 공간의 축소 
			- 최적기가 최소 비용의 질의문 계횎을 탐색해야할 공간의 범위를 축소시켜 주는 것
		- 최소 비용을 가진 질의문 계획 선정을 위해 주어진 계획에 대해 비용을 계산하는 방법이 있어야 함
		- 각 프로시저는 비용을 매개변수로 나타내는 비용식을 가지고 있다
			- 비용식들이 처리될 릴레이션들의 크기와 밀접한 관계를 가지고 있다 -> 릴레이션의 크기에 대해서도 추산해야함
		- 비용식에서 고려하는 요소 : 디스크 입출력 비용, 저장 비용, 계산 비용, 통신 비용 
		
	- 대형 데이타베이스에서 비용 문제는 주로 보조 기억 장치에 대한 접근 비용을 최소화하는 데 주안점을 두고 있다
	- 대부분의 비용식은 디스크와 주 기억장치 사이 블록 입출력 횟수를 중심으로 비용 추산
	- 소형 데이터베이스에서는 주로 계산 비용의 최소화에 주안점을 둠
	- 분산 데이터베이스에서는 자연히 통신 비용도 큰 비율을 차지하므로 최소화 해야함
	- 비용식은 이 모든 비용 요소들에 적절한 가중치를 부여해 포함시키는것이 이상적이지만 보통 디스크 접근 비용하나만 고려
	
- 내부 형태 변환 규칙
	- 질의문 트리 변환 시 기본 원칙은 질의문 트리들이 모두 동등해야한다는 것
		- 동등하다는 것은 실행하면 항상 같은 결과를 생성한다는 의미 
	- 동등한 변환을 위해 동등성을 유지하는 변환 규칙을 이용해야함
	
	- 논리곱(AND)으로 된 조건을 가진 SELECT 연산은 분해하여 일련의 개별적 SELECT 연산으로 변환
	- 다른 연산자를 포함하고 있는 SELECT 연산은 선택 조건의 애트리뷰트가 허용하는 범위 내에서 실렉트 연산이 먼저 실행되도록 변환
	- 질의문 트리의 단말 노드들을 재정된 해 가장 제한적 SELECT 연산이 가장 먼저 실행되도록 한다.
		- 제한적 SELECT는 선택 결과가 가장 작거나 피연산 릴레이션이 가장 작은 것을 의미
		- 선택 결과가 가장 작다는 것은 선택도가 가장 작은 것, 이 예상 선택도에 대한 정보는 카탈로그에 있다
	- 카티션 프로덕트 연산 다음 바로 실렉트 연산이 나오는 것은 하나의 조인 연산을 통합한다
	- 다른 연산을 포함하고 있는 PROJECT연산은 가능한 한 프로젝트 애트리뷰트를 분해해 개별적 PROJECT로 만들어 프로젝트 연산이 먼저 실행되도록 한다
	- OR로 연결된 조건식은 논리곱 정형식으로 변환한다.
	
	- 연산의 중간 결과의 크기를 줄이는 연산을 먼저 수행하는 것이 요점!
		- SELECT를 가능한 먼저 실행시켜 투플 수를 줄이고 PROJECT를 가능한 일찍 수행해 애트리뷰트를 줄이는 것
		- 검사해야 될 데이타 양을 감소하거나 중간 결과 크기를 줄여 준다
			- 중간 결과를 디스크에 이동시키지 않고 메인 메모리에 유지하며 처리할 수 있다
- 질의문 트리 변환 과정

	![ex_screenshot](/res/db27.png)
	![ex_screenshot](/res/db28.png)
		
- 질의문 분해
	- INGRES DBMS의 QUEL 데이터 언어를 실행하는 데 사용한 최적화 기법
	- 여러 개의 투플 변수가 관련된 질의문을 하나 OR 두개의 투플 변수만 포함된 일련의 소질의문으로 분해하여 처리한 다는 것
	- 분리 : 하나의 소질의문을 식별해 분리시키는 것이며 분리된 소질의문과 나머지 질의문과 하나의 공통 투플 변수로 연결
	- 투플 대입 : 질의문에 있는 변수에 실제 투플 값을 대입하는 것
	- 분리는 항상 하나의 질의문을 두개의 질의문으로 만들기 때문에 투플 대입전에 수행한다
	<pre><code>
	Q : RETRIEVE(S.SNAME) WHERE S.Dept =' 컴퓨터' AND S.Sno = E.sno AND E.fianl >= 90 AND E.Cno = C.Cno AND C.Name = '데이타베이스'
	// 변수 C만 관련된 단일 변수 질의문으로 분리
	// 데이타베이스 과목의 Cno를 반드시 검색해야 함
	D1 : RETRIEVE INTO C'(C.Cno) WHERE C.Cname = ' 데이터베이스'
	Q1 : RETRIEVE(S.SNAME) WHERE S.Dept =' 컴퓨터' AND S.Sno = E.sno AND E.fianl >= 90 AND E.Cno = C'.Cno
	// 투플 변수 E와 관련된 단일 질의문을 분리
	D2 : RETRIEVE INTO C'(E.Sno, E.Cno) WHERE E.Final >= 90
	Q2 : RETRIEVE(S.SNAME) WHERE S.Dept =' 컴퓨터' AND S.Sno = E'.Sno AND E'.Cno = C'.Cno
	// S와 관련된 단일 변수 질의문을 분리
	D3 : RETRIEVE ITNO C'(S.Sno, S.Sname) WHERE S.Dept = '컴퓨터'
	Q3 : RETRIEVE(S'.SNAME) WHERE S'.Sno = E'.Sno AND E'.Cno = C'.Cno
	// 더 이상 단일 변수 질의문을 분리할 수 없기에 투플 변수 E'와 C'에 관련된 두 변수 질의문을 분리
	D4 : RETRIEVE INTO E''(E.Sno) WHERE E'.Cno = C'.Cno;
	Q4 : RETRIEVE (S'Sname) WHERE S'.Sno = E''.Sno
	</code></pre>

	![ex_screenshot](/res/db29.png)
	- 최적화 기법의 기본 목표는 카티션 프로덕트를 피하고 각 단계에서 조사해야 될 투플의 수를 최소화 시키는 것

- 관계 대수 연산자의 구현
	- DBMS는 실행을 위한 질의문 계획에 사용되는 관계 연산들을 구현하는 프로시저를 가지고 있어야 한다
	- 하나의 프로시저는 특정 저장 구조와 접근 경로에만 적용될 수 있다
	- 특정 프로시저를 사용하기 위해서는 프로시저가 요구하는 접근 경로가 관련된 데이타 화일에 포함되어야 한다
	
	- 실렉트 연산의 구현
		- 선형 탐색 : 피일에 있는 모든 레코드를 차례로 검색해 그 애트리뷰트 값이 탐색 조건을 만족하는지 검사하는 방법
		- 이원 탐색 : 파일이 정렬되어 있고 그 정렬 키 애트리뷰트가 선택 조건식의 애트리뷰트로 명세되어 있을 때 사용할 수 있다. 탐색 범위를 매번 절반으로 줄여가면서 목표 레코드를 찾는 방법
		- 기본 인덱스나 해시 키를 통해 하나의 레코드를 탐색 : 선택 조건식에 기본 인덱스(해시 키)애트리뷰트가 명세되어 있을 때 사용하는 방법
		- 기본 인덱스를 이용해서 복수 레코드를 탐색 : 만일 비교 조건식이 기본 인덱스 키 필드에 대한 비교, 즉 >, E, < 또는 D이면 먼저 기본 인덱스를 사용해서 '='조건을 만족하는 레코드를 찾은 다음에 나머지 조건을 만족하는 레코드들을 파일로 부터 검색
		- 집중 인덱스를 이용해 복수 레코드를 탐색 : 선택 조건식이 키는 아니지만 집중 인덱스가 만들어진 애트리뷰트를 포함하고 있을 때 사용
		- 보조 인덱스(B+ - 트리)이용 : 동일 비교에서 인덱스 필드가 키일 때는 단일 레코드를 검색하는 데 사용할 수 있고, 키가 아닐 때는 복수 레코드를 검색하는 데 사용할 수 있다. 또한, >,E,< 또는 D이 들어간 조건식에서도 사용할 수 있다.
	
	- 조인 연산의 구현
		- 조인은 질의문 처리에 가장 시간이 많이 걸리는 연산 중 하나		
		- 중첩 루프 
			- 외부 릴레이션 R의 각 투플 R(i)에 대해 내부 릴레이션 S의 각 투플 S(j)를 검색해 조인 조건 R(i).A = S(j).A를 만족하는지 검사
			<pre><code>
			do i = 1 to n; // outer loop
				do j = 1 to m; // inner loop
					if R(i).A = S(j).A then
						add R(i) * S(j) to result;
					end;
				end;
			</code></pre>
		- 인덱스 검사
			- 릴레이션 S의 애트리뷰트 S.A에 대한 인덱스 X가 만들어져 있다고 할 때 인덱스를 검사한다
			<pre><code>
				do i = 1 to n;
				// R(i).A와 같은 값을 가진 인덱스 엔트리가 k개
				// X(k)가 있다고 가정
					do j = 1 to k;
						// X(j)로 인덱스되는 S의 투플을 S(j)라 하자
						add R(i) * S(j) to result;
					end;
				end;
			</code></pre>
		- 해시 검사
			- 릴레이션 S의 조인 애트리뷰트 S.A에 대해 해시 테이블 H가 있다고 할 때 이 테이블 을 검사
			<pre><code>
			do i =1 to n;
				k = hash(R(i).A);
				// H(k)에 h개의 투플
			 	do j = 1 to h;
			 		if s(j).A = R(i).A then
						add R(i) * S(j) to result;
					end;
				end;
			</code></pre>
		- 정렬 / 합병
			- 릴레이션 R과 S가 모두 조인 애트리뷰트 A에 대해 오름차순으로 정렬되어 있다 가정
			<pre><code>
			k =1;
			do i =1 to n;
				do j = k to m;
					if S(j).A = R(i).A then
						add R(i) * S(j) to reuslt;
					if S(j).A > R(i).A then
						leave inner loop;
				end;
				k = j;
			end;
			</code></pre>
		- 해싱
			- 먼저 릴레이션 S의 조인 애트리뷰트 S.A에 대한 해싱 테이블 H르르 만든 다음 해시 검사 수행
			<pre><code>
			// S.A에 대한 해시 테이블 H 구성
			do j = 1 to m;
				k = hash(S(j).A);
					add S(j) to hash table entry H(k);
			end;
			// 해시 검사를 R에 대해 수행
			</code></pre>
		- 위 방법의 조합
	- 프로젝트 연산 구현
		- 프로젝트 애트리뷰트에 키가 포함되면 구현은 쉽다
		- 결과 릴레이션은 원래 릴레이션 투플 수와 똑같은 수의 투플을 포함하게되고 다만 프로젝트 애트릴뷰트 리스트에 있는 값만 각 투플에 포함
		- 프로젝트 애트리뷰트 리스트에 키가 포함되지 않으면 중복되는 투플을 제거하는 작업을 추가로 수행
		- 해싱 방법은 중복 투플을 제거하는 데 사용할 수 있다
- 비용 함수 
 	- 비용식, 비용 함수가 필요로 하는 정보를 유지해야 한다
	- 이런 정보는 질의어 최적기가 접근하는 시스템 카탈로그에 저장
		- 파일의 크기를 알아야함
		- 레코드 수 r, 블록 수 b, 파일에 대한 블록 인수 bf
		- 기본 접근 방법과 기본 접근 애트리뷰트에 대해서도 알아야 함
		- 모든 보조 인덱스와 인덱스된 애트리뷰트에 대한 정보도 저장
	- 저장된 인덱스 애트리뷰트 값에 대해 서로 다른 상이한 값의 수 d -> 중요한 매개 변수
		- 검색 투플 수 s, 애트리뷰트 값을 선택 조건으로 할 때 이것을 만족하는 평균 투플 수 계산이 필요
	- 비용 함수는 메모리와 디스크 간의 블록 전송 수, 즉 디스크 입출력 수만 고려한 것이고 이외 연산 시간, 저장 시간 등의 요소 무시한 것
	- 질의어 최적기는 질의문 계획을 선정할 때 각 후보 계획들을 이런 비용 함수를 이용해 추산해보고 가장 최저 비용의 질의문 계획을 선정하는 것
- 의미적 질의어 최적화
	- 구문적인 것에 주안점을 둔 것
	- 구문적 변환 규칙과 데이터베이스 스키마에 명세된 제약 조건을 혼용해 질의문을 효율적으로 처리할 수있는 질의문으로 변환하는 방법

15. 회복
- 장애와 회복
	- 회복 : 장애가 일어났을 때 데이터베이스를 장애 발생 이전의 일관된 상태로 복원시키는 것을 말함
		- 일관된 상태 : 데이터베이스에 오류가 없는 상태
	- 장애 : 정해진 명세대로 시스템이 작동하지 않는 상태
	- 장애 유형
		- 트랜잭션 장애 : 트랜잭션내의 논리적 오류나 내보 조건 등으로 정상적 실행을 계속할 수 없는 상태 
		- 시스템 장애 : 하드웨어의 오작동으로 메인 메모리에 있는 정보의 손실이나 교착상태가 발생해 더 이상 실행을 계속할 수 없는 상태
		- 미디어 장애 : 디스크 헤드 붕괴나 고장으로 인해 저장장치의 데이터베이스 일부 또는 전부가 손상된 상태
	- 회복 관리자 : DBMS의 서브시스템으로 신뢰성 있는 회복을 책임지기 위해 장애 발생을 탐지할 수 있는 기능과 탐지된 장애로부터 데이터베이스를 복원시키는 기능을 가짐
	- 회복의 기본 원리는 데이터 중복이며 데이터 정복 기법에는 덤프와 로그가 있음
		- 덤프 : 주기적으로 데이터베이스 전체를 다른 저장장치에 복제 하는 것
		- 로그 : 데이터베이스가 변경될 때마다 변경되는 데이타 아이템 옛 값과 새 값을 별도 파일로 기록해 두는 것
	
	- 장애 발생 시 조치 유형
		- Redo : 데이타베이스 내용 자체가 손상된 경우 가장 최근의 복제본을 적재시킨 뒤 복제본 이후에 일어난 변경만 로그를 이용해 재실행함으로 복원하는 것
		- Undo : 데이터베이스 내용 자체는 손상되지 않았으나 변경 중이거나 변경된 내용에 대한 신뢰성을 잃어버린 경우 로그를 이용해 모든 변경을 취소시킴으로 원래 상태로 복원하는 것
	- 회복 작업은 손상된 부분만을 포함하는 최소 범위 내에서 최단 시간 내에 완료해 데이터베이스 접근이 중단되는 시간을 최소로 줄어야 한다
		- 작업 단위 : 트랜잭션
		- 사용자 도움 없이 수행할 수 있는 시스템 레벨의 자동 조치이어야 함

- 데이타베이스 저장 연산
	- 회복에 관련된 데이타 저장 장치는 장애에 대한 탄력성에 따라 소멸, 비소멸, 안정 저장장치로 구분 할 수 있다
		- 소멸 저장 장치 : 메인 메모리와 같이 시스템의 붕괴와 함께 저장된 데이타를 상실
		- 비소멸 저장 장치 : 시스템 붕괴 시에도 보통 저장된 데이타는 손실되지 않음
		- 안정 저장장치 : 데이타의 손실이 발생하지 않게 여러 개의 비소멸 저장장치로 구성된 저장 장치
	- 트랜잭션은 디스크로부터 메인 메모리로 데이터를 입력시켜 처리하고 디스크로 출력한다
		- 입, 출력 연산은 블록 단위로 수행
		- 디스크에 있는 블록을 디스크 블록, 물리적 블록이라 하며, 메인 메모리에 있는 블록을 데이터베이스 버퍼 블록이라함
	- 디스크와 메인 메모리 사이의 블록 이동
		- Input(Bi) : 데이타 아이템들이 포함되어 있는 디스크 블록Bi를 메인 메모리로 이동
		- Output(Bj) : 데이타 아이템들이 포함 되어 있는 버퍼 블록 Bj를 디스크 볼록에 이동시켜 기록		
		![ex_screenshot](/res/db30.png)
		
	- 데이터 이동 연산 
		- Read : 데이타 아이템 X의 값을 지역 변수 x의 값으로 지정 
			- 데이터 아이템 X가 버퍼 블록에 없으면 x가 포함된 블록에 대해 Input 실행
			- 버퍼 블록에 데이터 아이템 X의 값을 변수 x에 저장
		- Write : 지역 변수 x 값을 버퍼 블록에 있는 데이터 아이템 X에 지정
			- 데이터 아이템 X가 버퍼 블록에 없으면 x가 포함된 블록에 Input 실행
			- 변수 x의 값을 버퍼 블록에 있는 데이타 아이템 X에 저장
			
- 트랜잭션
	- 하나의 논리적 기능을 수행하기 위한 작업 단위로 데이터베이스의 일관된 상태를 다른 일관된 상태로 변환
	- 트랜잭션 특성
		- 원자성 : 트랜잭션은 자기의 연산을 전부, 전무 실행만 있다
		- 일관성 : 실행을 성공적으로 완료하면 언제나 일관성 있는 데이터베이스 상태로 변환
		- 격리성 : 실행 중에 있는 연산의 중관 결과는 다른 트랜잭션이 접근 불가
		- 영속성 : 그 실행을 성공적으로 완료하면 결과는 영속적, 시스템은 어떠한 경우라도 완료 결과에 대해 영속성을 보장해야 함
		
	- 트랜잭션은 작업의 논리적 단위이기에 원자성 성질이 가장 중요!
		- Commit 연산 : 트랜잭션의 실행이 성공적으로 종료됨을 선언 -> 영속성을 갖도록 시스템이 보장
		- RollBack 연산 : 트랜잭션의 실행이 실패했음을 선언 -> 원상 복귀 시켜야함
	- 디스크 갱신 
		- 원 위치 갱신 : 갱신된 버퍼 블록을 원리 디스크 블록에 다시 기록
		- 간접 갱신 : 다른 공간에 기록
	- 트랜잭션 상태 
		- 활동 : 실행을 시작했거나 실행 중인 상태
		- 부분 완료 : 트랜잭션이 마지막 명령문을 실행한 직후 상태
		- 실패 : 정상 실행을 계속할 수 없어 중단한 상태
		- 철회 : 트랜잭션이 실행에 실패해 RollBack 연산을 수행한 상태
		- 완료 : 트랜잭션이 실행을 성공적으로 완료해 Commit 연산을 수행한 상태		
	
	![ex_screenshot](/res/db31.png)
		
- 로그 이용 회복
	- 로그 : 트랜잭션 이름, 데이타 아이테메 이름, 변경 전 데이터 아이템 값, 변경 후 아이템 값으로 구성
	- 로그 레코드 유형
		- <Ti, Start> : 트랜잭션 Ti 실행 시작
		- <Ti, Xj, V1,V2> : 트랜잭션 Ti가 데이터 아이템 Xj 값을 V1에서 V2로 변경
		- <Ti, Commit> : 트랜잭션 Ti가 실행 완료
	- 보존 로그 : 일정 기간마다 누적되는 로그를 보존시키기 위해 별도로 로그를 만듬, 보통 테이프에 저장	
		![ex_screenshot](/res/db32.png)
	- 데이터가 변경 시 생성되는 로그는 철회되면 로그 레코드도 같이 삭제해야 하는 겨우도 있다
	- 온라인 로그 : 실행 중인 트랜잭션에 대한 로그를 디스크에 기록 저장하는 것
	- 보존 데이타베이스 : 디스크 붕괴나 시스템 장애로 인한 손실에 대비해 주기적으로 사존을 만들어 보존하는 데이터
		- 온라인 데이터베이스와 온라인 로그를 이용한 회복은 주로 트랜잭션 회복, 시스템 회복을 위해 사용, 장치 화복은 보존 데이터베이스와 보존 로그가 사용됨
	- 대형화 되는 로그 파일을 위한 저장 장치의 효율성과 신속한 회복을 위해 시스템은 로그를 압축시키는 노력 수행
	
	- 지연 갱신 회복
		- 트랜잭션이 부분 완료 될 때 까지 모든 Output 연산을 지연시키고 데이터 베이스의 변경을 로그에 전부 기록해 두었다 한꺼번에 실행시킴으로 트랜잭션 원자성을 보장하려는 것
		- 트랜잭션이 부분 완료되면 보류 시킨 Output 연산을 수행 -> 로그를 사용
		- 모든 로그 레코드들은 이 갱신 작업 전 안정된 저장장치에 기록 되어야 한다 -> 시스템 붕괴는 갱신 작업 과정에서도 일어 날 수 있다
		- Redo 연산에 대비해 데이터 아이템의 새로운 변경된 값만 있으면 되기 때문에 옛날 값 필드가 없어도 된다
		- 로그 레코드는 <트랜잭션 Id, 데이타 아이템, 변경된 값> 형식을 가짐
		- Redo 프로시저
			- 트랜잭션 Ti가 변경한 모든 데이타 아이템 값들을 로그 파일의 순서에 따라 다시 로그에 있는 새로운 값으로 재지정
		- Redo 연산은 idempotent 성질을 가지고 있어야 함
			- 여러 번 실행한 것이나 한 번 실행한 것이나 결과는 동등해야 한다
		- 장애가 일어나면 회복 관리자는 트랜잭션이 재실행되어야 하는가를 로그를 이용해 결정
	
	- 즉시 갱신 회복
		- 트랜잭션이 연산을 실행하고 있는 활동 상태에서 데이타의 변경 결과를 데이타베이스에 그대로 반영하는 것
		- 활동성 완료가 안 된 트랜잭션에 의해 데이타베이스에 반영된 갱신을 미완료 갱신이라 한다
		- 로드 레코드는 <트랜잭션 ID, 데이타 아이템, 변경된 값> 형식을 취함
		- 회복 방법은 Undo 프로시저를 사용
			- 트랜잭션 Ti가 변경하ㅑㄴ 모든 데이타 아이템 값들을 로그에 기록된 역순으로 로그에 있는 변경 전 값으로 환원
			- idempotnet 성질을 가지고 있어야 한다 
		- 장애 시 다음 방법으로 Redo, Undo 트랜잭션 결정
			- 로그에 <Ti, Start> 레코드만 있고 <Ti, Commit> 레코드가 없으면 Undo(Ti) 수행
			- 로그에 <Ti, Start> 레코드와 <Ti, Commit> 레코드 모두 있으면 Redo(Ti) 수행
		- 모든 Undo 연산을 마친 뒤 Redo 연산을 하는 것이 효율적
			- Undo 연산은 로그에 기록된 순서의 역순으로 수행하고 Redo 연산은 로그에 기록된 순서로 수행해야 되기 때문

- 검사 시점 회복
	- 시스템 장애 발생 시 로그 이용 기법에서는 Redo, Undo를 해야할 트랜잭션을 결정하기 위해 로그 전체를 조사해야 한다
	- 트랜잭션 수행 동안에 로그 기록을 유지하며 일정한 시간 간격으로 검사 시점을 만들어 놓고 다음 작업 수행
		- 메인 메모리에 있는 모든 로그 레코드를 안정 저장소로 출력
		- 변경된 데이타 버퍼 블록을 전부 디스크로 출력
		- 검사 시점 표시로 <Checkpoint L> 로그 레코드를 안정 저장소에 출력	(L은 현재 실행 중에 있는 트랜잭션 리스트)
	- <Checkpoint L> 레코드는 회복 작업의 범위를 정해준다
		- 검사 시점 설정 시 이전 트랜잭션에 대해서는 회복 작업이 필요 없어짐
	- 회복 관리자는 로그에 있는 가장 최근 <Checkpoint L> 레코드를 찾아 그 시점 이후 로그만 회복 대상으로 하면 된다
		
		![ex_screenshot](/res/db33.png)
	- 다음과 같은 방법으로 Undo와 Redo를 해야 될 트랜잭션을 결정
		- 두 개의 빈 Undo-list와 Redo-list 를 만든다
		- 검사 시점 설정 당시 활동 중인 트랜잭션은 전부 Undo-list에 삽입
		- 로그를 차례로 검색하며 <Ti, Start> 로그 레코드를 만나면 트랜잭션 Ti를 Undo-list에 첨가
		- 로그를 차례로 검색하면서 <Ti, Commit> 로그 레코드를 만나면 트랜잭션 Ti를 Undo-list에서 삭제하고 Redo-list에 첨가
	- 작업이 완려되면 회복 관리자는 먼저 Undo-list에 있는 모든 트랜잭션에 대해 로그에 기록된 역순으로 Undo 연산을 수행
		- 다음 Redo-list에 있는 트랜잭션에 대해 로그에 기록된 순서로 Redo를 수행
	- Undo 연산을 수행해 회복하는 것을 후진 회복이라하고 Redo 연산을 수행해 회복하는 것을 전진 회복이라 함
- 그림자 페이징 기법
	- 로그를 이용하지 않는 회복 기법
	- 페이지 테이블에는 데이터베이스 페이지에 대응하는 n개의 엔트리가 있고 각 엔트리는 디스크에 있는 해당 페이지를 가리키는 포인터를 포함
		- 첫번 째 엔트리는 데이터베이스의 첫 번째 페이지를 가리키는 포인터
	- 기본 아이디어는 트랜잭션을 실행하는 동안 두개의 페이지 테이블 즉, 현 페이지 테이블과 그림자 페이지 테이블을 유지하는 것
		- 실제 실행에서 현 페이지 테이블만 사용하고 그림자 테이블은 사용하지 않음
		- 그림자 페이지는 전혀 변하지 않고 트랜잭션 실행 직전의 상태만 유지 
	- 변경 연산을 수행하기 직전 상태를 그림자 페이지 테이블로 유지해 두었다 시스템 붕괴나 트랜잭션 철회의 경우에 간단히 실행 직전 상태로 복귀시킬 수 있게 하는 방법
	- 트랜잭션 성공적 완료 시 현 페이지 테이블을 새로운 그림자 페이지 테이블로 대체
	- 그림자 페이지 테이블은 비소멸 저장장치에 저장시켜야 한다(중요!!)
		- 데이터베이스 페이지를 찾아내는 유일한 방법이 그림자 테이블이기 때문
	- 시스템 붕괴 후 다시 작동 되면 그림자 페이지 테이블을 메인 메모리에 복사해 트랜잭션을 실행하는 데 사용
		- 그림자 페이지 테이블에 대한 주소는 디스크 일정 장소에 저장
	
	![ex_screenshot](/res/db34.png)
	- 트랜잭션이 실행을 완료하기 위해 다음과 같은 조치 필요
		- 트랜잭션이 변경한 메인 메모리의 버퍼 페이지들을 디스크에 출력
			- 출력 연산은 현 페이지 테이블이 가리키는 디스크 페이지에 출력시키는 것
		- 현 페이지 테이블을 디스크에 출력
			- 같은 장소에 중첩 출력하면 안됨
		- 그림자 페이지 테이블 주소가 저장되어 있는 지정된 위치에 현 페이지 테이블의 디스크 주소를 출력
			- 이후 현 페이지 테이블이 그름자 페이지 테이블이 되고 트랜잭션 실행은 완료된다
	
	- 단일 사용자 환경에서 로그 레코드를 출력하는 오버헤드가 없다 -> 디스크 접근 횟수를 줄일 수 있다
	- Undo 연산이 간단하고 Redo 연산이 필요 없다 -> 장애로부터 회복 작업이 신속
	- 병행 수행 환경에서 그림자 페이징 기법으로만 운영이 어렵고 로그와 검사시점 기법을 함께 사용해야 함
	- 데이타베이스 페이지가 변경될 때마다 물리적 위치가 변해 페이지의 집중성이 없어져 데이타 단편 문제가 일어남
	- 페이지 테이블이 크면 그림자 페이지 테이블을 복사하고 기록하는 오버헤드가 커지게 된다

- 미디어 회복
	- 데이타베이스 애용 전체를 주기적으로 다른 안전한 저장장치에 덤프 시키는 것
		- 가장 최근의 덤프를 이용해 장애 발생 이전의 어떤 일관성 있는 데이타베이스 상태로 복원 
	- 끝나면 다시 로그를 이용해 가장 최근의 일관된 상태로 데이터베이스를 복원
	- 덤프 절차 
		- 메인 메모리에 있는 모든 로그 레코드를 안정 저장소에 출력
		- 변경된 버퍼 블록들을 모두 리스크에 출력
		- 데이타베이스 내용을 안정 저장장치에 복사
		- 로그 레코드 <dump>를 안정 저장소에 출력시켜 덤프를 표시
	- 회복 절차
		- 가장 최근의 덤프를 이용해 디스크에 데이타베이스 적재
		- 로그를 이용해 덤프 이후 완결된 트랜잭션들을 재실행 
	- 덤프 절차는 데이터베이스 전체를 안정 저장소에 복사해야 되므로 많은 데이터 전송 필요
	- 처리 동안 트랜잭션 처리를 중단해야 되기 때문에 CPU가 낭비되어 비용이 많이 들게 된다

- 회복 기법의 구현 
	- 로그 레코드 버퍼링 
		- 로그 레코드를 메인 메모리 버퍼 블록에 모아 한꺼번에 출력
		- 메인 메모리에 있어야 될 시간을 길게 만들어 시스템 붕괴 시 로그 레코드가 손실 될 위험 성이 높다
		- 원자성을 보장하는 회복 기법 -> 로그 우선 기록 규약
		- 로그 우선 기록 규약
			- 트랜잭션 Ti는 <Ti, Commit> 로그 레코드를 안정 저장장치에 출력시켜야 완료 상태로 들어 갈 수 있다
			- <Ti, Commit> 로그 레코드를 출력시키기 위해 먼저 Ti와 관련된 모든 로그 레코드를 안정 저장장치에 출력시켜야 함
			- 데이타베이스 버퍼 블록을 출력시키기 위해 먼저 이 버퍼 블록의 데이터와 관련된 모든 레코드가 안정 저장장치에 출력되어야 한다
	- 데이타베이스 버퍼링
		- 메인 메모리 일부를 DBMS가 관리하는 버퍼로 예약해놓고 데이타베이스 블록 이동을 관리
			-> DBMS는 버퍼내 변경된 블록을 출력하기전 블록에 관련된 로그 레코드를 먼저 안정 저장소에 출력 시킬 수 있다
			- 메인 메모리 크가가 제한되는 단점이 있다
			- 메인 메모리가 낭비 될 수 있고 데이터베이스 버퍼로 예약된 부분에 대해 데이터 베이스를 이용하지 않는 응용들은 사용할 수 없다				
		- DBMS는 운영체제의 가상 메모리 속 데이터베이스 버퍼를 구현하고 데이타베이스 자체는 운영체제의 파일 시스템 속에 저장
			- 데이터베이스 파일과 가상 메모리 사이 이동은 DBMS가 관리해 변경된 블록보다 로그 레코드가 출력되도록 한다
			- 디스크에 추가적인 출력을 필요로 하는 단점이 있다
	
- 다중 데이타베이스 트랜잭션 회복
	- 하나의 트랜잭션이 한 시스템 내 사잉한 자원 관리자가 관리하는 여러 개의 데이타베이스를 접근해야 하는 경우
	- 각 DBMS는 서로 독자적인 자신의 트랜잭션 관리자를 가지게 된다
	- 원자성을 확보하기 위해 전역 회복 관리자 OR 조정자 레벨과 지역 회복 관리자 OR 참여자 레벨에서 수행하는 회복 기법이 있어야 한다
	- 이 회복 기법을 2단계 완료 규약이라 한다
	- 단계 1
		- 모든 참여 데이터베이스가 조정자에게 자기가 관련된 다중 데이타베이스 트랜잭션의 부분에 대해 결론 내렸다 신호 하면 조정자는 각 참여자에게 트랜잭션 완료를 준비하게끔 'prepare for commit' 메시지를 보냄
		- 메시지 받은 각 참여자는 모두 로그 레코드로 디스크에 강제 출력시키고 'OK' 메시지를 조정자에게 보냄
		- 로그 레코드로 강제 출력시키지 못하거나 기타 다른 이유로 완료할 수 없는 참여자는 'NOT OK' 메시지를 조정자에게 보냄
	- 단계2
		- 조정자가 모든 참여자로부터 'OK' 메시지를 받으면 트랜잭션을 성공적인 실행이기 때문에 조정자는 자신의 로그에 트랜잭션의 최종 상태에 대한 결정으로 'commit'을 기록하고 각 참여자에게 'commit' 메시지를 보냄
		- 참여자는 그 다중 데이타베이스 트랜잭션에 대한 로그에 'commit' 레코드를 기록해 데이타베이스 갱신을 완료
		- 그외 경우, 적어도 하나 트랜잭션이 'NOT OK' 메시지를 보내거나 일정 시간 경과 시까지 응답이 없으면 조정자는 자기 로그에 'rollback'을 기록하고 각 참여자에게 'rollback' 메시지를 보냄
		- 모든 참여자는 트랜잭션에 대해 'rollback' 연산을 수행
	
	- 2단계 완료 규약의 결과 모든 참여 데이타베이스들이 다중 데이타 베이스 트랜잭션에 대해 완료를 하거나 취소 하게 한다
	- 어느 한 참여자 or 조정자가 장애를 일으켰다면 언제라도 트랜잭션이 완료된 상태이거나 취소된 상태로 회복할 수 있다
	- 단계1이 완료되기 전에 일어나는 장애에 대해서는 트랜잭션을 취소하고 단계2 수행 중 일어나는 장애는 트랜잭션을 회복하고 완료할 수 있다.

16. 병행 제어

- 복수 사용자 DBMS
	- 데이터베이스 시스템의 주 목표의 하나는 공용성 -> 여러 사용자가 접근 할 수 있도록 하는 것
	- 병형 데이터베이스라고 함
	- 반드시 병행성을 지원해야 한다
	- 병행성 : 몇 개의 트랜잭션들을 동시 실행시키는 것으로 트랜잭션들의 실행에 있어 시작과 종료가 서로 중복되는 것을 말함
		- 데이터 베이스의 공용도를 높이고, 응답시간을 단축, 시스템 활용도를 증대할 수 있다
	- 인터리브 병행 실행 개념에서 기초되었다
	- 논리적 프로그램 단위 -> 트랜잭션
- 무제어 동시 공용의 문제점
	- 각 트랜잭션 상호 간섭으로 예기지 못한 틀린 결과를 생설할 수 있다
	- 갱신 분실
		- 트랜잭션이 겹처 기록되는 바람에 데이터베이스에 영향을 주지 못하고 분실
	- 모순성
		- 트랜잭션이 일부만 실행시킨 상태에서 다른 트랜잭션 연산이 모든 연산을 마친 경우
		- 두 트랜잭션의 값과 사용자가 원하는 값이 달라지게 됨
	- 연쇄 복귀
		- T1과 T2중 T1이 X값 갱신하고 T2가 X값 갱신후 T1에서 ROLLBACK 발생 -> T2는 이미 갱신 작업 후 시스템을 떠난 상태이므로 복귀 할수 없음

- 트랜잭션 스케줄
	- 충돌 : 두 개의 연산이 각각 상이한 트랜잭션에 속하고 있으며 동일한 데이터 아이템을 처리 대상으로 하고 있고 적어도 하나의 연산은 기록 연산이 되는 경우
	- 트랜잭션의 스케줄 : 트랜잭션들의 연산들을 실행하는 순서
		- 각 트랜잭션 내에 명세된 연산의 선후 관계를 유지해야 된다
	- 직렬 가능성 이론
		- 어떤 스케줄이 정확하고 정확하지 않은 것을 결정해 정확한 스케줄만 허용하는 기법
	- 직렬 스케줄 : 스케줄에 포함된 모든 트랜잭션의 연산들을 각 소속 트랜잭션별로 연속적으로 실행하는 스케줄
		- CPU를 낭비하게되어 일반적으로 사용 않함
	- 비직렬 스케줄 : 인터리브 실행이 포함되어 트랜잭션들을 병행 실행시키는 스케줄
	- 직렬 가능 스케줄 : n개 트랜잭션에 대해 비직렬 스케줄 S가 같은 n개의 트랜잭션에 대한 어떤 직렬 스케줄 S'과 동등하다고 하면 S를 직렬 가능 스케줄이라 한다
	
	- 스케줄 동등과 직렬 가능 스케줄 
		- 두개의 상이한 스케줄로 생성된 데이터베이스의 최종 결과가 같으면 결과 동등이라함 -> 항상 보장하지는 않음
		- 충돌 동등과 충돌 직렬 가능 스케줄
			- 두 스케줄에서 충돌 연산 순서가 같으면 충돌 동등이라 함
			- 서로 다른 트랜잭션에 속하는 두 연산이 동일 데이터 아이템에 접근하고 최소 한 연산이 Write 연산이면 두 연산은 충돌 연산
			- n개의 트랜잭션에 대한 어떤 스케줄 S가 같은 n개의 트랜잭션에 대한 직렬 스케줄 S'와 충돌 동등하다면 S는 충돌 직렬 가능 스케줄
			- 비충돌 연산 원리 : 충돌 연산이 아닌 두 연속 연산의 순서를 교환해도 전체 연산에 영향을 주지 않는 것
			- 충돌 동등 스케줄은 교환 원리를 이용해 직렬 스케줄로 변환 할 수 있다
			- 충돌 동등 스케줄 S에 비충돌 연산의 교환 원리를 적용해 어떤 직렬 스케줄 S'으로 변환시킬 수 있으면 S'와 S는 충돌 동등
		- 뷰 동등과 뷰 직렬 가능 스케줄 
			- 두 스케줄 S와 S'에 포함된 트랜잭션이 모두 같고 다음 조건을 만족하면 뷰 동등 
				- 각 데이터 아이템 X에 대해 스케줄 S에서 X의 초기값을 Ti가 읽는다면 스케줄 S'에서도 X의 초기값을 Ti가 읽어야 함
				- 스케줄 S에서 트랜잭션 Ti가 수행하는 모든 read(x) 연산의 x 값이 트랜잭션 Tj가 수행한 write(x) 연산으로 생성된 값이라면 스케줄 S'에서도 Ti가 수행하는 모든 read(x) 연산의 x값이 트랜잭션 Tj의 write(x)연산으로 생성된 값이어야함
				- 스케주 상 write(x) 연산이 수행되는 각 데이터 아이템 x에 대해 스케줄 S에서 Ti가 write(x)를 마지막으로 실행하면 S'에서도 마지막으로 실행해야 함
				-> 두 스케줄에서 독깥은 값을 읽고 결과를 생성해야 함 
			- 두 스케줄에서 모두 데이터를 읽을 때 같은 데이터 값을 읽어야 하고 기록 할 때도 같은 값을 기록해야 똑같은 뷰를 갖게 됨
			- 트랜잭션 T1, T2 .... Tn을 위한 스케줄 S에 대해 뷰 동등한 직렬 스케줄 S'이 존재할 때 스케줄 S를 뷰 직렬 가능 스케줄 이라함
			- 모든 충돌 직렬 가능 스케줄은 뷰 직렬 가능이지만 역은 성립하지 않는다
		- 스케줄의 직렬 가능성 검사
			- 주어진 스케줄이 직렬 가능 스케줄인가 판단하는 것은 매우 중요
			- 충돌 직렬 가능 성검사
				- 스케줄 S에 포함된 각 트랜잭션 Ti에 대해 선행 그래프에 Ti 노드를 생성
				- S에서 Ti가 write(x)한 x의 값을 Tj가 read(x)를 수행하면 간선 Ti -> Tj를 삽입한다.
 				- S에서 Ti가 read(x)한 뒤에 Tj가 write를 하는 경우 간선 Ti -> Tj 삽입
				- S에서 Ti가 write(x) 한뒤 Tj가 바로 write(x) 하면 Ti -> Tj를 삽입
				- 선행 그래프에 사이클이 없으면 스케줄 S는 충돌 직렬 가능하고 사이클이 있으면 직렬 불가능이다.
				- 트랜잭션 Ti는 Tj보다 선행되어야 한다
			- 직렬 가능성 이용
				- 직렬 스케줄은 서로 다은 트랜잭션들의 연산 사이 인터리빙 없이 실행하는 것
				- 직렬 가능 비직렬 스케줄은 어떠한 정확성도 잃어버리지 않으면서 병행 실행의 이점을 제공

- 로킹 기법
	- Lock의 성질과 타입
	- 로킹 규약	
		- 트랜잭션 T가 데이터 아이템 x에 대해 read, write 연산을 하려면 반드시 먼저 lock 연산을 실행해야 한다.
		- 트랜잭션 T가 실행한 lock에 대해서는 T가 모든 실행을 종료하기 전에는 반드시 unlock 연산을 실행 해야한다.
		- 트랜잭션 T는 다른 트랜잭션에 의해 이미 lock가 걸려 있는 x에 대해 다시 lock을 실행시키지 못한다.
		- 트랜잭션 T는 x에 lock을 자기가 걸어 놓지 않았다면 unlock을 실행시키지 못한다.
	- 공용 로크와 전용 로크
		- lock-S(공용 로크) 
			- 트랜잭션 T가 데이터 아이템 x에 대해 lock-S를 걸면 T는 이 데이터 아이템 x에 대해 판독할 수는 있지만 기록할 수는 없다.
			- x에 대해 다른 트랜잭션이 공용 lock을 동시에 걸 수 있다.
		- lock-X(전용 로크)
			- 트랜잭션 T가 아이템 x에 대해 lock-X를 걸면 T는 아이템 x에 대해 판독과 기록을 모두 할 수 있다.
			- x에 대해 다른 트랜잭션은 lock을 걸 수 없다.
		- lock-S, lock-X, unlock 연산을 구현하는 방법은 각 lock에 세개의 필드<데이타 아이템, lock, 트랜잭션 수>를 만들어 관리 하면 된다
	- 공용 로킹 규약
		- 트랜잭션 T가 데이터 아이템 x에 대해 read 연산을 실행하려면 먼저 lock-S나 lock-X 연산을 실행해야 한다.
		- 트랜잭션 T가 데이터 아이템 x에 대해 write 연산을 실행하려면 먼저 lock-X 연산을 실행해야 한다.
		- 트랜잭션 T가 lock-S나 lock-X 연산을 하려할 때 x가 이미 다른 트랜잭션에 의해 양립될 수 없는 타입으로 lock이 걸려 있다면 모두 풀릴 때까지 기다려야 한다.
		- 트랜잭션 T가 모든 실행을 종료하기 전에는 T가 실행한 모든 lock에 대한 반드시 unlock을 해야한다.
		- 트랜잭션 T는 자기가 lock을 걸지 않은 데이터 아이템에 대해 unlock을 실행할 수 없다.
	- 2단계 로킹 규약
		- 확장 단계 : 트랜잭션은 새로운 lock 연산만 실행할 수 있고 unlock 연산은 실행할 수 없는 단계
		- 축소 단계 : 트랜잭션은 unlock만 실행할 수 있고 일단 unlock 연산을 실행하면 lock연산은 더이상 실행할 수 없는 단계
		- 한 트랜잭션에서 모든 lock 연산들이 첫 unlock 연산 전에 실행되었다면 2단계 로킹 규약을 준수 
		- 만일 어느 한 스케줄이 참여하고 있는 모든 트랜잭션들이 2단계 로킹 규약을 준수한다면 스케줄은 직렬 가능하다
	- 엄밀 2단계 로킹 규약
		- 로킹 2단계뿐 아니라 모든 독점 로크(lock-S)는 트랜잭션이 완료 할 때까지 unlock하지 않고 그대로 유지한다는 것
		- 연쇄 복귀 문제가 일어나지 않는다
	- 엄격 2단계 로킹 규약
		- 모든 로크는 트랜잭션이 완료 될 때까지 unlock되지 않고 로크된 상태로 유지해야만 된다는 것
		- 트랜잭션이 완료하는 순서로 직렬화 될 수 있다

- 교착 상태
	- 모든 트랜잭션들이 실행을 전혀 진전시키지 못하고 무한정 기다리고 있는 상태
	- 교착 상태 발생 조건 : 상호 배제, 대기, 선취 금지, 순환 대기
	- 회피 : 자원 할당 시 교착상태가 일어나지 않도록 알고리즘을 사용해 검사하는 것
	- 예방 : 트랜잭션을 실행시키기 전 교착상태 발생이 불가능하게 만드는 방법
	- 탐지 : 교착 상태가 일단 일어난 뒤 교착 상태 발생 조건을 하나 제거하는 것 
	- 타임 스탬프를 이용해 교착 상태를 회피 하는 방법
		- 각 트랜잭션은 유일하게 식별할 수 있는 식별자 지정됨 --> 트랜잭션의 타임 스탬프
		- 타임 스탬프는 트랜잭션이 실행을 시작하는 순서에 기초한다
			- 트랜잭션이 기다려야 할지, 복귀할 지를 결정하는 데 사용 가능
			- wait-die 기법 : 트랜잭션 Ti가 이미 트랜잭션 Tj까 로크한 데이터 아이톔을 요구할 때 만일 TS(Ti) < TS(Tj)인 경우(Ti의 타임스탬프가 Tj가 작은 경우)에는 기다린다. 그렇지 않으면 Ti는 복귀(die) 했다가 나중에 같은 타임 스탬프를 가지고 다시 시작
			- wound-wait 기법 : 트랜잭션 Ti가 이미 트랜잭션 Tj가 로크한 데이터 아이템을 요구할 때 Ti의 타임스탬프가 Tj것보다 클 경우(TS(Ti) > TS(Tj))가된 경우에는 기다린다. 그렇지 않으면 Tj가 복귀했다가(Ti가 Tj를 상처 입혔기 때문) 나중에 같은 타임스탬프를 가지고 다시 시작
			- 두 기법에는 모두 기아 문제를 발생하지 않는다
			- 언제든지 가장 작은 타임스탬프를 가진 트랜잭션이 있게 되고, 트랜잭션은 어떤 경우에도 복귀되지 않기 때문
		- wait-die 기법에서는 고참 트랜잭션이 신참 트랜잭션을 기다린다
		- wound-wait 기법은 고참 트랜잭션이 신참 트랜잭션을 기다리지 않는다
		- 두 기법의 기본적인 문제는 불필요한 복귀가 자주 일어날 수 있다는 점
	
	- lock을 수행할 수 없는 때 바로 그 트랜잭션을 복귀 시키고 적절한 시간 뒤에 다시 시작하는 방법
		- 불필요한 복귀/재시작이 일어날 수 있다
	- 교착상태가 일어나지 않는 것을 보장하지 못하면 시스템은 교착상태를 탐지하여 처리하는 기법이 있어야 한다
		- 주기적으로 교착 상태를 판단하는 알고리즘이 수행되어야 한다
		- 현재 트랜잭션들이 로그한 데이터 아이템과 현재 로크 요청이 대기 중에 있는 데이타 아이템에 대하나 정보를 유지해야 한다
		- 이 정보를 사용해 시스템이 교착상태에 들어가 있는가를 판단할 수 있는 알고리즘이 있어야 한다
		- 교착 상태에 있다고 판단되었을 때 교착상태로부터 회복할 수 있어야 한다
		
	- 교착 상태를 탐지하는 간단한 방법은 대기 그래프를 구축하는 것
		- 대기 그래프에는 스케줄 상 현재 실행 중인 각 트랜잭션에 대해 하나의 노드가 만들어 진다
		- 현재 트랜잭션 Tj가 로크한 데이터 아이템 x를 트랜잭션 Ti가 로크하기 위해 기다리고 있으면 Ti->Tj를 첨가시킨다
		- 구축된 대기 그래프에 사이클이 생성되면 교착 상태가 발생했다고 판단
		- 하지만 교착 상태를 검사하는 시기에 문제가 있다
		- 교착상태가 탐지되면 관련된 트랜잭션 하나를 선정해 취소시키고 그 트랜잭션에 의해 변경된 데이타 아이템들은 원상태로 복귀나 회복
		- 취소시킬 트랜잭션으로 작업이 가정 적게 수행된 트랜잭션이 선정되는 것이 효율적! 기아 문제를 일으켜서는 안됨!
	
- 로킹 단위
	- 로킹 단위 : 로킹의 대상이 되는 데이타 객체 크기
		- 병행 제어의 데이타 단위가 된다
		- 로킹 단위가 크면 병행성 수준이 낮아지는 반면 병행 제어 기법은 간단
		- 로킹 단위가 작으면 병행성 수준은 높아지나 로크 수가 많아지게 되어 관리가 복잡해진다
	- 다중 단위 로킹 계층 트리 : 데이터 베이스 - 구역 - 파일 - 레코드
	- 병행성 수준을 감소시키지 않기 위해 필요 이상의 크기를 로크하지 않아야 한다
	- 다중 단위 로킹을 지원하기 위해서는 데이타 레코드들을 여러 타입의 논리적 크기로 정의할 수 있어야 하고 작은 단위는 상위 큰 단위에 포함시킬 수 있어야 한다
	- 2단계 로킹 규약에 의해서 트랜잭션이 노드 N을 X나 S 타입으로 로크했다면 모든 자손 노드들까지도 같은 타입으롤 로크했다는 것을 의미, 명시적으로 로크할 필요는 없음
	
	- 의도형 로크 : 로크의 기능 확장
		- 어떤 노드에 의도형 로크가 걸리게 되면 노드의 자손 노드 중 명시적 노크가 걸려있음을 의미
		- 원하는 목표 노드를 명시적으로 로크하기 전 그 노드의 모든 선조 노드들에 먼저 걸어야 한다
			- 전체를 순회할 필요 없이 루트에서 목표 노드 N까지의 경로만 순회하면 된다 -> 순회하는 과정에서 트랜잭션은 의도형 로크를 걸게 된다
		- IS(의도 공용)로크 : 자손 노드를 S타입 로크로 걸겠다는 의미
		- IX(의도 전용)로크 : 자손 노드를 X타입이나 S타입 로크로 걸겠다는 의미
		- SIX(공용 의도 전용) 로크 : 이 노드를 루트로 하는 서브트리가 명시적 S 타입 로크로 걸려있는데 자손 노드를 명시적으로 X타입 로크로 변경하겠다는 의미
		
	![ex_screenshot](/res/db35.png)
	- 다중 단위 로킹 규약 : 다중 단위 지원 로킹 기법에서 직렬 가능성 보장
		- 로크의 양립성이 준수 되어야 한다
		- 로크는 반드시 트리의 루트부터 걸어야 한다
		- Ti가 노드 N의 부모 노드를 현재 IX나 IS로 로크했다면 Ti는 노드 N을 S나 IS로 로크할 수 있다
		- Ti가 노드 N의 부모 노드를 현재 IX나 SIX로 로크했다면 Ti는 노드 N을 X, SIX, IX로 로크할 수 있다
		- Ti가 어떤 타입의 unlock 연산도 실행한 적이 없으면 lock을 실행할 수 없다
		- Ti가 로크한 노드 N의 자손 중 Ti에 의해 로크된 노드가 없을 때 Ti는 노드 N을 unlock 할 수 있다
		
	![ex_screenshot](/res/db36.png) 
	
- 타임 스탬프 순서 기법
	- 트랜잭션을 비직렬 즉, 인터리브드 방식으로 실행한 것이 타임스탬프 순서대로 트랜잭션을 실행한 직렬 스케줄의 결과와 항상 같게되는 것을 보장하는 것
	- 타임 스탬프는 시스템이 트랜잭션을 유일하게 식별하기 위해 부여한 식별자
	- 통상적으로 타임 스탬프 값은 순서대로 부여되기 때문에 트랜잭션의 실행 시작 시간으로 생각할 수 있음
	- 타임 스탬프 생성 방법
		- 논리적 계수 : 트랜잭션이 시스템에 들어올 때마다 계수를 증가시켜 트랜잭션의 타임스탬프 값으로 부여하는 것
		- 시스템 클록 : 트랜잭션이 시스템에 들어오면 시스템 클록의 값을 트랜잭션의 타임스탬프 값으로 부여하는 것
	- 타임 스탬프를 이용해 병행 제어 하는 방법은 트랜잭션들이 타임스탬프 순서에 따라 실행된 것과 같도록 비직렬 스케줄을 만드는 것
	- 트랜잭션의 타임스탬프가 직렬 가능성을 결정!!
	- 타임 스탬프 순서 기법에서는 스케줄이 트랜잭션의 타임 스탬프 순서로 정해지는 직렬 스케줄과 동등함으로 직렬 가능한 것
	- 타임 스탬프 순서와 동등한 스케줄을 보장하기 위해서 둘 이상의 트랜잭션이 접근하는 각 데이타 아이템들에 대해 트랜잭션의 접근 순서가 타임스탬프 순서에 의한 직렬 가능성을 위반하지 않아야 한다
	- 다음과 같은 타임 스탬프 값을 유지해야 한다
		- read_TS(x) : 데이타 아이템 x의 판독 타임스탬프로 read(x)를 성공적으로 수행한 트랜잭션 타임 스탬프 중 제일 큰값
		- write_TS(x) : 데이타 아이템 x의 판독 타임스탬프로 write(x)를 성공적으로 수행한 트랜잭션 타임 스탬프 중 제일 큰값
		- 새로운 read나 write 명령문이 실행될 때마다 갱신된다
		- 연산 실행 전 타임 스탬프 순서를 위반하지 않는지 검사 -> 위반한다면 Ti는 실행 취소, 갱신한 것은 모두 원상 복귀 -> 연쇄 복귀 문제있음
	- 타임스탬프 순서 규약 : read나 write 연산을 타임스탬프 순서대로 실행되게 보장하는 것
		- 트랜잭션 Ti가 read(x) 수행 시 : 
	   	- TS(Ti) < write_TS(x)이면 read(x)를 거부하고 Ti를 취소시켜 복귀시킨다. -> 타임 스탬프 순서 위반(Ti가 접근 전 이미 x 값 변경됨)
  	 	- TS(Ti) >= write_TS(x)이면 read(x)를 허용하고 read_TS(x)는 TS(Ti)와 현재 read_TS(x)중 큰 것으로 설정
 		- 트랜잭션 Ti가 write(x) 수행 시:
   		- TS(Ti) < read_TS(x)이면 write(x)를 거부하고 Ti를 취소시켜 복귀시킨다. -> 타임 스탬프 순서 위반(x값을 먼저 판독 했기 때문)
   		- TS(Ti) < write_TS(x)이면 write(x)를 거부하고 Ti를 취소시켜 복귀시킨다. -> 타임 스탬프 순서 위반 
   		- TS(Ti) >= write_TS(x) , TS(Ti) >= read_TS(x)이면 write(x)를 허용하고 wtrie_TS(x)는 TS(Ti)로 고정 
		- 기록 연산이나 판독 연산 수행하다 실패하고 복귀된 트랜잭션은 새로운 타임 스탬프를 부여받아 재실행을 시도 해야함
		- 타임 스탬프 순서 규약은 2단계 로킹 규약과 같이 스케줄의 직렬 가능성을 보장
		- 타임 스탬프 순서 규약은 충돌 직렬 가능성을 보장 한다 -> 모든 충돌 연산들이 타임 스탬프 순서대로 실행
		- 교착 상태가 발생하지 않지만 계속 취소, 시작되는 경우 순환적 재시작 문제가 발생되고 연쇄 복귀 문제도 일어남
	- 토마스 기록 규칙
		- 트랜잭션 Ti가 read(x) 수행 시 : 
	   	- TS(Ti) < write_TS(x)이면 read(x)를 거부하고 Ti를 취소시켜 복귀시킨다. -> 타임 스탬프 순서 위반(Ti가 접근 전 이미 x 값 변경됨)
  	 	- TS(Ti) >= write_TS(x)이면 read(x)를 허용하고 read_TS(x)는 TS(Ti)와 현재 read_TS(x)중 큰 것으로 설정
 		- 트랜잭션 Ti가 write(x) 수행 시:
   		- TS(Ti) < read_TS(x)이면 write(x)를 거부하고 Ti를 취소시켜 복귀시킨다. -> 타임 스탬프 순서 위반(x값을 먼저 판독 했기 때문)
   		- TS(Ti) < write_TS(x)이면 Ti의 wirte(x)를 실행한 것으로 간주하고 무시
   		- TS(Ti) >= write_TS(x) , TS(Ti) >= read_TS(x)이면 write(x)를 허용하고 wtrie_TS(x)는 TS(Ti)로 고정
		- 토마스의 기록 규칙은 트랜잭션이 무용의 write 연산을 시도할 때 그 write 연산을 삭제하는 것
		- 트랜잭션의 수정은 다른 규약으로 직렬 불가능한 스케줄을 직렬 가능 스케줄로 만들 수 있게 해준다 

- 다중 버전 병행 제어
	- 데이타 아이템 값이 변경될 때 옛날 값을 보관시키는 방법 -> 하나의 데이타 아이템에 대해 여러 버전의 값을 유지
	- 트랜잭션이 한 데이타 아이템에 접근 시 트랜잭션의 타임스탬프에 접근하려는 데이타 아이템의 타임스탬프를 비교
	- read_TS(xk) : 버전 xk를 성공적으로 판단한 트랜잭션 중 제일 큰 타임스탬프
	- write_TS(xk) : 버전 xk를 생성한 트랜잭션의 타임 스탬프
	- Ti가 wirte(x) 연산 수행하며 x의 새로운 버전 x(m+1) 생성 write_TS(x(m+1))과 read_TS(x(m+1))은 TS(Ti) 값으로 설정
	- Tj가 버전 xk의 값을 판독하게 되면 read_TS(xk)는 현재의 read_TS(xk)와 TS(Tj)중 큰 값으로 설ㅈ렁
	- 다중 버전 타임 스탬프 규약
		- 트랜잭션 Ti가 read(x)연산을 요청하고 x의 모든 버전 중 버전 xk의 write_TS(xk)가 가장 크며 write_TS(xk)<=TS(Ti) 이면 버전 x값을 판독하고 read_TS(xk)는 현재의 read_TS(xk)와 TS(Ti)중 큰 값 설정 -> 가장 최신 버전의 데이터를 판독
		- 트랜잭션 Ti가 write(x)연산을 요청하고 x의 모든 버전 중 버전 xk의 write_TS(xk)가 가장 크며 동시에 write_TS(xk)<=TS(Ti)라 할 때 read_TS(xk)>TS(Ti)이면 트랜잭션 Ti는 취소되며 복귀된다, 아닌 경우 x의 새로운 버전 x(m+1)을 생성하고 read_TS(xm+1)와 write_TS(xm+1) 값을 TS(Ti) 값으로 설정 -> 트랜잭션이 너무 늦게 기록 하려면 강제로 복귀 된다
	- 판독 요청을 거절하지도 대기시키지도 않는다 
	- 판독 연산이 주류를 이루는 데이타베이스 시스템에서 이점이 된다 
	- 트랜잭션들 간 충돌 문제는 대기가 아니라 복귀로 해결 -> 비용이 많이 들고 연쇄 복귀가 발생할 수 있다

- 낙관적 병해 제어
	- 아무런 검사를 실시하지 않고 일단 트랜잭션을 실행하겠다는 것, 갱신은 실행이 다 끝날 때까지 반영시키지 않는다
	- 모든 갱신은 트랜잭션을 위해 유지되는 작업 구역의 지역 사본에만 반영, 실행이 끝나면 확인 단계가 시작되는 시점에 갱신 연산들이 직렬 가능성에 위반하는지 검사 -> 지역 사본과 함께 필요 정보가 관리되어야 함
		- 위반하지 않으면 트랜잭션은 실행, 데이타베이스는 지역 사본과 같은 값으로 갱신
		- 위반 시 트랜잭션은 복귀하고 다시 시작
	- 판독 단계
		- 트랜잭션이 필요 데이타 아이템을 판독해 트랜잭션 작업 구역에 지역 사본으로 만들어 관리
		- 트랜잭션의 모든 갱신은 사본에 대해서만 수행, 데이타베이스에 대해서 수행하지 않음
	- 확인 단계
		- 사본에 반영된 트랜잭션 실행 결과를 데이타베이스에 반영할 때 직렬 가능성에 위반되지 않는다는 것 확인
	- 기록 단계 
		- 확인 단계 통과 시 트랜잭션 실행결과는 실제 데이터 베이스에 반영
		- 아닌 경우 실행 결과는 취소되고 트랜잭션은 복귀후 다시 실행
	- 모든 검사를 나중에 한꺼번에 하자가 기본 아이디어!
	- 3가지 타임 스탬프
		- Start(Ti) : 트랜잭션 Ti가 판독 단걔에 들어가면서 판독을 시작한 시간
		- Validation(Ti) : 트랜잭션 Ti가 판독 단계를 끝내고 환인을 시작한 시간
		- Finish(Ti) : 트랜잭션 Ti가 최종 기록 단계를 완료한 시간
	- 확인 작업을 위해 트랜잭션의 판독 집합과 기록 집합을 유지해야 한다
	- Ti가 확인 과정을 통과하기 위해서 TS(ti) < TS(Tk)의 관계에 있는 모든 트랜잭션 Ti에 대해 다음 조건 중 하나를 만족해야 함
		- Finish(Ti) < Start(Tk), Ti의 기록 단계가 Tk의 판독 단계 시작 전 완료 되었음
		- Tk가 확인 단계 시작전 Ti는 기록 단계를 완료하였으며 Tk의 판독 집합과 Ti의 기록 집합 사이에 아무런 공통 데이타 아이템이 없음
		- Tk의 판독 단계가 끝나기전 Ti는 판독 단계를 완료, Tk의 ㄱ록 집합과 판독 집합이 Ti의 기록 집합과 아무런 곹오 데이터 아이템이 없음
- 팬텀 충돌 
	- 팬텀 투플 : 데이타베이스에 삽입 되려는 가상의 투플
	- 팬텀 투플에 대해 서로 충돌하는 것이 팬텀 충돌 
	- 해결 방법
		- 로킹 단위 확대
			- 로킹 데이타 단위를 투플이 아니라 릴레이션으로 확대
			- T1은 공용 로크, T2는 전용롤크 걸어야 되기에 로킹 충돌이 일어남 => 실제 충돌 
			- 로킹 단위가 커짐으로 병행성을 감소
		- 인덱스 로킹 
			- 투플을 삽입하려면 릴레이션으로 만들어진 모든 인덱스도 갱신 
			- 로킹 규약을 인덱스에 사용하면 팬텀 충돌 제거 
			- 릴레이션에 인덱스가 만들어진 이점을 이용해 팬텀 충돌을 인덱스 버킷에 대한 로킹 충돌로 해결하려는 방법
			- 규약
				- 모든 릴레이션은 적어도 하나의 인덱스를 가져야 함
				- Ti는 접근하려는 릴레이션 투플 t에 대해 포인터가 있는 인덱스 버킷에 S타입 로크 걸었을 때만 t에 대해 S타입 로크를 걸 수 있다
				- Ti는 갱신하려는 릴레이션 투플 t에 대한 포인터가 있는 인덱스 버킷에 x 타입로크 걸었을 때만 t에 대해 X타입 로크를 걸 수 있다
				- Ti는 투플 삽입 전 릴에시션의 모든 인덱스를 갱신해야 하고 갱신하려는 모든 인덱승 버킷에 X타입 로크를 걸어야 한다
				- 로킹은 2단계 로킹 규약에 따라야 한다
- 삽입 / 삭제 연산과 병행 제어
	- 삽입, 삭제 연산은 모두 전용 로크(lock-X)를 사용해야 되고 타임 스탬프 규약에도 두 연산을 write 연산과 같이 취급하고 검사해야 한다.

17. 무결성과 보안

17.1 무결성 서브시스템
- 데이터베이스의 무결성 : 데이터의 정밀성이나 정확성을 의미, 데이터베이스에 저장된 데이터 값을 정확하게 유지하는 데 있다
- 일관성 : 공용 데이터베이스에서 병행 트랜잭션들의 상호 작용으로부터 같은 의미를 나타내는 두개의 데이타 값이 서로 다르지 않도록 하여 의미상의 모순이 없도록 하는 것
- 무결성 서브 시스템의 주요 기능은 무결성 규정을 관리 유지하고 트랜잭션이 수행하는 갱신 연산이 무결성 규정에 위반되지 않는지 검사 
	- 위반 하는 경우 연산을 취소시키거나 거부하여 무결성이 파괴되는 것을 예방하는 것
	
![ex_screenshot](/res/db37.jpg) 

17.2 무결성 규정
-  무결성 규정에는 검사해야 할 조건, 검사를 수행해야 될 시기, 위반이 탐지되었을 때 취해야 될 조치가 명세되어야 한다
	- 규정 이름 : 규정을 참조할 때 사용하는 식별자
	- 검사 시기 : 트랜잭션의 접근 유형 및 데이타와 함께 검사해야 할 시기를 명세
	- 제약 조건 : 데이타가 만족해야 될 제약 조건
	- 위반 조치 : 제약 조건 검사 결과, 위반이 발견되었을 때 취해야 될 대응 조치를 명세
<pre><code>
R1 : AFTER UPDATING STUDENT.Year:
	CHECK(STUDENT.Year > 0)
	ELSE
		DO;
			PRINT "R1 violated";
			REJECT;
		END;
</code></pre>
- R1이 무결성인 규정은 AFTER절, CHECK절, ELSE 절로 되어 있다
	- AFTER 절은 검사 시점 명시
	- CHECK절은 갱신 연산 뒤에도 만족해야 될 제약 조건을 나타냄
	- ELSE절은 검사 실패 시 규정 R1이 위반되었다는 것 프린트, 갱신 연산을 거부한다는 것 명세
- 명세된 규정들은 무결성 제어 서브시스템에 의해 시스템 카탈로그 OR 데이터 사전에 저장
- 집행이 일반 사용자에 의하지 않고 시스템에 자동적으로 시행되는 장점이 있다
- 카탈로그에 집중되어 있기 때문에 전체를 파악하기 쉽고 필요시 변경하기가 용이하다
- 중복성이나 모순성을 탐지하기 쉬울뿐 아니라 효율적이고 전체 시스템적인 규정 시행 방법을 수립할 수 있다
- 무결성의 수정이나 삭제도 지원할 수 있어야 한다

- 무결성 규정의 유형
	- 도메인 무결성 규정 : 주어진 애트리뷰트의 값이 애트리뷰트가 정의된 도메인에 속한 값이어야 한다는 것을 규정, 삽입이나 갱신 연산에 적용
		- 단순한 값의 검사뿐아니라 널 값에 대한 명세, 일자와 같은 복합 도메인, 도메인 자체가 포함하고 있는 기본 순서에 대해 명세할 수 있어야 한다
	- 릴레이션 무결성 규정 : 릴레이션을 조작하는 과정에서 의미적 관계를 명세한 것, 삽입이나 삭제 OR 갱신과 같은 연산을 수행하기 전과 후에 대한 관계를 규정한 것
		- 상태 제약 : 데이타베이스가 일관성 있는 상태가 되기 위한 조건을 명세한 것
			- 데이타베이스 상태 : 어느 특정 시점에 데이타베이스에 저장되어 있는 데이타 값
			- 각 데이타베이스 상태가 모두 만족해야 하는 규정, 정적 제약의 성질을 가진다
			- 유효한 값에 대한 도메인 제약, 유일성을 유지해야 되는 키 애트리뷰트 제약, 널 제약, 참조 무결성 제약 등 적용 범위가 광범위
		- 과도 제약 : 데이타베이스의 한 상태에서 다른 상태로 변환되는 과정에 적용될 수 있는 규정
			- 데이타베이스 상태의 변환 직전과 직후의 비교가 관련
			- 데이타베이스 상태의 변경 전후가 모두 만족해야 되기때문에 동적 제약 성질을 가진다
		- 집합 제약 : 어떤 투플 집합 전체에 관련된 규정
		- 투플 제약 : 처리되고 있는 투플에만 적용되는 규정
		- 즉시 제약 : 삽입이나 삭제 OR 갱신 연산이 수행된 즉시 적용되는 규정
		- 지연 제약 : 트랜잭션이 완전히 수행된 뒤 적용되는 규정
			- 지연 규정은 검사 시기가 WHEN COMMIT으로 표현된다 ( 트랜잭션이 완전히 끝난 뒤 적용시켜야 하기 때문 )

- 무결성 규정의 명세
	- 트리거
		- 메시지를 보내거나 어떤 값을 갱신하게 되면 또 다른 값을 자동적으로 갱신하게끔 어떤 프로시저를 기동시키는 것 등 이러한 것을 트리거로 구현할 수 있다
		- 트리거 조건이 만족되는 경우 취해야 되는 조치를 명세한다
			- 조건을 프레디킷 형식으로 명세, 참이 될 때 조치가 유발, 기동된다
			- 특정 조건이 만족되면 활동을 시작하는 디먼 개념과 비슷
		- DEFIND TRIGGER 트리거 이름 ON 트리거 조건 : 명령문 
		<pre><code>
			DEFINE TRIGGER STUDENTS
				ON INSERTION OF STUDENT:
				(UPDATE DEPARTMENT
				SET			Tstdn = Tstdn+1
				WHERE 	Dno = NEW_STUDENT.Dno);
			DEFINE TRIGGER STUDDEL
				ON DELLTION OF STUDENT:
				(UPDATE DEPARTMENT
				SET			Tstdn = Tstdn-1
				WHERE 	Dno = OLD_STUENT.Dno);
		</code></pre>
		
	- SQL에서의 무결성 규정
		- 도메인 제약 조건
			- [CONSTRAINT constraint] CHECK (cond-exp)
			<pre><code>
			CREATE DOMAIN DYEAR SMALLINT
			CONTRAINT CONST-YEAR
			CHECK(VALUE IN (1,2,3,4));
			</code></pre>
		- 기본 테이블 제약 조건
		<pre><code>
			[CONSTRAINT constraint]
				{PRIMARY KEY | UNIQUE} (column-list) | [CONSTRAINT constraint]
				FOREIGN KEY (column-list)
				REFERENCE base-table[(column-list)]
								[ON DELETE {NO ACTION|CASCADE}]
								[ON UPDATE {NO ACTION|CASCADE}]
				| [ONSTRAINT consotraint] CHECK (cond-exp)
		</code></pre>		
		<pre><code>
			CREATE TABLE ENROL
				(Sno DSNO NOT NULL,
				Cn DCNO NOT NULL,
				Grade INTEGER NOT NULL,
				PRIMARY KEY(Sno, Cno),
				FOREIGN KEY (Sno)	REFERENCE STUDENT
								ON DELETE CASCADE
								ON UPDATE CASCADE
				FOREIGN KEY (Cno)	REFERENCE COURSE
								ON DELETE CASCADE
								ON UPDATE CASCADE
				CHECK(Grade >=0 AND Grade <= 100);
		</code></pre>
		- 일반 제약 조건
			- CREATE ASSERTION contraint CHECK(cond-exp);
			<pre><code>
			CREATE ASSERTION CONST_YEAR
					CHECK ((SELECT MIN(STUENT.Year) FROM STUDNET) >0 );
			</code></pre>
			- DROP ASSERTION constraint;
			<pre><code>
			SET CONSTRAINTS constraint_list {DEFERRED | IMMEDIATE}
			</code></pre>
			
- 보안의 개념
	- 데이터베이스 보안은 불법적인 데이터의 폭로나 변경, 파괴로부터 데이터베이스를 보호하는 것을 말함
		- 법적, 윤리적 통제 : 보안 환경 조성에 큰 영향을 줌
		- 행정, 관리적 통제 : 직원과 조직을 감독하여 데이터베이스 오용을 탐지하고 방지
		- 물리적 통제 : 물리적이고 적극적으로 보안 위반을 예방하고 탐지하는 것
		- 기술적 통제 : HW, SW, DB의 기술적 통제를 통한 보안
		
- 데이터베이스 보안의 구현
	- 데이타베이스 접근 제어 : 권한을 부여 받은 사용자에게만 데이터를 이용할 수 있게 하는 것
		- 데이타 검색 제어는 데이타 프라이버시를 유지
		- 데이터 갱신 제어는 정확성을 유지
		- 누가 무슨 데이타에 무슨 연산을 수행하는가를 제어하는 기법을 요구
	- 데이타베이스 접근 제어 모델	
		- 사용자 식별, 데이타 식별, 식별된 데이타에 식별된 사용자가 수행할 수 있는 연산들을 명세하는 것
		- 신분 증명과 권한 부여 두단계로 이루어짐
		- 사용자, 데이타, 연산 요구들을 권한부여 테이블에 대응시켜 요청한 연산을 허가할 것인지 결정
		- 사용자 신분 확인후 권한 검사를 확인
		- 연산 실행 동안 메인 메모링레 권한 테이블을 설정
		- 연산 요청을 할 때마다 시스템을 내부 테이블을 검사하고 사용자 활동에 대한 로그를 유지
		- 로그는 사용자 활동을 감시하는 감시 파일이됨
		- 권한부여 검사는 사용자가 프로그램이나 스키마 기동시키거나 검색이나 갱신명령 요청 시 수행
		
	![ex_screenshot](/res/db38.png)
	
	- 보안 서브시스템
		- 권한부여 규정
			- 사용자 프로파일 : DB 접근하는 각 사용자에 대해 접근할 수 있도록 권한이 부여된 데이타 객체와 연산에 대한 정보를 저장한 레코드
			- 권한 부여 테이블 : 시스템은 모든 사용자에 대한 프로파일을 하나의 테이블로 종합한 것
			- 권한부여의 대상이 되는 데이타 객체 크기는 시스템이 얼마나 복잡한 관리 능력을 가지고 있느냐에 달려 있다
			- 권한부여 대상이 되는 데이타 객체 명세 방법
				- 객체 이름 명세 : 데이타 객체를 단순히 객체ㅔ이름으로 명세 -> 컴파일 시간에 검사
				- 데이타 값 명세 : 데이터 객체를 어던 조건으로 명세하여 조건을 만족하는 레코드나 데이타 필드를 권한 부여 대상으로 정의하는 것 -> 내용 의존 제어로 실행 시간에 검사
				- 통계적 명세 : 데이터 객체 명세에 집계 연산자가 포함된것 -> 객체 이름 명세나 값 의존 명세에 적용 가능
				- 프로그램 : DB를 접근하는 프로그램에 대해 명세하는 것
				- 권한부여 테이블 : 접근 통제의 가장 중요한 데이타 객체는 권한부여 테이블 자체!! -> 테이블 갱신 연산은 DBA 제외하고 허용 불가
		- 권한 검사자 
			- 권한부여 테이블로 명세된 규정은 최고의 특권과 보호를 받는 권한 검사자, 즉 보안 집행기에 의해 시행된다
- 권한 부여 명세 기법
	- 뷰 기법 : 그 정의 자체를 권한부여 기법으로 사용할 수 있다
		- 보안에 민감한 데이타를 권한이 없는 사용자로부터 은닉시킬 수 있어 불법적 접근을 예방할 수 있다
		- 갱신이나 삽입, 삭제와 같은 연산에 제한이 있다
		- 허용된 데이타에 연산을 제한할 수 있는 방법은 아니다
	- GRANT/REVOKE 기법
		- DBA 권한 -> 권한 일부를 다른 사용자에게 부여할 수 있다
		- GRANT 권한 ON 데이타 객체 TO 사용자 [WITH GRANT OPTION]
		- DBMS는 항상 권한부여가 어떻게 파급되어 가는지 파악하고 있어야 한다
		- DBA : GRANT INSERT, DELETE ON STUDENT TO U1; -> U1은 삽입과 삭제 권한을 갖게 된다
		- DBA : GRANT SELECT ON STUDENT TO U2 WITH GRANT OPTION; -> U2은 검색 권한을 갖고 다른 사용자에게 권한을 부여 할 수 있다
		- REVOKE [GRANT OPTION FOR] 권한 ON 데이타 객체 FROM 사용자 {CASCADE, RESTRINCT};
		- DBA : REVOKE SELECT ON STUDENT FROM U2 CASCADE; -> 취소는 CASCADE에 따라 자동적으로 파급, GRNAT OPTION FOR가 사용되면 다른 사용자에게 권한을 부여할 수 있게 한 권한 자체를 취소하려는 것

	- 필수 접근 제어
		- 각 데이타 객체에 일정한 비밀 등급을 매기고 각 사용자도 일정한 허가 등급을 지정해 데이터 객체가 적절한 허가 등급을 가진 사용자에 의해서만 접근 되도록 하는 필수 접근 제어 기법

- 통계 데이타베이스 
	- 통계적 요약 정보만 제공하는 데이타베이스
	- 개인의 정보가 유도될 수 없도록 방지하는 데 목적이 있디
	- 통계질의문 : 통계 집계 함수가 들어간 질의문만 허용하는 질의문
		- 계획적으로 잘 스케줄하면 개인 정보를 유도해 낼 수 있다 
	- 어떤 질의문의 실행 결과에 관련된 레코드 수가 어떤 기본수 b보다 작은 경우에는 응답을 허용하지 않아야 한다 
		- n-b(n은 데이타베이스 전체 레코드 수)보다 큰 경우에도 응답을 거부해야 한다
		- 응답 가능 통계 질의문은 결과에 관련된 레코드 수 c가 b<=c<=n-b의 범위에 들ㅇ러가야 한다
	- 개인 추적자 : 특정 개인의 정보를 추적해서 알아내게 해주는 프레디킷개인 추적자
	- 일반 추적자 : 응답이 허용되지 않는 임의의 프레디킷을 포함하는 질의문에 대해 응답을 유도해 낼 수 있는 프레디킷
		- 응답이 허용되지 않는 어떤 특정 프레디킷을 가진 질의문에 대해서만 응답을 유도할 수 있다
		- 어떤 프레디킷 결과에 속하는 레코드 수 c가 2b<= c <= n-2b에 속하면 일반 추적자
	- 통계 데이타베이스의 보안 문제는 이러한 일반 추적자를 거의 항상 찾아낼 수 있고 개인 추적자도 찾을 수 있다는 것에 있다
	
18. 분산 데이타베이스
- 분산 데이타베이스 시스템 : 지리적(물리적)으로 분산된 데이타베이스 시스템을 사용자가 마치 하나의 중앙 데이타베이스 시스템으로 생각하고 사용할 수 있는 시스템
	- 분산 처리기 : 지리적으로 분산되어 있는 컴퓨터시스템
		- 지역에서 필요한 데이터 처리를 지원할 수 있는 지역 컴퓨터로 데이터베이스를 자치적으로 관리할 수 있는 데이터베이스 시스템을 가짐
	- 분산 데이타베이스 : 지리적으로 분산되어 있는 지역 데이터베이스
		- 각 처리기와 연관되어 지역 처리를 지원
	- 컴퓨터 네트워크 or 통신 네트워크 : 지리적으로 분산된 지역 처리기들을 네트워크로 연결시켜 자원을 공유하게함으로써 논리적으로 하나의 시스템과 같은 기능을 할 수 있꼐 하는망	
		- 네트워크 상에 있는 모든 지역 처리기들은 특정 통신 규약에 따라 테이타를 전송하고 수신한다
		
	- 여러 개의 지역 시스템으로 구성되지만 자치성을 가지면서도 네트워크로 연결된 전체 시스템의 한 구성원으로 범 시스템적인 규정에 의해 통제 받는다
	- 네트워크 측면에서 보면 전역 트랜잭션을 위해 컴퓨터 네트워크 상에 분산된 노드의 집합이라 정의할 수 있다
		- 각 노드는 지역 사이트로서 하나의 자치적인 중앙 데이터베이스 시스템을 의미
		- 자치성 : 자기 자신의 데이타베이스, 데이타베이스 관리 시스템, 컴퓨터, 사용자 터미널들을 가지고 운영한다는 것
		- 전역 트랜잭션 : 네트워크를 통해 다른 원격 사이트의 데이타베이스를 접근해서 처리해야 되는 트랜잭션(분산 트랜잭션)
		- 지역 트랜잭션 : 다른 사이트를 접근하지 않고 트랜잭션이 제출된 사이트의 데이타베이스만을 접근해 처리될 수 있는 트랜잭션
	
	- 분산 데이터베이스 시스템 목표
		- 기존 데이터 독립성 + 분산 데이타 독립성
		- 위치 투명성 : 사용자나 응용프로그램이 접근하려는 데이타가 어디에, 즉 어떤 사이트에 저장되어 있는지 알아야 될 것을 요구하지 않는 것
			- 데이타의 모든 위치 정보는 시스템이 카탈로그에 관리하고 데이터 접근에 대한 요구가 있을 때 이 정보를 제공
			- 다른 사이트의 데이타에 대한 접근 요청
				- 데이타를 자기 사이트로 가져와 지역 처리
				- 데이터 접근 요청을 하는 트랜잭션을 데이타가 있는 사이트로 보내 처리하여 결과만 자기 사이트로 가져오기
				- 두 방법을 종합해 처리
			- 응용 프로그램의 논리가 간단하게 되고 이용 빈도에 따라 한 사이트에서 다른 사이트로 데이타 저장 위치를 변경하더라도 응용 프로그램에 아무런 영향을 주지 않는다
		- 중복 투명성
			- 여러 사이트를 분산 시키는 경우에 데이타를 전혀 중복되지 않게 분할해 저장할 수 있고 중복되게 저장할 수 있다
			- 데이타 중복 : 하나의 논리적 데이타 아이템에 대해 물리적 값이 여러 상이한 사이트에 저장되는 것 -> 신뢰성과 가용성 증진
			- 값 갱신 시 모든 사본에 대해 갱신이 전부 파급되어야하고 저장 공간도 더 소요되는 단점이 있다
			- 완전 중복 : 둘 이상의 사이트가 똑같은 데이타베이스를 저장하고 있는 
			- 부분 중복 : 데이타베이스의 일부만 중복 저장된 ㅣ경우
			- 중복 투명성 : 어떤 데이타가 중복 저장되어야 하는지, 중복된 데이타는 어디에 저장되어야 하는지, 중복된 데이타의 검색과 갱신을 위한 데이타 위치 식별이나 관리 등에 대해 사용자는 전혀 신경쓰지 않아도 되는 것
		- 단편화 투명성
			- 단편화는 성능, 가용성, 신뢰성의 이유로 수행된다
			- 단편화는 데이타 중복의 단편을 보완할 수 있다
			- 단편화를 하면 각 사본은 릴레이션 전체가 아니라 일부가 되어 저장 공간이 적게 들고 관리해야 될 데이타 아이템 수도 적어진다
			- 단편을 이용해 처리해야 할 질의문 처리 전략이 있어야 한다
				- 전역 질의문을 여러 개의 단편 질의문으로 변환해 처리할 수 있는 기법
			- 데이타 단편화에 대해 전혀 인식하지 않고 데이타에 접근할 수 있어야 된다는 것이 핵심
		
	- 분산 데이타베이스 시스템의 장단점
		- 장점
			- 지역 자치성 : 중앙 시스템에 의존하지 않고 그 지역 고유의 데이타 관리에 대한 제어를 자치적으로 행사할 수 있게 한다
			- 점증적 시스템 용량 확장 : 서비스를 중단 시키지않을 수 있다
			- 신뢰성과 가용성 : 한 사이트의 장애나 개별적 장애가 있더라도 축소되긴하자 기능을 계속 수행할 수 있다
				- 중앙 시스템보다 높은 신뢰성을 제공
				- 중복되어 있는 사본 하나만 접근할 수 있어도 그 데이타 객체에 접근할 수 있기에 가용성이 증가된다
				- 회복용으로도 사용 가능
				- 신뢰성 : 주어진 시간 간격 동안 시스템이 장애가 일어나지 않을 확률
				- 가용성 : 주어진 어느 특정 시간에 시스템이 장애 없이 운용되고 있을 확률
			- 효용성과 융통성
				- 데이터 이용도에 따라 가장 많이 사용하는 사이트에 분산 저장하므로써 응답 시간과 통신비용을 줄일 수 있다
				- 동적으로 데이터를 이동시키거나, 사본을 더 늘이거나, 기존 사본을 제거할 수 있는 융통성이 많다
		- 단점
			- 소프트웨어 개발 비용 : 중앙 시스템보다 구현이 어려움 -> 비용도 많이 들게 됨
			- 오류의 잠재성 증대 : 병렬적으로 운영되기에 알고리즘 정확성 확인이 어렵다 -> 치명적인 오류가 잠재해 있을 가능성이 높음
			- 처리 비용의 증대 : 여러 사이트가 공조하여 처리 -> 메시지 교환 및 추가 연산 증가 -> 처리비용 발생
			
	- 분산 데이타베이스 구조	
		- 참조 구조 		
		![ex_screenshot](/res/db39.png) 
			- 전역 스키마(전역 개념 스키마) : 데이타베이스가 마치 분산과 관계가 전혀 없는 것과 같이 생각하고 분산 데이타베이스에 포함될 모든 데이타를 정의
			- 각 전역 릴레이션은 분산을 위해 논리적으로 분할된 여러 개의 단편으로 구성, 단편화에 대한 정의는 단편화 스키마에 기술
				- 전역 릴레이션과 단편과의 사상도 단편화 스키마에 정의
			- 단편은 전역 릴레이션의 논리적 구성단위, 인스턴스는 네트워크의 한 사이트나 여러 사이트에 물리적으로 저장 가능
			- 할당 스키마는 단편들의 인스턴스들이 어떤 사이트에 저장해야 되는지를 정의 한것
			- 할당 스키마에 정의된 사상에 따라 분산 데이타베이스는 중복, 비중복이 결정된다
				- 중복일 경우 일 대 다 사상, 비중복일 경우 일 대 일 사상			
			![ex_screenshot](/res/db40.png) 
			- 한 사이트에 있는 단편 인스턴스를 표현하기 위해 전역 릴레이션 이름, 두개의 인덱스(단편 인덱스, 사이트 인덱스) 사용
			- 이 구조가 추구하는 가장 중요한 목표 : 데이타 단편화와 할당의 분리, 중복의 제어, 지역 DBMS로부터의 독립성
				- 데이타 할당과 단편화의 분리 : 단편화 투명성과 위치 투명성으로 상이한 레벨의 분산 투명성을 제공
					- 단편화 투명성 : 최 상위 레벨의 투명성으로 사용자나 응용 프로그래머가 마치 중앙 데이타베이스 시스템에서처럼 전역 릴레이션 위에 작업 할 수 있게 한다
					- 위치 투명성 : 하위 투명성으로 사용자나 응용 프로그래머가 전역 릴레이션 대신, 단편 위에서 작업할 수 있게 한다
				- 중복의 제어
					- 분할 단편 정의는 곧 중복될 수 있는 데이타 단위가 되는 것
				- 지역 DBMS롤부터 독립성 
					- 지역 사상 투명성은 지역 DBMS의 특정 데이타 모델에 신경 쓰지 않고 분산 데이타베이스 관리 문제를 해결
		- 클라이언트-서버 구조
			- 서버 레벨에 중앙 DBMS 기능을 포함시키는 것
				- 각 클라이언트는 적절한 SQL질의를 구성하고 사용자 인터페이스와 프로그래밍 언어 인터페이스 기능들을 제공
				- 클라이언트는 여러 SQL 서버들에 저장된 데이타의 분산에 관현 정보뿐만 아니라 전역 질의문을 지역 사이트에서 실행할 수 있는 여러 개의 지역 질의문으로 분해할 때 필요한 정보를 얻기 위해 데이타 사전을 참조하기도 한다
				- 질의 과정에서 상호작용
					- 클라이언트는 질의문을 분석해 각 사이트가 처리할 수 있는 여러 개의 독립 서브 질의문으로 분해, 서버 사이트로 전송
					- 각 서버는 서브 질의문을 처리하고 결과를 클라이언트 사이트로 보냄
					- 클라이언트 사이트에서는 서브 질의문 결과들을 조합해 원래 질의문 결과 생성
				- 서버를 데이터베이스 처리기 OR 후위 처리기, 클라이언트를 응용 처리기 OR 전위 컴퓨터라고 함
			- DBMS의 소프트웨어 모듈을 클라이언트와 서버 사이에 보다 통합적인 방법으로 분할 하는 것
				- 서버 레벨 : 데이타 저장, 전역 병행 제어와 회복 등
				- 클라이언트 레벨 : 사용자 인터페이스, 데이타 사전 기능, 프로그래밍 언어 컴파일러를 가진 DBMS 상호 작용, 지역 질의어 최적화, 병행 제어, 회복 등에 관한 기능 수행
				- 통상적인 분산 DBMS 소프트웨어 모듈
					- 서버 소프트웨어 : 사이트의 지역 데이타 관리를 책임
					- 클라이언트 소프트웨어 : 대부분의 분산 기능 책임
						- 분산 DBMS의 카탈로그에 있는 데이타 분산 정보를 접근하고 둘 이상의 사이트 접근이 필요한 요청을 처리
					- 통신 소프트웨어 : 여러 사이트 사이 명령과 데이타를 전송하는 데 필요한 통신 기능 제공
				- 클라이언트는 다중 사이트 질의문이나 트랜잭션에 대한 분산 실행 계획을 생성하는 책임, 서버에 명령을 보내 분산 실행을 감독하는 책임을 진다
				- 명령문에는 실행할 지역 질의문과 트랜잭션뿐만 아니라 데이타를 다른 클라이언트나 서버에 보내기 위한 명령문도 포함
				- 클라이언트 소프트웨어는 다중 사이트 질의문 즉 전역 질의문이 제출되는 사이트에는 반드시 포함되어야 한다
				- 클라이언트는 데이타 아이템의 중복된 사본들에 대한 일관성을 분산 병행 제어 기법으로 보장하는 기능, 전역 트랜잭션의 원자성을 보장하는 기능도 가지고 있어야 한다
		- 데이타 단편화
			- 제약 조건
				- 완전성 : 전역 릴레이션의 모든 데이타는 반드시 어느 한 단편으로 사상되어야 한다
					- 전역 릴레이션에 속한 데이타로 어떤 단편에도 속하지 않는 데이타가 있어서는 안된다
				- 회복성 : 단편화된 전역 릴레이션은 단편들로부터 다시 원래의 전역 릴레이션으로 회복시킬 수 있어야한다
				- 분리성 : 한 전역 릴레이션의 단편들은 서로 중복되지 않고 분리되게 정의되어야 한다
			- 수평적 단편화 : 전역 릴레이션의 투플들을 어떤 선정 조건에 따라 몇 개의 부분 집합 즉 수평 단편으로 분할하는 것
				- 수평 단편의 조건이 지역적 성질을 나타낼 수 있을 때 유용
				- 전역 릴레이션에 대한 실렉션 연산으로 정의
				- 값이 변경되면 소속된 단편도 변경되어야 함 -> 동적 단편화
			- 수직적 단편화 : 전역 릴레이션의 애트리뷰트들을 그룹으로 분할 시킨 것 
				- 전역 릴레이션에 대해 애트리뷰트 그룹의 프로젝션 연산으로 정의
				- 각 애트리뷰트 그룹이 지역적으로 공통되는 성질의 데이타를 포함시킬 수 있을 때 유용
				- 수직 단편들을 모두 자연 조인시키면 원래의 전역 릴레이션으로 회복될 수 있어야 한다
				- 수직 단편들 간 공통 애트리뷰트가 있어야 한다
				- 객체 값이 변경해도 아무런 영향을 주지 않는다 -> 정적 단편화
			- 혼합 단편화 : 수평적 단편화와 수직적 단편화를 혼용해서 단편을 만드는 방법
				- 실렉션과 프로젝션 연산을 전역 릴레이션에 적절히 혼용해 적용

- 분산 질의어 처리
	- 중복과 단편에 대하 질의어 처리
		- 전역 릴레이션이 단펴녀화되어 있지 않으면 전송 비용이 가장 작게 드는 사본을 선정
		- 단편화되어 있으면 여러 개 조인이나 유니온이 필요 -> 단순하지 않음
	- 단순 조인 처리
		- 릴레이션 S,C,E를 모두 사이트에Su에 전송한 뒤 지역 처리
		- 릴레이션 S를 사이트Sc에 전송해 S조인C를 계산 -> 조인 결과를 사이트 Se에 전송해 (S조인C)조인E를 계산 -> 결과를 질의문이 제출된 사이트 Su에 전송
		- 릴레이션의 전송 사이트가 서로 바뀐 상이한 형태로 처리할 수 있다
	- 병렬 조인 
		- 파이프라인 조인 기법
	- 세미 조인 전략
		- 아주 작은 수의 투플만 릴레이션 R과 조인에 참여하는 경우 유용
		- 조인 가능 투플 수 << 전체 투플 수가 되어 많은 투플들이 조인에 관련되지 않는 경우에 효율적
		
- 분산 트랜잭션
	- 분산 트랜잭션 시스템 모델
		- 트랜잭션 원자성을 유지하는 것은 분산 데이타베이스 시스템 트랜잭션 관리자의 기능
		- 각 사이트에는 지역 처리를 위한 트랜잭션 관리자가 있다 -> 전역 트랜잭션 실행을 위해 협력
		- 트랜잭션 관리자
			- 지역 사이트에 저장된 데이타를 접근하는 트랜잭션 OR 서브트랜잭션의 실행을 관리하는 역할
			- 트랜잭션 -> 지역 트랜잭션이나 전역 트랜잭션의 일부
			- 회복을 위한 로그 관리, 사이트에서 실행하는 트랜잭션들의 병행 실행을 조정하기 위해 병행 제어 기법에 참여
		- 트랜잭션 조정자
			- 지역 사이트에서 시작된 트랜잭션의 실행을 조정하는 역할 
			- 자기 사이트에서 시작한 모든 트랜잭션들의 실행을 조정하는 책임을 지고 있다
			- 트랜잭션이 실행이 시작되게 하고, 트랜잭션을 몇 개의 서브트랜잭션으로 분할해 실행할 사이트에 할당, 참여한 모든 사이트에서 실행이 완료되든지 취소되든지 하게 하여 트랜잭션 종료를 조정한다
	- 분산 시스템 장애
		- 중앙 시스템 장애 + 분산 환경 장애(사이트 장애), 통신 링크 장애, 메시지 분실, 네트워크 분할 등
		- 장애가 일어난 사이트에 저장된 데이타는 카탈로그를 갱신해 트랜잭션이나 질ㅇ릐문이 참조하지 않도록 해야 한다
		- 장애가 일어난 사이트에서 활동 중이던 트랜잭션들은 모두 취소시켜야 한다
		- 장애 발생 사이트가 서버라면 다른 사이트를 새로운 중앙 서버로 선정해 운영될 수 있도록 해야 한다

- 완료 규약
	- 2단계 완료 규약
		- 1단계 
			- 트랜잭션 조정자 Ci는 <prepare T> 레코드를 먼저 로그에 기록하고 다시 앙ㄴ정 저장 장치에 기록
			- 트랜잭션 T를 실행한 모든 사이트에 [prepare T] 메시지를 보내고 대기 상태로 들어간다
			- 메시지를 받은 각 사이트 트랜잭션 관리자는 T 실행을 Commit / abort 결정
			- 완료가 아니면 <no T>를 로그에 기록 조정자 Ci에 [abort T] 메시지를 보냄, 일방적으로 abort 상태로 들어간다
			- 완료라면 <ready T> 레코드를 로그에 기록한 뒤 T에 관련된 모든 로크 레코드들을 안전 저장 장치에 기록
			- 트랜잭션 관리자는 조정자에 [ready T]라는 메시지를 보내고 ready 상태로 들어간다
		- 2단계
			- 트랜잭션 조정자 Ci가 메시지 [prepare T]에 대한 응답을 모든 사이트로부타 받거나 [prepare T] 메시지를 보낸 뒤 일정한 시간이 경과하도록 아무런 응답을 받지 못하면 조정자는 트랜잭션 T가 완료될 수 있는지, 취소되어야 하는지를 결정할 수 있다
			- 조정자가 모든 참여 사이트로 [ready T]를 받았다면 T는 완료, 아니면 취소
			- 결과에 따라 <commit T> / <abort T> 레코드를 로그에 기록하고 다시 로그를 안전한 저장 장치에 기록 -> 트랜잭션의 실행은 종료
	 		- 트랜잭션 조정자는 [commit T]나 [abort T] 메시지를 모든 참여 사이트에 보낸다
			- 메시지를 받은 사이트는 로그에 기록함으로 규약이 종료됨
		- 사이트가 [ready T] 메시지를 보낸다는 것은 T에 대한 조정자의 완료나 취소 명령에 따르겠다는 약속
			- 필요한 정보가 안전 저장 장치에 기록되어 있다는 것을 의미
		- 트랜잭션 T의 최종 결과는 적어도 하나의 사이트가 [abort T]라고 응답만 하면 곧바로 취소 결정
		- 트랜잭션 T에 대한 최종 결과는 조정자가 그 결정을 로그에 기록하고 그것을 다시 안전 저장 장치에 기록할 때 내려진다
		- 참여 사이트로 하여금 [ack T] 메시지를 조정자에게 보내기도 한다
			- 모든 사이트로부터 [ack T]를 받으면 <complete T> 레코드를 로그에 기록하고 모든 과정 종료
	
	![ex_screenshot](/res/db41.png) 
	![ex_screenshot](/res/db42.png) 
	
	- 장애 처리
		- 참여 사이트의 장애
			- 사이트가 조정자에 [ready T] 메시지 보내기 전 장애가 발생했다면 조정자는 [abort T] 메시지로 응답했다고 간주
			- 사이트로부터 [ready T] 메시지를 받았는데 사이트 장애 발생했다면 장애를 무시하고 나머지 완료규약 수행
			- 장애 사이트가 회복되면 사이트는 장애 발생시 실행 중이던 트랜잭션의 운명을 결정하기 위해 로그를 조사
				- 로그에 <commit T>가 있으면 redo(T)
				- 로그에 <abort T>가 있으면 undo(T)
				- 로그에 <ready T>가 있으면 조정자에게 T의 운명 문의
					- 조정자가 활동 중이면 사이트에게 T가 완료인지 취소인지 응답 -> 응답이 완료이면 redo(T), 취소이면 undo(T)
					- 조정자가 고장 상태이면 다른 모든 사이트에 질의 메시지를 보낸다 -> 메시지 받은 사이트는 자기의 로그를 조사해 T가 실행되었는지, 완료인지 취소인지를 판단해 장애 상이트에 알려준다
					- T에 대한 적절한 정보가 없으면 결정을 유보 -> 주기적으로 최종 결과에 대한 질의 메시지를 보냄(T에 대한 정보를 가진 사이트가 회복될 때까지)
				- 사이트의 로그에 T에 대한 아무런 제어 레코드가 없다면 조정자가 보낸 [prepare T]메시지에 대한 응답을 하기전 장애를 일으몄다는 것을 의미 -> 취소하고 undo(T) 실행
		- 조정자의 장애
			- 활동 중인 어느 한 참여 사이트의 로그에 <commit T>레코드가 있으면 T는 반드시 완료되어야만 한다
			- 활동 중인 어느 한 참여 사이트의 로그에 <abort T>레코드가 있으면 T는 반드시 취소되어야만 한다
			- 활동 중인 어떤 참여 사이트 로그에도 <ready T>레코드가 없으면 고장난 조정자는 완료 결정을 할 수 없을 것 -> 회복을 기다리기보다 T를 취소 해야 한다
			- 활동 중인 사이트는 모두 자기 로그에 <ready T>레코드만 있고 다른 제어 레코드가 없는 경우 -> 활동 중인 사이트는 조정자가 회복되기만을 기다릴 수 밖에 없다 -> T가 보유한 시스템 자원을 계속해서 보유한 상태로 유지해야마 된다
		- 네트워크 분할 
			- 조정자와 참여 사이트가 모두 단절된 한 분할에 속하는 경우 -> 완료 규약 실행에 영향받지 않음
			- 조정자와 참여 사이트들이 몇 개의 분할로 분산되는 경우
				- 조정자가 포함된 분할에 속하지 않은 사이트 -> 조정자가 장애 일으켰을 때 규약대로 처리
				- 조정자가 포함된 분할 -> 정상적인 완료 규약 수행

- 조정자 산출
	- 예비 조정자 : 본래의 기능 이외에 추가로 조정자의 역할을 인계받을 수 있도록 정보를 유지하는 사이트
		 - 조정자에 보내지는 메시지는 예비 조정자도 모두 수신한다
		 - 예비 조정자는 실제 조정자가 하는 것과 같은 알고리즘 수행, 내부 상태 정보를 유지한다
		 - 다른 사이트에 직접 영향을 주는 행동은 실제로 취하지 안ㄶ는다
		 - 실제 조정자의 고장을 탐지한 경우 바로 조정자 역할을 수행 -> 중단 없이 처리 수행
		 - 조정자의 작업을 이중으로 수행하는 오버헤드가 있다
		 - 주기적으로 조정자와 통신을 유지해 동기화해야한다
	- 새로운 조정자 선출 알고리즘
		- 불리 알고리즘 -> 시스템내의 활동 사이트에 유일한 식별 번호가 지정되어 있어야 한다
			- 조정자에 장애 발생 시 알고리즘에 따라 사이트 선정
			- 식별 번호는 모든 활동 사이트에 보내져야 하고 장애로부터 회복된 사이트는 현재 조정자를 알 수 있도록 하는 기법이 제공되어야 함
			- 사이트가 조정자에게 보낸뒤 조정자의 응답을 받지 못하면 자기가 새로운 조정자가 되겠다고 시도
				- 자신보다 우선순위의 모든 사이트에 새로운 조정자 선출 메시지를 보내고 일정 시간 동안 응답을 기다린다
				- 일정 시간 동안 아무런 응답이 없으면 우선순위의 사이트가 장애를 일으켰다 가정하고 자신이 새로운 조정자 사이트가 된다
					- 낮은 우선순위의 모든 사이트에 이 사실을 통보
				- 응답을 보내온다면 우선 순위의 사이트를 새로운 조정자로 선출되어 통보해 오기를 다시 기다린다
					- 어떤 다른 사이트가 조정자로 선출되면 결과가 일정 시간안에 통보되어야 한다
					- 일정시간보다 통보가 없으면 고장으로 단정하고 다시 선출 알고리즘을 시작한다
- 분산 병행 제어
	- 로킹 기법
		- 단일 로크 관리자 : 데이터가 중복되어 있는 상황에서 시스템이 지정한 특정 사이트에 하나의 로크 관리자를 유지하는 것
			- 데이타에 대한 lock과 unlock 요청은 사이트에서 처리
			- 트랜잭션이 어떤 데이타 아이템을 로크하려 함다면 사이트에 로크 요청을 보낸다
			- 로크 관리자는 요청이 즉시 허락될 수 있는지를 결정 -> 허락 될 수 있다면 로크 요청 사이트에 메시지를 보냄 / 아니면 로크 요청은 허락될 수 있을 때까지 대기하고 가능할 때 메시지를 보냄
			- 모든 로크는 사이트에서 처리되지만 실제 데이타 아이템 검색은 어떤 사이트의 사본을 접근해도 상관 없음
		- 분산 로크 관리자
			- 로크 관리자의 기능을 여러 사이트에 분산 시키는 것
			- 각 사이트는 지역 로크 관리자가 있어 사이트에 저장된 데이타 아이템에 대한 lock과 unlock 요청을 처리
			- 트랜잭션이 다른 사이트에 없고 한 사이트에만 있는 데이타 아이템 x에 대해 lock하기 원할 때 lock을 요청하는 메시지를 해당 사이트 로크 관리자에게 보낸다
			- 데이타 아이템 x에 양립할 수 없는 타입의 로크가 걸려있으면 허락될 수 있을 때까지 보류
			- 허락 결정을하면 로크 관리자는 로크 요청자에게 로크 요청이 허락되었다는 메시지를 다시 보낸다
			- 병목현상이 없다는 이점이 있다
			- 오버헤드가 비교적 적어 lock 요청에 대해 두개의 메시지 교환이 필요하고 unlock에 대해서는 하나의 메시지 교환이 필요하다
		- 기본 사본
			- 데이타를 중복으로 저장하는 경우, 그중 하나를 기본 사본으로 정함
			- 각 데이타 아이템 x에 대한 기본 사본은 x의 기본 사이트라고 하는 특정 사이트에 저장되어 있는 데이타 아이템이 된다
			- 기본 사본 기법은 중복된 데이타가 마치 중복되지 않은 데이타를 처리하는 것과 같은 방법으로 병행 제어를 가능하게 해준다
		- 과반수 규약 
			- 각 사이트마다 하나의 로크 관리자가 있게 된다
			- 각 관리자는 사이트에 저장된 모든 데이타 아이템이나 사본에 대한 로크를 관리한다
			- 어떤 트랜잭션 데이타 아이템 x에 대해 로크를 원하고 x는 n개의 사이트에 중복해 저장되어 있다면 트랜잭션은 x가 저장된 n사이트의 반수 이상의 사이트에 로크 요청 메시지를 보내 허락 받아야 한다
			- 각 로크 관리자는 로크 요청을 즉시 허락 할 수 있는지 여부를 결정한다
			- 트랜잭션은 데이타 아이템 x에 대한 과반수의 사본에 대해 로크를 획득할 때까지 접근하지 못한다
	- 타임스탬프 기법
		- 시스템이 직렬화 순서를 결정하는데 사용할 수 있는 유일한 타임스탬프를 각 트랜잭션에 지정하는 것
		- 분산 환경에서 타임스탬프 생성
			- 중앙식 : 타임스탬프를 생성하기 위해 하나의 사이트가 선택
				- 이 사이트는 타임스탬프르 위해 논리 계수나 자신의 지역 시스템 시계를 사용할 수 있다
				- 전역 타임스탬프는 유일한 지역 타임 스탬프에 사이트 식별자를 첨가시켜 만든다(반드시 유일해야하며 결합 순서는 매우 중요!!)
				- 지역 타임스탬프가 시스템 전반에 균형있게 생성될 수 있도록하는 것이 필요하다
					- 각 사이트에 논리적 시계를 정의하여 유일한 타임스탬프를 생성하게 한다
					- 논리적 시계는 새로운 지역 타임스탬프를 생성한 뒤 계수 하나를 증가시키도록 구현한다
		- 타임스탬프 운용
			- 중앙식의 경우 같이 연쇄 취소를 방지하기 위해 트랜잭션이 완료하지 않은 데이타 아이템 값을 판독하지 못하도록 하는 방법이 있어야 한다
			- 연쇄 취소를 방지하기 위해 기본적 타임스탬프 순서 기법에 2단계 완료 규약을 조합하면 연쇄 취소 없이 직렬 가능성을 보장하는 기법을 만들 수 있다
			- 기존 타임스탬프 기법의 트랜잭션 간 충돌을 취소하는 것을 read와 write 연산의 실행을 취소가 일어나지 않는다는 것이 확실해질 때까지 지연시키는 방법이 있다

- 분산 교착상태 관리
	- 어떻게 대기 그래프를 유지하느냐 하는 것이 중요
	- 분산시스템의 교착 상태는 여러 사이트가 관련된 전역 교착상태가 발생하기에 탐지가 쉽지 않다
	- 교착 상태 탐지 방법은 각 사이트로 하여금 지역 그래프를 유지하게 하는 것이다
		- 지역 그래프의 각 노드는 사이트의 지역 데이타 아이템을 점유하고 있거나 요청하고 있는 지역 or 전역 트랜잭션
	- 중앙 교착상태 탐지
		- 모든 지역 대기 그래프를 종합한 결과를 하나의 사이트, 교착상태 탐지 조정자에 구축하고 유지한다
		- 전역 대기 그래프는 지역 대기 그래프에서 새로운 간선이 첨가, 삭제 될 때 or 일정한 수의 변경 발생마다 주기적으로 구축되거나 조정자가 탐지 알고리즘을 가동시킬 필요가 있다고 결정할 때 구축
		- 교착상태 알탐지 알고리즘이 가동되면 조정자는 전역 그래프를 조사 -> 사이클 발견되면 희생자 선정
		- 조정자는 희생자로 선정된 트랜잭션을 모든 사이트에 알림
		- 장애 발생에 대해 취약하며 통신비용이 많이 든다
	- 계층 교착상태 탐지
		- 교착상태 탐지기들이 모두 하나의 트리로 구성
		- 리프에는 지역 교착상태 탐지기, 리프가 아닌 레벨은 비 지역 교착상태 탐지기가 있다
		- 지역 교착상태 탐지기는 중앙 집중의 지역 교착상태 탐지기 기능을 수행
			- 지역의 교착상태를 탐지하고 잠정적인 전역 사이클에 관한 정보를 계층상 직속 상위 탐지기에 전송한다
		- 각 비 지역 교착상태 탐지기는 자식 탐지기들만 관련된 교착상태를 탐지하고 잠정 대기 그래프를 직속 상위 탐지기에 전송
		- 교착상태 탐지기의 계층 구조에 성능이 달려있다
	- 분산 교착상태 탐지
		- 모든 제어기들이 교착상태를 탐지하는 책임을 똑같이 분담하고 있다
		- 모든 사이트가 전체 그래프의 일부를 나타내는 대기 그래프를 시스템의 동적 행태에 따라 구성하고 성능 유지
		- 교착 상태가 존재하면 적어도 부분 그래프 하나에 사이클이 나타날 것이라는 것
		- 사이트가 사이클 발견하면 사이트에 사이클에 관한 정보를 포함한 교착상태 탐지 메시지를 보낸다

- 카탈로그 관리
	- 데이터 정의나 통계정보가 변경될 때 시스템에 의해 자동적으로 갱신
	- 카탈로그 내용 
		- 전역 스키마 정보
		- 단편화 정보
		- 할당 정보
		- 이름 사상 정보
		- 접근 방법 정보
		- 통계 정보
		- 접근 권한 및 무결성 정보 
	- 카탈로그의 분산
		- 카탈로그의 할당과 관리는 각 사이트의 지역 자치성에 직접 관련되어 있다
		- 중앙 카탈로그 : 전체 카탈로그가 한 사이트 중앙에 저장
		- 완전 중복 카탈로그 : 카탈로그들을 각 사이트마다 중복 저장시킨다, 카탈로그 변경은 모든 사이트의 카탈로그를 접근, 갱신해야 되는 복잡성이 있다
		- 지역 카탈로그 : 카탈로그 자체를 단편화시켜 데이타가 저장되는 사이트에 관련 카탈로그 단편을 같이 저장하느 방법
			
19. 데이터 웨어하우스와 데이터 마이닝
- 의사결정 지원 시스템
	- OLTP(온라인 트랜잭션 처리)의 목적은 실제 현 기관의 정확한 모델로 데이타베이스에 데이터를 유지하는 것
		- 트랜잭션들을 짧은 응답시간으로 처리해야 한다
		- 갱신이 비교적 빈번하고 데이타베이스의 일부분만 접근하느 특징이 있다
	- 의사결정 지원 : 데이타로부터 정보를 추출해 의사결정을 할 때 정보를 사용할 수 있도록 하는 일련의 방법론
	- 의사결정 지원 시스템 : 비즈니스 내에서 관리적인 의사결정에 사용되는 컴퓨터화된 도구들로 구성되 ㄴ시스템
		- 광범위하고 종합적인 데이타 처리가 요구된다 
	- 의사결정 지원 시스템 구조
	
	![ex_screenshot](/res/db44.png) 
	
	- 데이타 저장소 : 비즈니스 데이타, 비즈니스 모델 데이타를 포함
		- 비즈니스 데이타는 데이터 분석과 질의에 최적이 되는 구조로 운영 데이터를 변환시켜 저장한 것
		- 비즈니스 모델 데이타는 비즈니스 상황과 문제점들을 식별하고 이해하기 위해 비즈니스 모델링하는 특별한 알고리즘에 의해 만들어 진다
	- 데이타 추출과 필터링 : 시스템 데이타베이스에 저장할 수 있도록 검사하느 모듈
	- 사용자 질의 도구 
	- 사용자 발표 도구
	- 효과는 데이타 품질에 달려있다
- 데이타 웨어 하우스
	- 주제 지향적이고 통합적이고 비소멸성이며 시간에 변하는 데이타베이스로 의사결정 지원을 제공하는 것
	- 복잡한 분석, 지식의 발견, 의사결정 지원을 위한 데이타에 대한 접근을 제공
	- 여러 소스의 데이타를 수집해 하나의 통일된 스키마를 이용해 단일 사이트에 저장한 정보 저장소를 의미하기도 한다
	- 데이타에 대한 통합된 단일 인터페이스를 제공하기 때문에 의사결정 지원 질의문을 쉽게 작성할 수 있도록 지원한다
	- 데이타 검색을 위한 최적화 되는 것
	- 시계열이나 동향 분석 작업에도 아주 적합
	- 정기적으로 갱신하기 때문에 변경이 자주 일어나지 않음
	- 정보의 변경 단위가 크고 계획된 정책에 따라 재생되며 내용이 점증적이다, 갱신은 수집을 담당하는 서브 모듈이 취급
	- 데이타 분석과 질의 처리를 위해 최적화된 판독 전용 데이타베이스

	![ex_screenshot](/res/db45.png) 
	
	- 수집 / 적재 관리자는 데이타 추출을 수행하면서 필터링, 변환, 통합, 분류, 요약 등의 작업을 담당
	- 데이타 웨어하우스와 운영데이타는 분리
	- 통합되어 있고 장기간 동안의 과거 데이타를 포함
	- 데이타는 어느 한 시점의 스냅샷 데이타이다
	- 데이타는 주제 지향적이다
	- 데이타는 운영 데이타로부터 주기적 일괄 갱신을 수행하는 판독 전용
	- 개발방법은 데이타 중심
	- 여러 레벨의 상세 데이타, 과거 상세 데이타, 고급 요약 데이타, 초급 요약 데이타를 포함
	- 대형 데이타에 대한 판독 중심으 ㅣ트랜잭션이 특징이다
	- 데이타 소스, 변환, 저장소를 추적할 수 있는 시스템을 가지고 있다
	- 메타데이타는 아주 중요한 요소이다
		- 모든 데이타 원소들을 식별하고 정의
		- 데이타 원소의 소스, 변환, 통합, 저장장소, 활용도, 관계성, history를 제공
	- 사용자가 데이타를 최적으로 사용하게끔 자원 사용에 대한 비용 부과 시스템을 가짐	
	- 데이타 마트 : 하나의 단일 주제로 부와 같이 기관의 일부 소수 몇 사람의 의사결정을 지원하는 작은 데이타 웨어 하우스

- OLAP과 다차원 데이타 모델
	- OLAP : 대규모의 다차원 데이타를 동적으로 온라인에서 분석, 통합하고 보고서를 만드는 일체의 작업
	- OLAP의 목표는 전략적 의사결정을 안내하기 위한 데이타베이스 정보를 사용하는 것
	- OLAP의 응용은 질의가 복잡하고 데이타 갱신이 드물고 트랜잭션들은 데이타베이스의 상당 부분을 접근하는 특징을 가짐
	- 데이타가 주로 다차원 배열 구조라는 전제하에 만들어진 질의를 지원
	
	- 사실 데이타와 차원 테이블
	
	![ex_screenshot](/res/db46.png)			
		
	- 사실 테이블 : 분석할 데이타의 모든 사실을 포함하는 테이블
		- B-id, I-id, T-id : 차원 애트리뷰트
		- Total : 측정 애트리뷰트
		- 다차원 데이타 : 차원 애트리뷰트와 측정 애트리뷰트로 모델링 한 것
	
	- 차원 테이블 : 사실 테이블의 차원에 관한 추가적 정보를 별도 테이블로 저장한 것
		- 각 차원 테이블은 자연히 사실 테이블에 있는 차원 애트리뷰트를 포함
		- 차원 애트리뷰트는 차원 테이블을 가리키는 차원 식별자 애트리뷰트			
	
	![ex_screenshot](/res/db47.png) 		
	
	- 데이타 큐브
	
	![ex_screenshot](/res/db48.png) 
		
	- 스타 스키마 
		- 다차원 의사결정 지원 데이타를 분석하기 위해 하나의 사실 테이블과 여러 개의 차원 테이블로 구성된 관계 데이타베이스 스키마로 사상하기 위해 사용되는 데이터 모델링 기법
		- 다차원 데이타 모델 : 차원 애트리뷰트와 측정 애트리뷰트로 구성된 사실 테이블과 차원을 기술하는 차원테이블을 스타 스키마 형태로 표현한 데이타 구조
		- 눈송이 스키마 : 차원테이블들이 정규화되어 여러 테이블로 분해된 것
		- 성좌 스키마 : 차원 테이블을 공유하느 여러 개의 사실 테이블로 구성 된 것		
	
	![ex_screenshot](/res/db49.png)			
	
	![ex_screenshot](/res/db50.png) 

- 다차원 집계 질의
	- 드릴 다운 : 일반적인 것부터 상세한 것으로 질의하는 것
	- 롤업 : 상세한 질의에서 보다 일반적인 질의를 하는 것
	- OLAP 데이타베이스의 데이타를 다차원 큐브로 보고 차원들의 일부를 검색하는 것을 피벗이라 한다
		- 피벗을 위해 사용하는 차원은 GROUP BY절의 애트리뷰트 리스트에 해당
		- 피벗 연산 결과를 교차 테이블, 크로스탭이라 한다
	- OLAP 시스템은 여러 유형의 질의를 할 수 있도록 지원해준다
	- 슬라이싱 연산 : 다차원 큐브 데이타에 대해 일부 차원의 애트리뷰트 값을 고정시켜 슬라이스한 모양의 결과를 만들어 내는 것
	- 다이싱 : 큐브 데이타에 대해 차원의 값을 어떤 범위로 제한해 부분 큐브 데이타를 생성하는 것(주사위 형태)
	
	- ROLLUP과 CUBE 연산자
		- 크로스탭 : 행과 열에 대한 소계와 전체에 대한 총계를 포함하는 행과열이 추가된 테이블
		- CUBE는 왼쪽에서 오른쪽으로 이동하며 부분 집합 생성
		- ROLLUP은 오른쪽에서 왼쪽으로 이동하며 부분 집합 생성
		<pre><code>
			SELECT S.B-id, S.I-id, SUM(S.Total)
   		FROM SALSE S
   		GROUP BY CUBE(S.B-id, S.I-id)
		</code></pre>
	
	![ex_screenshot](/res/db51.png) 
		<pre><code>			
			SELECT S.B-id, S.I-id, SUM(S.Total)
   		FROM SALSE S
   		GROUP BY ROLLUP(S.B-id, S.I-id)
		</code></pre>				
	
	![ex_screenshot](/res/db52.png) 
		
	- CUBE 연산자는 나중에 제출되는 질의문을 실행할 때 사용할 수 있도록 사실 테이블의 모든 차원에 대해 집계를 미리 계산해 저장해 두기위해서도 사용된다
	
	- OLAP 구현
		- ROLAP : 스타 스키마로 표현된 OLAP 데이터를 관계 데이터베이스로 저장해 구현한 OLAP 시스템
		- MOLAP : 다차원 구조를 이용해 데이터 큐브로 저장해 구현한 시스템
		- HOLAP : 일부 요약 데이터는 메모리에 저장하고 나머지 다른 요약 데이터는 관계 데이터베이스에 저장하는 시스템
	- OLAP 시스템 요건
		- 다차원 개념적 뷰를 가질 수 있어야함.
		- 투명성 / 접근성
		- 일관성 있는 보고 성능 
		- 클라이언트-서버 구조
	 	- 일반적 차원성 (차원의 수에 관계없이 모든 테이블은 능력이 동등해야 함)
	 	- 동적 희소 행렬 처리
	 	- 다중 사용자 지원
	 	- 무제한적 교차차원 연산
	 	- 직감적 데이터 처리
	 	- 유연한 보고
 		- 무제한적 차원과 집계 레벨
	- OLAP는 다차원 데이타 모델을 기반으로 만들어 진다

- 데이타 마이닝 기법
	- 데이타 마이닝 : 대량의 데이타로부터 규칙이나 패턴으로 표현할 수 있는 지식 발견 과정
	- 연관 규칙
		- 연관 : 데이타 베이스에 있는 어떤 값들 사이 존재하는 상관 관계
		- 신뢰도 : 연관 규칙의 왼편 전제조건이 참일 경우 오른편 결론이 참이 되는 백분율
 		- 지지도 : 연관 규칙의 왼편 전제조건과 오른편 결론이 모두 참이 되는 백분율
		- 연관 규칙이 존재한다 주장하기 위해서는 신뢰도와 지지도가 최소한 어떤 경계값을 넘어야 한다
	- 순차 패턴 : 순차 데이터에 포함되어 있는 순차 상관관계 
	- 분류 규칙 
		- 분류 : 예측하는데 사용할 수 있는 규칙을 개발하기 위해 데이터베이스에 있는 객체를 이용하는 것 
			- 주어진 데이터가 어떤 카테고리에 속하는지 판단하는 규칙을 발견하는 문제 
			- 들어오는 데이타가 속해야 될 카테고리를 결정하느 데 사용
 - 기계학습 : 뉴럴 넷을 이용한 알고리즘을 적용 ( 가중치와 경계 값을 어떻게 결정하는 가가 중요)
 - 데이타로부터 지식의 추출
 
 	![ex_screenshot](/res/db53.png) 
