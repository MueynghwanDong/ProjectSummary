# 운영체제(Operating System)

### 서론
1.1 운영체제가 할일 
1) 사용자 관점 
- PC : 한 사용자가 자원을 독점하도록 설계되었으며 사용자가 수행하는 작업을 최대화하는 것이 목적, 사용의 용이성을 위해 설계
- 대형, 미니 컴퓨터 : 자원을 공유하며 정보 교환 가능, 자원 이용을 극대화하도록 설계하며 각 개인은 자신의 정당 몫만 사용 가능
- 워크스테이션, 서버 : 자신이 맘대로 할 수 있는 전용자원을 갖지만 네트워킹 서버-파일, 프린트 서버를 공유, 개인의 사용 용이성과 자원 이용간 적절한 조화를 이루도록 설계
- 휴대용 컴퓨터 : 개인 사용자들을 위한 독립형 장치
2) 시스템 관점 
- 자원 할당자 : 자원의 관리자로 동작하며 작업을 위해 특정 프로그램과 사용자에게 필요 자원 할당, 효율적이고 공정하게 운영할 수 있도록 어느 요청에 자원을 할당할지 결정해야함
- 제어프로그램 : 부적절한 사용을 방지하기 위해 사용자 프로그램의 수행을 제어

1.4 운영체제 구조
- 운영체제의 가장 중요한 면 => 다중 프로그램을 할 수 있는 능력
- 다중 프로그래밍
  - CPU가 수행할 작업을 항상 하나 가지도록 구성함으로 CPU 이용률을 증가한다
  - 작업들은 디시크의 작업 풀 내에 유지된다
  - 작업 풀은 디스크 내의 모든 프로세스로 구성되며 주 메모리의 할당을 기다린다
  - 메모리 내 작업 집합은 작업 풀 내의 작업들의 부분 집합이다
  - 여러 시스템 자원을 효율적으로 이용할 수 있는 환경을 제공하나 사용자를 위해 컴퓨터 시스템과 상호작용을 제공하지 않음
  - 시분할은 다중 프로그래밍의 논리적 확장
- 시분할 시스템
  - 사용자, 시스템 간 직접 통신을 제공하는 대화식 컴퓨터 시스템을 필요로 함
    - 응답시간이 짧아야 하며, 1초 이내 정도
  - 동시에 많은 사용자가 컴퓨터를 공유하도록 한다
  - CPU 스케줄링과 다중 프로그래밍을 사용한다 
    - 각 사용자에게 시분할 되는 작은 부분을 제공하기 위해 
  - 시분할과 다중 프로그래밍 운영체제는 여러 작업이 메모리에 동시에 유지되어야 한다
    - CPU 스케줄링, 작업 스케줄링
  - 시분할 시스템에서 운영체제는 적잘한 응답시간을 보장해야 한다
  - 파일 시스템을 제공해야 한다
  - 디스크 관리 기법, 작업 동기화와 통신 기법을 제공해야 하며 교착 상태에 빠지지 않도록 해야한다
  - 자원을 보호하기 위한 기법을 제공해야 한다
  
1.5 운영체제 연산 
- 트랩 : 오류 혹은 사용자 프로그램의 운영체제 서비스 수행 요청에 의해 유발되는 소프트웨어에 의해 생성된 인터럽트
1) 이중 연산 모드 
- 운영체제를 위해 실행되는 작업과 사용자를 위해 실행되는 작업을 구분할 수 있다
- 사용자 응용을 위해 실행 시 사용자 모드, 운용체제로부터 서비스 요청을 하면 사용자에서 커널 모드로 전환
- 이중 모드는 잘못된 사용자로부터 운영체제를, 잘못된 사용자 서로를 보호하는 방법을 제공함

  ![ex_screenshot](/res/os1.jpg)
  
  - 시스템 부트 시 커널 모드에서 시작
  - 운영체제가 적재되고 사용자 모드에서 프로세스 시작
  - 트랩, 인터럽트 발생마다 사용자에서 커널모드로 전환 
  - 운영체제가 컴퓨터 제어를 얻을 때마다 커널모드에 있게됨
  - 특권 명령은 커널 모드에서만 수행되도록 하며 사용자 모드에서 수행 시 불법적 명령으로 간주해 운영체제로 트랩을 건다
  
2) 타이머 
- 운영체제가 CPU에 대한 제어를 유지할 수 있도록 보장
- 프로그램이 무한 루프에 빠지거나 시스템 서비스 호출에 실패해 제어가 운영체제로 복귀하지 않는 경우가 없도록 방지해야한다
- 가변 타이머는 고정률의 클락과 계수기로 구현
  - 계수기가 0이 될 때 인터럽트 발생
- 타이머가 인터럽트 발생하면 제어는 운영체제로 넘어가며 타이머 값을 변경 명령은 특권 명령
  - 사용자 프로그램이 오래 실행되는 것을 방지하기 위해 사용할 수 있음
  
1.6 프로세스 관리
- 프로세스는 자신의 일을 수행하기 위해 CPU 시간, 메모리, 파일, 입출력 장치를 포한한 여러 자원을 필요로 함
- 한 프로세스는 한 시스템 내의 작업의 단위
- 운영체제는 다음과 같은 활동에 대한 책임을 진다
  - CPU에 프로세스와 스레드 스케줄
  - 사용자 프로세스와 시스템 프로세스의 생성과 제거
  - 프로세스의 일시 중지와 재수행
  - 프로세스 동기화를 위한 기법 제공
  - 프로세스 통신을 위한 기법 제공
1.7 메모리 관리 
- 주 메모리는 CPU와 입출력 장치에 의해 공유되는 빠른 접근이 가능한 데이터 저장소
- 주 메모리는 CPU가 직접 주소 지정할 수 있고, 직접 접근이 가능한 유일한 대량 메모리
- 프로그램 수행을 위해 반드시 절대 주소로 매핑되고 메모리에 적재되어야 한다
- CPU 이용률과 사용자에 대한 응답속도를 개선하기 위해 메모리에 여러 개의 프로그램을 유지해야 하며 이를 위한 메모리 관리 기법이 필요
- 운영체제는 다음과 같은 일을 담당
  - 메모리의 어느 부분이 사용되고 누구에 의해 사용되는지 추적해야 한다
  - 어떤 프로세스들을 메모리에 적재하고 제거할 것인지 결정
  - 필요에 따라 메모리 공간을 할당하고 회수해야한다
1.8 저장장치 관리 
- 파일 시스템 관리 
  - 파일의 생성 및 제거
  - 디렉토리 생성 및 제거
  - 파일과 디렉토리 조작을 위한 프리미티브 제공
  - 파일을 보조 저장 장치로 매핑
  - 안정적 저장 매체에 파일 백업
- 대용량 저장 장치 관리 
  - 자유 공간의 관리 
  - 저장 장소 할당 
  - 디스크 스케줄링
  
### 시스템 구조
1) 운영체제 서비스 
- 사용자에게 도움을 주는 목적

  ![ex_screenshot](/res/os2.png)  
  
  - 사용자 인터페이스 : 명령어 라인 인터페이스 / 그래피컬 사용자 인터페이스
  - 프로그램 수행 : 시스템은 프로그램을 메모리에 적재해 실행할 수 있어야함
  - 입출력 연산
  - 파일 시스템 조작 
  - 통신 : 공유 모메리, 메시지 전달 기법 등
  - 오류 탐지 : 각 유형 오류에 대해 적당한 조치를 취해야 함
- 시스템 자체의 효율적 동작을 보장하기 위한 운영체제 기능
  - 자원 할당 
    - 다수의 사용자, 작업들이 동시 수행 시, 각각에 자원을 할당해 주어야함
  - 회계
    - 사용자가 어떤 종류의 컴퓨터 자원을 많이 사용하는지 추적할 수 있어야함
  - 보호와  보안
2) 사용자 운영체제 인터페이스

2.1 명령 해석기
- 사용자가 지정한 명령을 가져와 수행하는 것이 주 기능
- 구현 방식 중 하나는 명령 해석기 자체가 명령을 실행할 코드를 갖고 있는 경우
  - 명령 해석기가 자신의 코드의 한 부분을 분기하고 코드 부분이 매개 변수를 설정하고 적절 시스템을 호출 -> 명령의 수가 명령 해석기 크기를 결정
- 다른 방법은 시그템 프로그램에 의해 대부분의 명령을 구현하는 방법
3) 시스템 호출
- 시스템 호출은 운영체제에 의해 사용 가능하게 된 서비스에 대한 인터페이스를 제공
- API : 각 함수에 전달되어야 할 매개변수들과 프로그래머가 기대할 수 있는 반환 값을 포함해 응용 프로그래머가 사용 가능한 함수의 집합을 명시
  - 프로그램의 호환성에 따라 실제 시스템 호출 보다 API를 선호하는 편
- 프로그래밍 언어들을 위한 실행시간 지원 시스템은 운영체제가 제공하는 시스템 호출에 대한 연결로서 동작하는 시스템 호출 인터페이스를 제공
  - API 함수의 호출을 가로채 필요 운영체제 시스템 호출을 부른다
- 통상 시스템 호출은 번호가 할당되고 번호에 따라 색인되는 테이블을 유지한다, 호출 인터페이스는 의도 시스템 호출을 부르고 시스템 호출의 상태와 반환 값을 돌려준다
- 호출자는 단지 API를 준수하고 시스템 호출의 결과로서 운영체제가 무엇을 할 것인지만 이해하면 된다
- 운영체제에 매개변수를 전달하기 위한 방법
- 매개변수를 레지스터 내에 전달하는 방법
- 레지스터보다 매개변수가 많은 경우 매개변수는 메모리 내 블록이나 테이블에 저장되고, 블록의 주소가 레지스터 내에 매개변수로 전달

  ![ex_screenshot](/res/os3.png)  
  
  ![ex_screenshot](/res/os4.png)  
  
4) 시스템 호출 유형
- 프로세스 제어
  - 끝내기(end), 중지(abort)
  - 적재(load), 수행(execute)
  - 프로세스 생성 및 종료
  - 프로세스 속성 획득, 프로세스 속성 설정
  - 시간을 기다림
  - 사건 기다림(wait event), 사건 알림(signal event)
  - 메모리 할당 및 자유화
- 파일 조작
  - 파일 생성(create file), 파일 삭제(delete file)
  - 열기, 닫기
  - 읽기, 쓰기, 위치 변경
  - 파일 속성 획득 및 설정
- 장치 관리
  - 장치를 요구, 장치를 방출
  - 읽기, 쓰기, 위치 변경
  - 장치 속성 획득, 장치 속성 설정
  - 장치의 논리적 부착 및 분리
- 정보 유지
  - 시간과 날짜의 설정과 획득
  - 시스템 데이터의 설정과 획득
  - 프로세스, 파일, 장치 속성의 획득
  - 프로세스, 파일, 장치 속성의 설정
- 통신
  - 통신 연결의 생성, 제거
  - 메시지 송신, 수신
  - 상태 정보 전달
  - 원격 장치의 부착 및 분리
  
6) 운영체제 설계 및 구현

6.1 설계 목표
- 시스템 설계 시 문제점은 시스템 목표와 명세를 정의하는 일 
- 사용자 목적과 시스템 목적으로 나눔
- 사용자들이 시스템에 기대하는 특징 
  - 사용하기 쉽고 편리하며, 배우기 쉽고 믿을수 있고 안전, 신속 해야한다.
  - 즉, 운영체는 설계, 구현, 유지보수가 쉬어야하며 적응성, 신뢰성, 무오류, 효율성을 가져야 한다
6.2 기법과 정책
- 기법으로부터 정책을 분리하는 것이 중요 원칙
- 기법 : 어떤 일을 어떻게 할 것인가 결정하는 것
- 정책 : 무엇을 할 것인가를 결정하는 것
- 정책과 기법의 분리는 융통성을 위해 중요함
  - 정책은 장소가 바뀌거나 시간 흐름에 따라 변경될 수 있다
- 기법이 정책으로부터 적절히 분리되면 입출력 중심 프로그램이 CPU 중심 프로그램보다 높은 우선순위를 가지도록 하는 정책을 지원하거나 반대 정책을 지원할 수 있다
- 정책 결정은 모든 자원 할당 문제이 있어 중요하다
  - 자원의 할당 여부를 결정할 필요가 있을 때마다 정책 결정을 해야한다
  - 무엇이 아니라 어떻게 일때마다, 반드시 결정되어야 하는 것은 기법
  
7) 운영체제 구조

7.1 간단한 구조 
- MS-DOS는 인터페이스와 기능 계층이 잘 분리되어 있지 않다. 사용자 프로그램이 고장 나면 시스템 전체가 고장나게 된다
- UNIX는 커널과 시스템 프로그램으로 구성되어 있고 커널은 시스템 호출을 통해 파일 시스템, CPU 스케줄링, 메모리 관리, 다른 운영체제 기능을 제공

 ![ex_screenshot](/res/os5.png) 
 
 ![ex_screenshot](/res/os6.png) 
 
7.2 계층적 접근
- 운영체제 스템은 여러 계층으로 구분
  - 최하위 계층 : 하드웨어
  - 최상위 계층 : 사용자 인터페이스
- 운영체제의 층은 데이터와 연산으로 구성된 추상된 객체의 구현이다
- 모듈화를 통해 각 계층은 바로 아래 계층에서 제공하는 기능과 서비스만을 사용
  - 계층은 하위 계층에 대한 연산을 호출 할 수 있다
- 장점 
  - 구축과 디버깅의 단순함
  - 설계와 구현이 단순하다
  - 각 계층은 하위 계층에서 제공하는 연산만을 통해 구현
  - 각 계층은 연산들이 어떻게 구현되는지 알 필요 없음
- 단점
  - 다양한 계층들이 대략적으로 정의
  - 각 계층은 오직 하위 계층들이 제공하는 기능만 사용하기에 주의 깊은 계획이 이요구 된다
  - 다른 유형의 구현 방법보다 효율성이 낮다
7.3 마이크로 커널
- 중요하지 않는 구성 요소를 커널로 부터 제거하고 시스템 및 사용자 수준 프로그램으로 구현해 운영체제를 구성
- 주 기능은 클라이언트 프로그램과 사용자 공간에서 수행되는 다양한 서비스 간 통신 제공
  - 커널과 통신은 사용자 모듈 사이에서 메시지 전달을 통해 이루어짐
- 장점
  - 마이크로 커널을 확장하기 쉽다
  - 운영체제를 새로운 구조로 이식하기 쉽다
  - 커널에서 수행되는 코드가 적으므로 안정적이고 안전하다
- 단점 
  - 커널 공간과 통신하기 위한 사용자 공간의 성능 오버헤드 발생

7.4 모듈
- 적재 가능 모듈 : 커널은 핵심 구성요소 집합을 가지고 있고 부팅 때 또는 실행 중 부가 서비스들을 모듈을 통해 링크 한다
- 설계 주안점 : 커널은 핵심 서비스를 제공, 다른 서비스들은 커널이 실행되는 동안 동적으로 구현
- 대부분의 현대 운영체제는 커널 모듈을 구현
  - 객체 지향 접근 사용
  - 각 핵심 컴포넌트는 나뉘어 짐
  - 각 컴포넌트는 정해진 인터페이스를 통해 다른 컴포넌트와 대화
  - 각 컴포넌트는 커널 내에서 필요에 따라 적재 가능
- 모듈화 커널 접근법은 계층 구조 접근법과 유사
  - 모듈화 커널 접근법은 서브시스템들이 서로 정해진 인터페이스를 통해 상호 작용 하도록 요구
  - 각 부분이 정의되고 보호된 인터페이스를 가진다
  - 단, 모듈에서 임의의 다른 모듈을 호출할 수 있다는 점에서 계층구조보다 유연함
- 중심 모듈은 단지 핵심 기능만 가지고 다른 모듈 적재방법과 어떻게 통신하는지 안다는 점에서 마이크로 커널과 유사
  
  ![ex_screenshot](/res/os7.png) 
  
  ![ex_screenshot](/res/os8.png) 
  
8. 운영체제 디버깅
- 디버깅은 하드웨어와 소프트웨어에서의 시스템 오류를 발견하고 수정하는 행위
- 시스템에서 처리 중 발생하는 병목 현상을 제거해 성능을 향상시키려는 성능 조정도 포함

8.1 장애 분석
- 오류 정보를 로그 파일에 기록하고 프로세스가 사용하던 메모리를 캡처한 코어 덤프를 취하고 차후 분석을 위해 파일로 저장
- 커널 장애는 충돌로 불리며 프로세스 장애와 마찬가지로 오류 정보가 로그파일에 저장되고 메모리 상태가 충돌 덤프에 저장
8.2 성능 조정
- 처리 병목 지점을 제거함으로 성능을 향상하려함
  - 병목지점 발견을위해 시스템 성능을 감시할 수 있다
- 운영체제는 시스템 동작 추적 목록 생산
  - 관심 사건은 시간과 중요 매개변수와 함께 파일에 기록
  - 후에 분석 프로그램이 로그 파일을 처리하고 시스템 성능을 결정하고 병목지점, 비효율성을 발견한다
- 추적은 운영체제 동작의 오류를 발견하는 데 도움을 줄 수 있다

### 프로세스
1. 프로세스 개념 
- 프로세스 : 실행 중인 프로그램, 시분할 시스템에서 작업의 단위
- 스택, 데이터 섹션, 힙을 포함한다

1.2 프로세스 상태
  
  ![ex_screenshot](/res/os9.png)
  - 새로운(new) : 프로세스 생성 중
  - 실행(running) :  명령어들이 실행
  - 대기(wating) : 프로세스가 어떤 사건이 일어나길 기다림
  - 준비 완료(ready) : 프로세스가 처리기에 할당되기를 기다림
    - 프로세스 식별자 배정, 메모리 할당, 프로그램 적재, PCB 초기화, 스케줄링 추가
  - 종료(terminated) : 프로세스 실행이 종료
  
  - new -> ready : Job Scheduling
  - ready -> running : CPU Scheduling
  
1.3 프로세스 제어 블록(PCB)

  ![ex_screenshot](/res/os10.png) 
  
  - 프로세스 상태 : 상태는 new, ready, running, wating, halted 상태 등이 있다.
  - 프로그램 카운터 : 다음 실행할 명령어 주소를 가리킴
  - CPU 레지스터들 : 컴퓨터 구조에 따라 다양한 수와 타입을 가짐
    - 누산기, 인덱스 레지스터, 스택 레지스터, 범용 레지스터, 상태 코드 정보 포함
  - CPU-스케줄링 정보 : 프로세스 우선순위, 스케줄 큐에 대한 포인터, 다른 스케줄 매개변수들을 포함
  - 메모리 관리 정보 : OS에 의해 사용되는 메모리 시스템에 따라 기준 레지스터, 한계 레지스터 값, OS가 사용하는 메모리 시스템에 따라 페이지 테이블 or 세그먼트 테이블과 같은 정보 포함
  - 회계 정보 : CPU 사용 시간과 경과된 실시간, 시간 제한, 계정 번호, 잡 or 프로세스 번호 등을 포함
  - 입출력 상태 정보 : 이 프로세스에 할당된 입출력 장치들과 열린 파일의 목록 등을 포함

  ![ex_screenshot](/res/os11.png) 

2. 프로세스 스케줄링
- 다중 프로그래밍의 목적 : CPU 이용을 최대화하기 위해 항상 어떤 프로세스가 실행되도록 하는 데 있다
- 시분할 목적 : 각 프로그램이 실행되는 동안 사용자가 상호 작용할 수 있도록 프로세스들 사이에서 CPU를 빈번히 교체하는 것
- 프로세스 스케줄러는 CPU에서 실행 가능한 여러 프로세스들 중에서 하나의 프로세스를 선택

2.1 스케줄링 큐

  ![ex_screenshot](/res/os12.png) 
- 프로세스가 시스템에 들어오면 잡 큐(시스템 안의 모든 프로세스로 구성)에 놓여진다
- 준비 완료 상태에서 실행 대기하는 프로세스들은 준비 완료 큐라는 리스트 상에 유지된다
  - 큐의 헤더는 리스트의 첫번째와 마지막 PCB를 가리키는 포인터 포함
  - 각 PCB는 준비 완료 큐에 있는 다음 프로세스를 가리키는 포인터 필드를 가짐
- 특정 입출력 장치를 대기하는 프로세스들의 리스트를 장치 큐라고 하며 각 장치는 자신의 장치의 장치 큐를 가짐
- 새로운 프로세스는 처음 준비 완료 큐에 놓이며 실행을 위해 선택 될 때 CPU를 할당 받을 때까지 준비 완료 큐에서 대기한다
- 프로세스에 CPU가 할당되어 실행되면 여러 사건 중 하나가 발생
  - 프로세스가 입출력 요청을 하여 입출력 큐에 넣어질 수 있다
  - 프로세스가 새로운 자식 프로세스를 생성하고 자식 프로세스의 종료를 기다릴 수 있다
    - 대기 상태에서 중비 완료 상태로 전환되고 다시 준비 완료 큐에 넣어지게 된다
  - 프로세스가 인터럽트의 결과에 의해 강제로 CPU로부터 제거되고, 준비 완료 큐에 다시 놓일 수 있다
- 프로세스는 종료될 때까지 주기를 계속하며 종료되면 모든 큐에서 삭제되고 자신의 PCB의 자원을 반납한다

  ![ex_screenshot](/res/os13.png) 
2.2 스케줄러
- 장기 스케줄러(잡 스케줄러, new-> ready) : 프로세스들을 선택하여 실행하기 위해 메모리로 적재
- 단기 스케줄러(CPU 스케줄러, ready -> new) : 실행 준비가 완료되어 있는 프로세스들 중 선택해 CPU를 할당 
- 두 스케줄러의 차이점은 실행 빈도에 있음
  - 단기 스케줄러는 CPU를 위해 반드시 자주 새로운 프로세스를 선택해야한다.
  - 장기 스케줄러는 실행 빈도수가 훨씬 적고 다중 프로그램의 정도를 제어한다 
    - 다중 프로그래밍의 정도가 안정적이면 평균 프로세스 생성률이 시스템을 떠나는 평균 프로세스 이탈률과 반드시 동일해야함
- 입출력 중심 프로세스 : 연산보다 입출력 실행에 더 많은 시간을 소요하는 프로세스
- CPU 중심 프로세스 : 입출력 중심 프로세스보다 연산에 시간을 더 소요하여, 입출력 요청을 드물게 발생시키는 프로세스
- 장기 스케줄러는 입출력 중심과 CPU 중심 프로세스들의 적절한 프로세스 혼합을 선택하는 것이 중요

- 중기 스케줄러 : 메모리에서 프로세스들을 제거함으로써 다중 프로그래밍 정도를 완화하는 것이 핵심 아이디어 

  ![ex_screenshot](/res/os14.png) 
  - 차후 다시 프로세스를 메모리로 불러와 중단 시점에서부터 실행 재개 -> swapping
  - 스와핑은 프로세스 혼합 상태를 개선하기 위해 필요하기도 하며, 메모리 요구에 대한 변화가 가용 메모리에 비해 너무 많은 요규를 수용하여, 메모리를 자유화시키기 위해 필요하기도 함

2.3 문맥 교환
- 인터럽트 발생 시 시스템은 인터럽트 처리 후 문맥을 복구할 수 있도록 현재 실행 프로세스의 현재 문맥을 저장할 필요가 있다
- 문맥은 프로세스의 PCB에 표현
- 문맥 교환 : CPU를 다른 프로세스로 교환하려면 이전 프로세스의 상태를 보관하고 새로운 프로세스의 보관된 상태를 복구하는 작업
- 문맥 교환 발생 시, 커널은 과거 프로세스의 문맥을 PCB에 저장, 실행이 스케줄된 새로운 프로세스의 저장된 문맥을 복구
- 문맥 교환 시간은 순수한 오버헤드
- 운영체제가 복잡할 수록 문맥교환 시 해야할 작업 양이 많다. 

3. 프로세스에 대한 연산

3.1 프로세스 생성
- 생성하는 프로세스를 부모 프로세스, 새로운 프로세스는 자식 프로세스
- 유일한 프로세스 식별자(pid)를 사용해 구분, 각 프로세스에 고유한 값을 가지도록 할당
- pid가 1인 init 프로세스가 모든 사용자 프로세스의 루트 부모 프로세스 역할을 수행
- 프로세스가 자식 프로세스를 생성할 때, 자식 프로세스는 자신의 임무를 달성하기 위해 어떤 자원(CPU 시간, 메모리, 파일, 입출력 장치)이 필요
- 자식 프로세스는 자원을 운영체제로부터 직접 얻거나, 부모 프로세스가 가진 자원의 부분 집합만을 사용하도록 제한
- 부모 프로세스는 자원을 분할해 자식 프로세스에 나누어 주거나 메모리나 파일 같은 몇몇 자원은 자식 프로세스들이 같이 사용할 수 있다
- 부모 프로세스 자원의 일부분만 사용하도록 자식 프로세스가 쓸 수 있게 제한하며 자식 프로세스들을 많이 생성해 시스템을 과부하 상태로 만드는 프로세스를 방지 할 수 있다

- 프로세스가 새로운 프로세스 생성 시
  - 부모는 자식과 병행하게 실행을 계속한다
  - 부모는 일부 OR 모든 자식이 실행을 종료할 때까지 기다린다
- 새로운 프로세스들의 주소 공간 측면
  - 자식 프로세스는 부모 프로세스의 복사본(부모와 같은 프로그램과 데이터를 가짐)
  - 자식 프로세스가 자신에게 적재될 새로운 프로그램을 갖음
- UNIX 
  - 새로운 프로세스는 fork()로 호출, 원래 프로세스의 주소 공간의 복사본으로 구성
  - 부모 프로세스가 쉽게 자식 프로세스와 통신할 수 있게 한다
  - fork()의 복귀 코드가 서로 다르다
    - 자식 프로세스의 식별자가 부모로 복귀되지만, 새로운 프로세스는 '0'이 복귀된다
  - exec()는 자식의 메모리 공간을 새로운 프로그램으로 교체한다 (동시 실행)
  - 부모는 더 많은 자식을 생성할 수 있고, 자식이 실행하는 동안 할일 없으면, 자식이 종료될 때까지 준비 완료 큐에서 자신을 제거하기 위해 wait() 를 호출한다
  - 자식 프로세스에게 보이는 pid값은 0이고 부모 프로세스에게 보이는 pid값은 0보다 큰 정수값
  - 자식 프로세스는 열린 파일과 같은 자원, 특권, 스케줄링 속성을 부모 프로세스로부터 상속받고 부모는 wait()로 자식 프로세스가 끝나기 기다림
  - 부모와 자식은 같은 코드를 실행하는 병행 실행 프로세스
  - 자식은 부모의 복사본이기에 각 프로세스는 모든 데이터에 대해 자신만의 복사본을 가짐
3.2 프로세스 종료
- exit 시스템 호출을 사용해 운영체제에게 자신의 삭제를 요청하면 종료한다
- 프로세스는 자신의 부모 프로세스에게 상태값을 반환할 수 있고, 물리 메모리, 파일, 입출력 버퍼 등 프로세스의 모든 자원이 운영체제로 반환
- 한 프로세스는 적당 시스템 호출을 통해 다른 프로세스의 종료를 유발할 수 있다(부모만 호출 가능)
  - 부모가 자식의 pid를 알아야 종료시킬 수 있다
  - 새로운 프로세스 생성 시, 새로운 프로세스의 신원이 부모에게 전달된다
- 부모가 자식의 실행을 종료하는 경우
  - 자식이 자신에게 할당된 자원을 초과하여 사용할 때, 부모가 자식들의 상태를 검사할 수 있는 방편이 주어져야함
  - 자식에게 할당된 태스크가 더 이상 필요 없을 때
  - 부모가 exit 하는데, 운영체제는 부모가 exit한 후 자식이 실행을 계속하는 것을 허용하지 않는 경우
- 부모는 wait를 통해 자식 프로세스가 종료할 때를 기다리며 wait는 부모가 자식으이 종료 상태를 얻어낼 수 있도록 하나의 인자를 전달 받음
- wait는 부모가 어느 자식이 종료되었는지 구별할 수 있도록 종료된 자식 프로세스 식별자를 반환
- 좀비 프로세스 : 종료되었지만 부모 프로세스가 아직 wait를 호출하지 않은 프로세스
- 고아 프로세스 : 부모 프로세스가 wait를 호출하는 대신 종료할 때 자식 프로세스 

4. 프로세스간 통신

- 프로세스 협력을 허용하는 환경을 제공하는 이유
  - 정보 공유
  - 계산 가속화 : 병렬 실행
  - 모듈성
  - 편의성
- 협력적 프로세스들은 데이터와 정보를 교환할 수 있는 프로세스간 통신 기법을 필요로 함

 ![ex_screenshot](/res/os17.png) 
 
- 공유 메모리 모델
  - 협력 프로세스들에 의해 공유되는 메모리 영역이 구축
  - 프로세스들은 영역에서 데이터를 읽고 쓰고 함으로 정보를 교환
  - 공유 메모리 영역을 구축할 경우에만 시스템 호출이 필요
  - 메시지 전달 모델 보다 빠르다
  - 캐시 일관성 문제로 인해 성능 저하가 발생할 수 있다
- 메시지 전달 모델 
  - 협력 프로세스들 사이 교환되는 메시지를 통해 통신한다
  - 충돌을 회피할 필요가 없기에 적은 양의 데이터 교환을 하는데 유용
  - 통상 시스템 호출을 사용해 구현되므로 부가적 시간 소비 작업들이 필요로 하기에 공유 메모리 모델 보다 느리다
  - 많은 처리 코어를 가진시스템 사엥서는 메시지 전달이 더 나은 성능을 보인다
- 시스템 처리 코어의 수가 증가할수록 IPC로 메시지 전달이 선호될 수 있다

4.1 공유 메모리 시스템
- 공유 메모리 영역을 구축해야한다
- 공유 메모리 세그먼트를 생성하는 프로세스의 주소 공간에 위치 
- 통신 시 다른 프로세스들은 이 세그먼트를 자신의 주소 공간에 추가해야함
4.2 메시지 전달 시스템
- 동일 주소 공간을 공유하지 않고도 프로세스들이 통신하고, 동작을 동기화할 수 있도록 허용하는 기법을 제공
- 프로세스들이 네트워크에 의해 연결된 분산 환경에서 유용하다
- 프로세스 P와 Q가 통신을 원하면 반드시 서로 메시지를 보내고 받아야하며 통신 연결이 설정되어야 한다
- 통신 연결 
  - 직접 통신하에서 통신을 원하는 프로세스는 통신의 수신, 송신자의 이름을 명시해야한다
    - send(P, message) : 프로세스 P에게 메시지를 전송
    - reveive(Q, message) : 프로세스 Q로부터 메시지를 수신
    - 통신을 원하는 각 프로세스의 쌍들 사이 연결이 자동적으로 구축되며 서로 상대방의 신원만 알면 된다
    - 연결은 정확히 두 프로세스들 사이에만 연관
    - 각 쌍 사이에는 정확히 하나의 연결이 존재해야 한다
  - 주소 지정 시 비대칭을 사용하는 경우, 송신자만 수신자 이름을 지명한다
    - send(P, message) : 메시지를 프로세스 P에 전송
    - reveive(id, message) : 임의 프로세스로부터 메시지 수신, 변수 id는 통신을 발생시킨 프로세스의 이름
  -> 두 방법은 결과로 얻어지는 프로세스 정의의 제한된 모듈성이 있는 단점이 있다 
  
  - 간접 통신에서 메시지들은 메일박스 or 포트로 송신되고 수신된다
  - 메일박스는 프로세스들에 이해 메시지들이 넣어지고 제거될 수 있는 객체
  - 각 메일박스는 고유 id를 갖는다 
    - send(A, message) : 메시지를 메일박스 A로 송신
    - receive(A, message) : 메시지를 메일박스 A로부터 수신
    - 한쌍의 프로세스들 사이 연결은 프로세스가 공유 메일박스를 가질 때만 구축된다
    - 연결은 두 개 이상의 프로세스들과 연관될 수 있다
    - 통신하는 각 프로세스들 사이에는 다수의 서로 다른 연결이 존재할 수 있고, 각 연결은 하나의 메일박스에 대응된다 
  - 메일박스는 한 프로세스 OR 운영체제에 의해 소유될 수 있다
    - 프로세스에 의해 소유될 경우, 소유자와 메일박스 사용자를 구분 할 수 있고 메일 박스를 소유한 프로세스 종료시 메일박스는 사라지며 메일박스로 송신하는 프로세스들은 메일박스가 존재하지 않다는 사실을 통보 받아야 한다
    - 운영체제에 의해 소유한 경우 메일박스는 자체적으로 존재한다 (메일박스 생성, 송수신, 삭제 등을 제공해야함)
  - 메일박스 생성 프로세스는 디폴트로 메일박스의 소유자가 된다 

- 동기화
  - 봉쇄형 보내기 : 송신하는 프로세스는 메시지가 수신 프로세스 OR 메일박스에 의해 수신될 때까지 봉쇄
  - 비봉쇄형 보내기 : 송신하는 프로세스가 메시지를 보내고 작업을 재시작한다
  - 봉쇄형 받기 : 메시지가 이용 가능할 때까지 프로세스 봉쇄
  - 비봉쇄형 받기 : 송신하는 프로세스가 유효한 메시지 또는 NULL을 받음
  - send(), receive()가 모두 봉쇄형일 때, 우리는 송,수신자 간에 랑데부를 갖게된다 
- 버퍼링 
  - 무용량 : 큐의 최대 길이가 0이고, 링크는 자체 안에 대기하는 메시지들을 가질 수 없다 -> 송신자는 수신자가 메시지 수신할 때까지 기다림
  - 유한 용량 : 유한 길이 큐를 가지낟
  - 무한 용량 : 무한한 길이의 큐를 가지고 메시지들은 얼마든지 큐 안에서 대기할 수 있다
6. 클라이언트 서버 환경에서 통신 

6.1 소켓 
- 두 프로세스가 네트워크상에서 통신하려면 양 프로세스 마다 하나씩 소켓이 필요
- 소켓은 IP 주소, 포트 번호 두가지를 접합해 구별
- 클라이언트 프로세스가 연결을 요청하면 호스트 컴퓨터가 포트 번호를 부여
- 두 호스트 사이에 패킷들이 오갈 때 패킷들은 목적지 포트 번호가 지정하는 데 따라 적절한 프로세스로 배달딘다
- 모든 연결은 유일해야하며 모든 연결이 유일한 소켓 쌍으로 구성되는 것을 보장한다 

6.2 원격 프로시저 호출(RPC)
- 메시지 반 통신을 해야한다
- 각 메시지에는 원격지 포트에서 listen 중인 RPC 디먼의 주소가 지정되어 있고 실행되어야 할 함수 식별자, 그 함수에게 전달되어야 할 매개변수가 포함된다
- 네트워크 주소는 하나씩 갖지만 시스템에서 지원되는 여러 서비스를 구별하기 위해 포트를 여러개 가질 수 있다
- 원격 프로세스가 어떤 서비스를 받고자하면 서비스에 대응되는 적절한 포트 주소로 메시지를 보내야함
- RPC는 클라이언트가 원격 호스트 프로시저 호출하는 것을 자기 프로시저 호출 처럼 해준다
- RPC시스템은 클라이언트 쪽에 stub을 제공해 통신하는 데 필요한 자세한 사항들을 숨겨 준다
- 원격 프로시저 마다 다른 stub가 존재한다
- 클라이언트가 원격 프로시저 호출하면 RPC는 대응 stub를 호출하고 원격 프로시저가 필요로한 매개변수를 건네주고 stub가 원격 서버의 포트를 찾고 매개변수를 정돈 한다.
  - 매개 변수 전동 : 프로시저에게 갈 매개변수를 네트워크로 전송하기 위해 적절한  형태로 재구성하는 작업
- stub는 메시지 전달 기법을 사용해 서버에게 메시지를 전송한다.
- 대응 stub가 서버에 존재하여 서버측 stub가 수신후 적절 서버의 프로시저를 호출하고 필요한 경우 반환 값들도 동일 방식으로 되돌려 준다.

- 클라이언트와 서버의 데이터 표현 방식이 다른 경우 RPC 시스템은 기종 중립적인 데이터 표현 방식을 정의한다
  - 클라이언트 측에서 서버에 보내기전 매개변수 정돈 작업의 일환으로 전송 데이터를 XDR 형태로 바꾸어 보냄
  - 수신측에서 XDR을 받으면 매개변수를 풀어 자기 기종의 형태로 데이터 바꾼 후 서버에게로 전잘 
- 호출의 의미
  - 운영체제로 하여금 메시지가 최대 한 번 실행되는 것이 아니라 정확히 한번 처리되도록 보장하게 한다 
    - 응답 메시지 활용
- 클라이언트와 서버간 통신 문제
  - 고정된 포트 주소 형태로 미리 정해 놓는 방법
    - 컴파일 시 RPC에게는 고정된 포트 번호가 주어짐
  - 랑데부 방식에 의해 동적으로 바인딩하는 방법
    - 운영체제는 미리 정해진 고정 RPC 포트를 통해 랑데부용 디먼을 제공
    - 클라이언트가 실행을 원하는 RPC 이름을 담은 메시지를 랑데부 디먼에 보내 RPC 이름에 대응하는 포트 번호가 무엇인지 알려달라 요청
    - 포트 번호가 클라이언트에 반환되고 클라이언트는 포트 번호로 RPC 요청을 계속 보냄

  ![ex_screenshot](/res/os15.png) 
  
  ![ex_screenshot](/res/os16.png) 

6.3 파이프
- 파이프 : 두 프로세스가 통신할 수 있게 하는 전달자로서 동작
- 일반 파이프 : 생산자-소비자 형태로 두 프로세스 간 통신을 허용
  - 생산자는 파이프의 한 종단에 쓰고, 소비자는 다른 종단에서 읽음
  - 한쪽으로만 데이터 전송하며 오직 단반형 통신만 가능
  - 파이프를 생성한 프로세스 이외는 접근 할 수 없다
  - 통상 부모 프로세스가 파이프를 생성하고 fork()로 생성한 자식 프로세스와 통신하기 위해 사용
  - Windows 시스템의 일반 파이프는 익명 파이프라 불린다
  - 동일한 기계 상의 두 프로세스만 통신이 가능!
- 지명 파이프
  - 양방향으로 가능하며 부모-자식 관계도 필요로 하지 않음
  - 지명 파이프가 구축되면 여러 프로세스 들이 통신할 수 있다 
  - UNIX에서 FIFO라 부르며 반이중 전송만이 가능하며, 바이트-단위 통신만 허용
  - Windows는 전이중 통신을 하용하고 두 프로세스는 같은 기계 or 다른 기계 상에 존재할 수 있고, 바이트-단위 or 메시지-단위 데이터 전송 허용

### 스레드 
- 스레드는 CPU 이용의 기본 단위이며 스레드 ID, PC(프로그램 카운터), 레지스터 집합, 스택으로 구성
- 같은 프로세스에 속한 다른 스레드, 코드, 데이터 섹션, 운영체제 자원들을 공유한다
- 단일 스레드와 다중 스레드
  
  ![ex_screenshot](/res/os18.jpg)

  ![ex_screenshot](/res/os16.png)

1.2 장점 
- 응답성 : 사용자에 대한 응답성을 증가시킨다
- 자원 공유 : 프로세스는 공유 메모리와 메시지 전달 기법을 통해 자원을 공유
  - 스레드는 자동적으로 그들이 속한 프로세스의 자원들과 메모리를 공유
  - 코드와 데이터 공유의 이점은 한 응용 프로그램이 같은 주소 공간 내 여러 개의 다른 작업을 하는 스레드를 가질 수 있다는 점
- 경제성 : 자원을 공유하기에 스레드를 생성하고 문맥 교환하는 것이 프로세스를 생성을 위해 자원 할당 하는 것 보다 경제적이다
- 규모 적응성 : 다중 처리기 구조에서 더욱 증가 할 수 있다
  - 다중 처리기 구조에서는 각 스레드가 다른 처리기에서 병렬로 수행될 수 있기 때문

2. 다중코어 프로그래밍
- 코어가 여러 CPU칩 형태를 띠거나 칩 안에 여러 개가 존재한 시스템 (다중코어 OR 다중 처리기 시스템)
- 다중 스레드 프로그래밍은 다중 계산 코어를 더 효율적으로 사용할 수 있고 병행 실행을 더 향상 시킬 수 있는 기법을 제공
- 병행성은 스레드들이 병렬적으로 실행될 수 있다는 것을 의미
- 병렬 : 하나 이상의 태스크를 동시에 수행할 수 있는 시스템
- 병행 : 모든 태스크가 진행하게끔 함으로써 하나 이상의 태스크를 지원 

2.2 병렬 실행의 유형 
- 데이터 병렬 실행 : 동일 데이터의 부분집합을 다수 계산 코어에 분배한 뒤 각 코어에 동일한 연산을 실행하는데 초점을 맞춤
  - 데이터가 코어에 분배되어야함
- 태스크 병렬 실행 : 태스크를 다수의 코어에 분배하고 각 스레드는 고유 연산을 실행
  - 태스크가 분배되어야 함
-> 두 전략을 혼용하여 사용

3. 다중 스레드 모델

3.1 다대일 모델 : 많은 사용자  수준 스레드를 하나의 커널 스레드로 사상
- 사용자 공간 스레드 라이브러리에 의해 스레드 관리가 행해짐 -> 효율적
- 한 스레드가 봉쇄형 시스템 콜을 할 경우 전체가 봉쇄
- 한번에 하나의 스레드만 커널에 접근할 수 있기에 병렬로 실행할 수 없다

3.2 일대일 모델 : 사용자 스레드를 각 하나으 ㅣ커널 스레드로 사상
- 다대일 델보다 더 많은 병렬성을 제공하고 다중 스레드가 병렬로 수행되는 것을 허용
- 사용자 수준 스레드를 생성할 때 커널 스레드를 생성해야하는 단점이 있음
- 커널 스레드를 생성하는 오버헤드가 성능을 저하할 수 있음 -> 시스템에 의해 지원되는 스레드 수 제한

3.3 다대다 모델 : 여러 개의 사용자 수준 스레드를 적은수 혹은 같은 수의 커널 스레드로 멀티플렉스 한다
- 필요한 만큼 사용자 수준 스레드를 생성할 수 있고 상응하는 커널 스레드가 다중 처리기에 의해 병렬로 수행될 수 있다
- 다대다 모델의 변형으로 한 사용자 스레드가 하나의 커널 스레드에만 연관되는 것을 허용하는 두 수준 모델이 있다

  ![ex_screenshot](/res/os20.png)
  
  ![ex_screenshot](/res/os21.jpg)
  
4. 스레드 라이브러리
- 프로그래머에게 스레드를 생성하고 관리하기 위한 API를 제공
- 구현 방법
  - 커널의 지원 없이 완전히 사용자 공간에서만 라이브러리를 제공하는 것
    - 라이브러리를 모든 코드와 자료구조는 사용자 공간에 존재
    - 함수 호출하는 것은 사용자 공간의 지역 함수를 호출하게 된다는 것을 의미
  - 운영체제에 의해 지원되는 커널 수준 라이브러리를 구현하는 것
    - 라이브러리를 위한 코드와 자료구조는 커널 공간에 존재
    - 라이브러리 API 호출은 커널 시스템 호출을 부르는 결과 
  
  - 비동기 스레딩 : 부모가 자식 스레드 생성 후 부모는 자신의 실행을 재개하여 부모와 자식 스레드가 병행하게 실행
    - 각 스레드는 독립적으로 실행하고 부모 스레드는 자식의 종료를 알 필요 없음
  - 동기 스레딩 : 부모 스레드가 하나 이상의 자식 스레드를 생성하고 자식 스레드 모두가 종료할 때까지 기다렸다 자신의 실행을 재개하는 방식
    - 포크-조인 전략
    - 부모가 생성한 스레드는 병행하게 실행되지만 부모는 자식들의 작업이 끝날 때 까지 실행을 계속할 수 없음
    - 모든 자식 스레드가 조인한 후에 실행을 재개할 수 있다
    - 상당한 야야의 데이터 공유를 수반한다

4.3 자바 스레드
- 스레드 생성 기법
  - Thread 클래스로부터 파생된 새로운 클래스를 생성하고 Thread 클래스의 run() 메서드를 무효화 하는 것
  - Runnable 인터페이스를 구현하는 클래스를 정의하는 것
    - 스레드 생성은 Thread 클래스의 객체 인스턴스를 생성하고 Runnable 객체의 컨스트럭트를 전달함으로 이루어짐
    - start 메서드가 새로운 스레드를 생성
      - 메모리가 할당되고 JVM 내에 새로운 스레드가 초기화
      - run() 메서드를 호출하면 스레드가 JVM에 의해 수행될 자격을 갖게 한다.
    <pre><code>
      class Sum{
        private int sum;
        public int getSum(){
          return sum;
        }
        public void setSum(int sum){
          this.sum = sum;
        }
      }
      
      class Summation implements Runnable
      {
        private int upper;
        private Sum sumValue;
        public Summation(int upper, Sum sumValue){
          this.upper = upper;
          this.sumValue = sumValue;
        }
        public void run(){
          int sum = 0;
          for(int i =0; i<=upper; i++)
            sum+=i;
          sumValue.setSum(sum);
         }
       }
       
       public class Driver
       {
        public static void main(String[] args){{
          if(args.length>0){
            if(Integer.parseInt(args[0] <0)
              System.out.println(args[0] + " must be >=0.");
            else{
              Sum sumObject = Sum(); // 공유 객체
              int upper = Integer.parseInt(args[0]);
              // 스레드 생성 및 실행
              Thread thrd = new Thread(new Summation(upper, sumObject));
              thrd.start();
              try{
                thrd.join();
                System.out.println("The sum of " + upper+" is " + sumObject.getSum());
              }catch(InterruuptedException e){}
             }
           else
            System.out.println("m of " + upper+" is " + sumObject.getSum());
         }
        }
    </code></pre>

5. 암묵적 스레딩
- 스레딩 생성과 관리 책임을 응용 개발자로부터 컴파일과 실행시간 라이브러리에게 넘겨주는 것
5.1 스레드 풀 : 프로세스를 시작할 때 일정한 수의 스레드를 미리 풀로 만들어 두는 것
- 요청이 들어오면 풀에서 한 스레드에게 할당하고 요청을 다하면 스레드는 다시 풀로 돌아가 작업을 기다림
- 장점
  - 새 스레드를 만들어 주는 것 보다 기존 스레드로 서비스하는 것이 빠름
  - 스레드 개수에 제한을 두며 많은 스레드를 병렬 처리할 수 없는 시스템에 도움이 됨
  - 태스크를 생성하는 방법을 태스크로부터 분리하면 태스크 실행을 다르게 할 수 있음
- 스레드 개수는 CPU 수, 물리 메모리 용량, 동시 요청 클라이언트 개수를 고려해 정해질 수 있고 동적으로 풀의 크기를 바꿔 줄 수도 있다

5.2 OpenMP : C++, C, FORTRAN으로 작성된 API와 컴파일러 디렉티브의 집합
- 공유 메모리 환경에서 병렬 프로그래밍을 할 수 있도록 도움을 주고 병렬로 실행될 수 있는 블록을 찾아 병렬 영역이라 부른다
- 병렬 영역에 컴파일러 디렉티브를 삽입하고 OpenMP 실행시간 라이브러리에 해당 영역을 병렬로 수행하라고 지시
- 병렬화를 위한 디렉티브를 제공할 뿐아니라 개발자가 병렬화 수준을 선택할 수 있게 해줌

5.3 Grand Central Dispatch : Apple의 Max OS X와 iOS 운영체제를 위한 기술로 C, API 및 실행시간 라이브러리 각각 확장해 조합한 기술
- 개발자가 병렬로 실행될 수 있는 영역을 식별할 수 있게 도움을 준다
- C, C++ 언어를 확장한 블록을 식별하고 블록은 독립적으로 실행될 수 있는 작업 단위이다
- ^{ printf("I am a block"); }
- 블록을 디스패치 큐에 넣어 실행될 수 있도록 스케줄 한다
- 직렬과 병행의 두가지 유형의 디스패치 큐를 유힌다
  - 직렬 큐는 넣어진 블록은 FIFO 순서대로 제거되고 각 프로세스는 각자 직렬 큐를 가짐
  - 병행 큐는 FIFO 순으로 제거되지만 여러 블록이 동시에 제거 될 수 있으며 여러 블록이 동시에 병렬로 실행되는 것이 가능

6. 스레드와 관련된 문제들

6.1 Fork() 및 Exec() 시스템 호출
- fork() 모든 스레드를 복사하는 것, fork()를 호출한 스레드만 복사 둘 중 어떠한 것을 사용하는지에 따라 다름
6.2 신호처리
- 신호는 프로세스에게 어떤 사건이 일어났음을 알려주기 위해 사용
- 동기식 or 비동기식으로 전달 될 수 있음
- 신호는 특정 사건이 일어나야 생성된다
- 생성된 신호가 프로세스에게 전달된다
- 신호가 전달되면 반드시 처리되어야 한다
- 동기적 신호는 신호를 발생시킨 연산을 수행한 동일 프로세스에게 전달되고 비동기식 신호는 신호가 실행중인 프로세스 외부로부터 발생되는 것을 말함
- 디폴트 신호 처리기 모든 신호마다 커널이 실행시키는 것이고 신호를 처리하기 위해 호출되는 사용자 정의 처리기에 의해 대체도리 수 있다

6.3 취소
- 스레드 취소는 스레드가 끝나기 전 그것을 강제 종료시키는 작업
- 취소되어야 할 스레드를 목적 스레드라 부른다
- 목적 스레드 취소 방식
  - 비동기식 취소 : 한 스레드가 즉시 목적 스레드를 강제 종료
  - 지연 취소 : 목적 스레드가 주기적으로 자신이 강제 종료되어야 할지 점검, 목적 스레드가 질서정연하게 강제 종료될 수 있는 기회가 만들어짐
- 스레드 취소를 어렵게 만드는 것
  - 할당된 자원
  - 다른 스레드와 공유하는 자료구조를 갱신하는 도중 취소 요청 -> 모든 자원 시스템을 회사하지 못하는 경우도 있음
- 지연 취소는 목적 스레드가 취소 여부를 경정하기 위한 플래그를 검사 한 후 일어나고 자신이 취소되어도 안전하다 판단되는 시점에 취소 여부를 검사할 수 있다.
- 디폴트 취소는 지연 취소이며 취소점에 도달했을 때만 취소 작업이 일어남

6.4 스레드 국지 저장소
- 한 프로세스에 속한 스레드들은 프로세스의 데이터를 모두 공유하지만 상황에 따라 각 스레드가 자기만 액세스할 수 있는 데이터를 가져야할 필요가 있는데 이러한 데이터를 스레드 국지 저장소라함
- TLS은 전체 함수 호출에 걸쳐 보이고 TLS 데이터는 각 스레드의 고유한 정보를 저장한다

6.5 스케줄러 액티베이션
- 다대다 OR 두 수준 모델을 구현하는 많은 시스템들은 사용자, 커널 스레드 사이 중간 자료 구조를 두고 경량 프로세스(LWP)라고 함
- LWP 방식은 응용이 사용자 스레드를 수행하기 위해 스케줄 할 가상 처리기처럼 보인다
- 각 LWP는 하나의 커널 스레드에 부속되었으며 물리 처리기에 스케줄 하는 대상은 커널 스레드이다
- 통상 동시 발생하는 봉쇄형 시스템 호출마다 하나의 LWP가 필요하다

  ![ex_screenshot](/res/os22.png)
  
- 사용자 스레드 라이브러리와 커널 스레드 간 통신 방법 중하나는 스케줄 액티베이션이다
  - 커널은 응용에게 가상 처리기의 집합을 제공하고 으용은 사용자 스레드를 가용한 가상 처리기로 스케줄
  - 커널은 응용에게 특정 사건에 대해 알려줘야하며 이 프로세저를 upcall이라 부름
  - Upcall은 스레드 라이브러리의 upcall 처리기에 의해 처리되고 upcall 처리기는 가상 처리기 상에서 실행되어야 한다
  - upcall 처리기를 일으키는 한 사건은 응용 스레드가 봉쇄하려고 할 때 발생
  - 커널은 스레드가 봉쇄하려는 사실과 스레드의 식별자를 알려주는 upcall을 수행하고 커널은 새로운 가상 처리기를 응용에게 할당
  - 응용은 새로운 가상 처리기 상에서 upcall 처리기를 수행하고 upcall 처리기는 봉쇄 스레드 상태를 저장하고 스레드가 실행 중이던 가상 처리기를 반환
  - upcall 처리기는 새로운 가상 처리기에서 실행 가능한 다른 스레드를 스케줄하고 봉쇄 스레드가 기다리던 사건 발생 시 커널은 이전 봉쇄된 스레드가 실행 가능하다는 사실을 알려주는 다른 upcall을 스레드 라이브러리에게 한다
  - upcall처리기도 가상 처리기가 필요하고 커널은 새로운 가상 처리기를 할당하거나 사용자 스레드 하나를 선점해 처리기에서 upcall 처리기를 실행한다
  - 봉쇄가 풀린 스레드를 실행 가능 상태로 표시후 응용은 가용한 가상 처리가 상에서 다른 실행 가능 스레드 실행
  
### CPU 스케줄링
- 다중 프로그래밍의 목적은 CPU 이용률을 최대화하기 위해 항상 실행 중인 프로세스를 가지게 함에 있다
- CPU 스케줄링은 운영체제 설계의 핵심

1.2 CPU 스케줄러
- CPU가 유휴 상태가 될 때마다, 운영체제는 준비 완료 큐에 있는 프로세스들 중 하나를 선택해 실행
- 선택 절차는 단기 스케줄러에 의해 수행
- 스케줄러는 실행 준비가 되어 있는 메모리 내 프로세스들 중 선택해 CPU를 할당

1.3 선점 스케줄링
- 4가지 상황에서 CPU 스케줄링 결정이 발생
  - 한 프로세스가 실행 상태에서 대기 상태로 전환될 때
  - 프로세스가 실행 상태에서 준비 완료 상태로 전환될 때
  - 프로세스가 대기 상태에서 준비 완료 상태로 전환 될 때
  - 프로세스가 종료될 때
- 선점 스케줄링은 데이터가 다수의 프로세스에 의해 공유될 때 경쟁 조건 초래

1.4 디스패처
- 디스패처는 CPU 제어를 단기 스케줄러가 선택한 프로세스에 주는 모듈이며 다음 작업을 포함
  - 문맥 교환 
  - 사용자 모드로 전환
  - 프로그램을 다시 시작하기 위해 사용자 프로그램의 적절 위치로 이동하는 일
  - 디스패처는 모든 프로세스의 문맥 교환 시 호출되며, 가능한 최고로 빨리 수행되어야 함
  - 디스패처 하나가 프로세스를 중지하고 다른 프로세스의 수행을 시작하는 데 소요되는 시간 -> 디스패치 지연
  
2. 스케줄링 기준
- CPU 이용률 : 가능한 CPU를 최대한 바쁘게 유지하기를 원함
- 처리량 : CPU가 프로세스 수행시 바쁘면 작업이 진행되고 있는것, 작업량 측정 방법은 단위 시간당 완료된 프로세스 갯수
- 총처리 시간 : 프로세스 실행 동안 소요된 시간 중요!
- 대기 시간 : 스케줄링 알고리즘은 단지 프로세스가 준비 완료 큐에 대기하는 시간의 양에만 영향을 줌
- 응답 시간
- CPU 이용률과 처리량을 최대화하고 총 처리 시간, 대기 시간, 응답 시간을 최소화 하는 것이 바람직

3. 스케줄링 알고리즘
3.1 선입선출 알고리즘(FCFS)
- 선입 선처리 스케줄링에서는 먼저 요청하는 포로세스가 CPU를 먼저 할당 받음
- 프로세스가 준비 완료 큐에 진입하면 프로세스의 프로세스 제어 블록을 큐의 끝에 연결
- CPU가 자유 상태가 되면 준비 완료 큐의 앞부분에 있는 프로세스에 할당
- 평균 대기 시간을 일반적으로 최소가 아니며, 프로세스 CPU 버스트 시간이 크게 변할 경우 평균 대기 시간도 변할 수 ㅣㅇㅆ다
- 모든 다른 프로세스 들이 하나의 긴 프로세스가 CPU를 양도하기 기다리는 것 -> 호위 효과
  - 짧은 프로세스들이 먼저 처리 되도록 허용할 때보다 CPU와 장치 이용률이 저하되는 결과를 낳음
- 한 프로세스가 지나치게 오랜 동안 CPU 점유시 손해가 클 것

3.2 최단 작업 우선 스케줄링
- CPU가 이용가능하면 가장 작은 다음 CPU 버스트를 가진 프로세스에게 할당
- 프로세스 전체 길이가 아니라 다음 CPU의 버스트 길이에 의해 스케줄링 -> 최단 다음 CPU 번스트
- 주어진 프로세스 집합에 대해 최소 평균 대기 시간을 가진다
- 다음 CPU 요청 길이 파악이 어려운 문제점!!
- SJF 스케줄링은 장기 스케줄링에서 자주 사용
  - 단기 스케줄링에서는 다음 CPU 버스트 길이를 알 수 있는 방법이 없음
  - 한가지 접근 방식은 다음 CPU 버스트 길이를 예측하는 것
- SJF 알고리즘은 선점 OR 비선점형일 수 있음
  - 선점형 SJF 알고리즘은 현재 실행 프로세스를 선점
  - 비선점 SJF 알고리즘은 현재 실행 프로세스가 자신의 CPU 버스트를 끝내도록 허용
- 선점형 SJF 알고리즘은 때로 최소 잔여 시간 우선 스케줄링이라고도 함

3.3 우선순위 스케줄링
- 우선순위가 프로세스들에게 연관되어 있으며, CPU는 가장 높은 우선순위를 가진 프로세스에게 할당
- 우선순위가 같을 경우 FCFS 순서로 스케줄
- 내부적 우선순위는 프로세스의 우선순위를 계산하기 위해 어떤 측정 가능한 양들을 사용(시간제한, 메모리 요구, 열린 파일 수, 평균 CPU 버스트 비율 등)
- 외부적 우선순위는 프로세스 중요성, 비용, 타입 등과 같은 운영체제 외부적 기준에 의해 결정
- 선점형이거나 비선점형이 될 수 있다
- 프로세스가 준비 완료 큐에 도착하면, 새로 도착한 프로세스의 우선순위를 현재 실행 프로세스의 우선순위와 비교
  - 선점형일경우 새로 도착한프로세스 우선순위가 현재 실행 프로세스보다 높다면 CPU 선점
  - 비선점일 경우 준비완료 큐의 머리 부분에 새로운 프로세스 넣음
- 무한 봉쇄 OR 기아 상태가 우선순위 스케줄링의 주요 문제점!!
  - 낮은 우선순위 프로세스들이 CPU를 무한히 대기하는 경우 발생 가능
  - 부하가 과중한 컴퓨터 시스템 시 높은 우선순위 프로세스들이 꾸준히 들어와 낮은 우선순위 프로세스들이 CPU를 얻지 못할 수 있음
  - 결국 낮은 우선순위 프로세스를 잃는 경우가 발생할 수 있음
- 무한 봉쇄 문제 해결하는 방법은 노화
  - 오랫동안 시스템에서 대기하는 프로세스들의 우선순위를 점진적으로 증가 시킨다

3.4 라운드 로빈 스케줄링
- 시분할 스템을 위해 설계되었음
- 선입선출 스케줄링과 유사하나 시스템이 프로세스들 사이를 옮겨 다닐 수 있도록 선점이 추가
- 시간 할당량이라는 작은 단위의시간을 정의
- 준비 완료 큐는 원형 큐로 동작
- CPU 스케줄러는 준비 완료 큐를 돌면서 한 번에 한 프로세스에게 한 번의 시간 할당량 동안 CPU를 할당

- 첫 번째 프로세스 선택해 한 번의 시간 할당량 이후 인터럽트를 걸도록 타이머 설정 후, 프로세스를 디스패치한다
  - CPU 버스트가 한 번의 시간 할당량보다 작을 경우
    - 자신이 CPU를 자발적으로 방출 -> 준비 완료 큐에 있는 다음 프로세스로 진행
  - CPU 버스트가 한 번의 시간 할당량보다 클 경우
    - 타이머 끝나고 운영체제에게 인터럽트를 발생 -> 문맥 교환이 일어나고 실행 프로세스는 준비 완료 큐의 꼬리에 넣어짐 -> CPU 스케줄러는 준비 완료큐의 다음 프로세스 선택

- RR 알고리즘의 성능은 시간 할당량 크기에 매우 많은 영향을 받음
  - 시간 할당량이 크면, 선입 선처리 정책과 같음
  - 시간 할당략이 작으면, 매우 많은 문맥교환을 야기
  -> 시간 할당량이 문맥 교화나 시간에 비해 클 것을 원함
- 총처리 시간 역시 시간 할당량의 크기에 좌우
  - 대부분 프로세스들이 단일 시간 할당량 안에 다음 cpu 버스트 끝내면 평균 총 처리시간은 개선된다
- 시간 할당량이 문맥 교환 시간에 비해 커야하나 너무 커서는 안된다 -> CPU 버스트의 80%는 시간 할당량보다 짧아야 한다

3.5 다단계 큐 스케줄링
- 준비 완료 큐를 다수의 별도 큐로 분류한다
- 프로세스들인 메모리 크기, 프로세스 우선순위 같은 특성에 따라 한 개의 큐에 영구적으로 할당
- 각 큐는 자신의 스케줄링 알고리즘을 갖고 있다
- 큐와 큐 사이에 스케줄링도 반드시 있어야 하며, 고정 우선순위의 선점형 스케줄링으로 구현된다

  ![ex_screenshot](/res/os23.png)

3.6 다단계 피드백 큐 스케줄링
- 다단계 큐 스케줄링은 프로세스들이 시스템 진입 시 영구적으로 하나의 큐에 할당 -> 스케줄링 오버헤드가 장점이나 융통성이 적다
- 다단계 피드백 큐에서는 프로세스가 큐들 사이를 이동하는 것을 허용
- 프로세스들을 CPU 버스트 성격에 따라 구분
  - CPU 시간을 너무 많이 사용하면 낮은 우선순위 큐로 이동
  - 입출력 중심 프로세스와 대화형 프로세스들을 높은 우선순위 큐에 넣음
  - 낮은 우선순위 큐에서 너무 오래 기다린 프로세스는 높은 우선순위 큐로 이동 -> 기아 상태를 예방
- 다단계 피드백 큐 스케줄러는 다음 매개변수에 의해 정의된다
  - 큐의 개수
  - 각 큐를 위한 스케줄링 알고리즘
  - 한 프로세스를 높은 우선순위 큐로 올려주는 시기 결정 방법
  - 한 프로세스를 낮은 우선순위 큐로 강등하는 시기 결정 방법
  - 프로세스가 서비스 필요 시 프로세스가 들어갈 큐 결정 방법
  
4. 스레드 스케줄링
- 다대일, 다대다 모델 구현 시스템에서는 스레드 라이브러리는 사용자 수준 스레드를 가용한 LWP 상에서 스케줄 한다
  - 동일 프로세스에 속한 스레드들 사이에 CPU를 경쟁하기에 프로세스-경쟁-범위라고 한다
  - 우선순위에 따라 행해진다 
- CPU 상에 어느 커널 스레드를 스케줄 할 것인지 결정하기 위해 커널은 시스템-경쟁 범위를 사용
  - CPU에 대한 경쟁은 시스템 상 모든 스레드 사이에서 일어남

5. 다중 처리기 스케줄링

5.1 다중 처리기 스케줄링에 대한 접근 방법
- 비대칭 다중 처리 사용
  - 주 서버라는 하나의 처리기가 모든 스케줄링 결정과 입출력 처리, 다른 시스템의 활동을 취급하게 하는 것
  - 다른 처리기들은 다만 사용자 코드만을 수행
  - 단지 한 처리기만 시스템 자료구조를 접근해 자료 공유의 필요성을 배제하기에 간단하다
- 대칭 다중 처리를 사용
  - 각 처리기가 독자적으로 스케줄링
- 서로 다른 2개의 처리기가 같은 프로세스를 선택하지 않아야 하며 프로세스들이 큐에서 사라지지 않는다는 것을 보장해야 한다

5.2 처리기 친화성
- 처리기에 의해 가장 최근에 접근된 데이터가 처리기의 캐시를 채우게 됨
- 캐시를 무효화 하고 다시 채우는 작업은 비용이 많이 들기 때문에 대부분 SMP 시스템은 한 처리기에서 다른 처리기의 이주를 피하고 같은 처리기에서 프로세스를 실행하려고 하는데 이를 처리기 친화성이라 한다
- 프로세스가 현재 실행 중인 처리기에 친화성을 가진다는 것을 의미
- 연성 친화성 : 운영체제가 동일 처리기에서 프로세스를 실행시키려 노력하는 정책을 갖지만, 보장하지 않는 경우
- 강성 친화성 : 시스템 호출을 통해 프로세스는 자신이 실행될 처리기 집합을 명실할 수 있는 경우
- 대부분 연성, 강성 친화성을 모두 지원한다.

5.3 부하 균등화
- 처리가가 하나 이상이라는 것을 최대한 활용하려면 부하를 모든 처리기에 균등하게 배분하는 것이 중요!
- 부하 균등화는 SMP 시스템의 모든 처리기 사이에 부하가 고르게 배분되도록 시도한다
- 각 처리기가 실행할 프로세스를 위한 자기 자신만의 큐를 가지고 있는 시스템에서만 필요한 기능임을 주의!
- PUSH 이주 : 특정 태스크가 주기적으로 각 처리기의 부하를 검사하고 불균형 상태이면 과부하인 처리기에서 쉬고 있거나 덜 바쁜 처리기로 프로세스를 이동시킴으로 부하를 분배
- PULL 이주 : 쉬고 있는 처리기가 바쁜 처리기를 기다리고 있는 프로세스를 PULL 할때 발생
-> 둘은 병렬적으로 구현딘다.

5.4 다중코어 프로세서
- 각 프로세스가 자신의 물리 칩을 가지는 시스템에 비해 속도가 쁘르고 적은 전력을 소모
- 스케불링 문제를 복잡하게 한다
  - 메모리 멈춤 : 프로세스가 메모리 접근 시 데이터가 가용해지기를 기다리며 많은 시간을 허비
    - 캐시 미스 등 여러원인이 이유
- 처리기를 다중 스레드화 하는 방법
  - 거친 다중 스레딩 : 스레드가 메모리 멈춤과 같은 긴 지연시간을 가지 사건 발생 시까지 한 처리기에서 수행
    - 처리기는 다른 스레드 실행
    - 스레드간 교환 비용이 많이 든다
  - 세밀한 다중 스레딩 : 보통 명령어 주기의 경계에서 같이 좀 더 세밀한 정밀도를 가진시점에 스레드 교환이 일어남
    - 세밀한 시스템의 구조적 설계는 스레드 교환을 위한 회로를 포함 -> 스레드간 교환 비용이 적어짐
- 다중 스레드 다중코어 프로세스는 두가지 스케줄링이 필요
  - 소프트웨어 스레드가 각 하드웨어 스레드에서 실행되어야 하는지 운영체제가 결정 하는 것
  - 각 코어가 어떤 하드웨어 스레드를 실행시킬지 지정해야 하는 것
  
6. 실시간 CPU 스케줄링
- 연성 실시간 시스템 : 오직 중요한 프로세스가 그렇지 않은 프로세스들에 비해 우선권을 가진다는 것만 보장
- 경성 실시간 시스템 : 엄격한 요구조건을 만족
  - 태스크는 반드시 마감시간까지 서비스 받아야 하며 마감시간이 지난 후 서비스 받은 것은 서비스를 전혀 받지 않는 것과 동일 결과

6.1 지연 시간 최소화
- 사건 지연 시간 : 사건이 발생해서 그에 맞는 서비스가 수행될 때까지의 시간
- 두가지 유형의 지연시간이 실시간 시스템 성능을 좌우
  - 인터럽트 지연 시간 : CPU에 인터럽트가 발생한 시점부터 해당 인터럽트 처리 루틴이 시작하기까지 시간
    - 인터럽트 지연시간을 최소화하는것이 실시간 운영체제에게 매우 중요한 일
    - 실시간 운영체제는 인터럽트 불능 시간을 매우 짧게 해야한다
  - 디스패치 지연 시간 : 스케줄링 디스패처가 하나의 프로세스를 블록시키고 다른 프로세스를 시작하게 하는데 걸리는 시간
    - 실시간 운영체제는 이 지연 시간을 최소화해야한다
    - 가장 효과적인 방법은 선점형 커널이다
    
8. 알고리즘 평가
- 알고리즘을 선택하는 데 사용할 기준을 정의하는 것
  - CPU 이용률, 응답시간, 처리량에 의해 기준이 정의됨
- 최대 응답 시간이 1초라는 제약 조건 하에 CPU 이용률을 극대화 한다
- 총 처리 시간이 전체 실행 시간에 평균적으로 선형 비례가 되도록 처리량을 극대화 한다

8.1 결정론적 모델링
- 분석적 평가 : 주어진 작업 부하에 대한 알고리즘 성능을 평가하는 공식이나 값을 생성하기 위해 주어진 알고리즘과 시스템 작업 부하를 이용
- 결정론적 모델링은 분석적 평가의 한가지 유형
  - 사전에 정의된 특정한 작업 부하를 받아들여 그 작업 부하에 대한 각 알고리즘 성능을 정의
  - 단순하고 빠르며, 알고리즘들을 비교할 수 있도록 정확한 값을 제공한다
  - 정확한 숫자를입력으로 요구하며, 응답도 단지 이들의 경우에만 적용하는 단점이 있다
  - 주로 스케줄링 알고리즘을 설명하고 예를 제공하는데 사용

### 프로세스 동기화
- 협력적 프로세스 : 시스템 내에서 실행중인 다른 프로세스의 실행에 영향을 주거나 영향을 받는 프로세스
  - 논리 주소 공간을 직접 공유하거나 파일 or 메시지에 의해 데이터의 공유가 허용
- 경쟁 상황 : 동시에 여러 개의 프로세스가 동일한 자료를 접근하여 조작하고 실행 결과가 접근이 발생한 특정 순서에 의존하는 상황
2. 임계구역 문제
- 한 프로세스가 자신의 임계구역에서 수행하는 동안 다른 프로세스들은 임계구역에 들어갈 수 없다
- 프로세스들이 협력할 때 사용할 수 있는 프로토콜을 설계하는 것
- 해결하기 위한 요구조건
  - 상호 배제(mutual exclusion) : 프로세스 p가 자기 임계구역에서 실행된다면, 다른 프로세스들은 그들 자신의 임계구역에서 실행될 수 없음
  - 진행(progress) : 자기 임계구역에서 실행되는 프로세스 없고 임계구역으로 진입하려는 프로세스가 있다면 나머지 구역에서 실행중이지 않은 프로세스들만 다음 임계구역으로 진입할 지 결정에 참여 가능, 이 선택은 무한정 연기될 수 없음
  - 한정된 대기(bounded wating) : 임계구역 진입 요청 후부터 허용때까지 다른 프로세스들이 임계구역에 진입하도록 허용되는 횟수에 한계가 있다
- 운영체제 내에서 임계구역을 다루기 위해 선점형 커널, 비선점형 커널 두 가지 접근법 사용
  - 선점형 커널 : 프로세스가 커널 모드에서 수행되는 동안 선점하는 것 허용
  - 비선점형 커널 : 커널 모드에서 수행되는 프로세스의 선점을 허용않고 커널 모드 프로세스는 커널을 빠져나갈 때까지 or 봉쇄될 때까지 or 자볼적으로 CPU 제어를 양보할 때까지 계속 수행

3. 피터슨의 해결안
- 임계 구역과 나머지 구역을 번갈아 실행하는 두 개의 프로세스로 한정
- 두 프로세스가 두 개의 데이터 항목을 공유하도록 하여 해결
- int turn; (임계구역으로 진입할 순번)
  - turn == i 이면 프로세스 Pi가 임계구역에서 실행될 수 있다
- boolean flag[2]; (프로세스가 임계구역으로 진입할 준비가 되었다는 것을 나타낸다)
  - flag[i] == true 이면 Pi가 임계구역으로 진입할 준비가 되었음을 나타냄
<pre><code>
do{
  flag[i] = TRUE;
  turn = j;
  while(flag[j] && turn == j);
  
  critical section
  
  flag[i] = FALSE;
  
  remainder section
  } while(TRUE);
</code></pre>

4. 동기화 하드웨어
- test_and_set() 명령어
<pre><code>
Boolean test_and_set(boolean *target){
  boolean rv = *target;
  *target = true;
  return rv;
}

do{
  while(test_and_set(&lock))
    ; // do noting
    // critical section
   lock = FALSE;
    // remainder section
  } while(TRUE);
  
</code></pre>

- compare_and_swap() 명령어
<pre><code>
void compare_and_swap(int *value, int expected, int new_value){
  int temp = *value;
  
  if(*value == expectd)
    *value = new_value;
  return temp;
}

do{
  while(test_and_set(&lock))
    ; // do noting
    // critical section
   lock = 0;
    // remainder section
  } while(TRUE);
  
</code></pre>

5. Mutex Locks
- 임계구역을 보호하고 경쟁 조건을 방지하기 위해 mutex 락을 사용
- 프로세슷는 임계구역에 들어가기 전 반드시 락을 획득하고 빠져 나올 때는 반환해야한다
- boolean available; 락의 가용여부 
<pre><code>
// 락 획득
acquire(){
  while(!available)
    ; // busy wait
   available = false;
 }
// 락 반환
release(){
  available = true;
}
</code></pre>
- 두 함수 호출은 원자적으로 수해오디어야 한다
- 바쁜 대기를 하는 단점이 있다
  - 프로세스가 임계구역에 있는 동안 다른 프로세스들은 acquire() 함수를 호출하는 반복문을 계속 실행해야 한다
  - 락이 사용해지기를 계속 기다리면 프로세스가 회전하고 있기에 spinlock이라고 부른다
  - CPU 사이클을 낭비하게 된다
- spinlock은 문맥 교환을 전혀 필요로 하지 않는 장점이 있다
  - 짧은 시간동안 락을 소유할 경우 spinlock이 유용

6. 세마포(Semaphores)
- 세마포 S는 정수 변수로, 원자적 연산 wait(), signal()로만 접근이 가능
<pre><code>
wait(S){
  while(S<=0)
    ;// 바쁜 대기
  S--;
}
signal(S){
  S++;
}
</code></pre>

6.1 세마포 사용법
- 카운팅 세마포는 제한이 없는 영역을 갖는다
- 이진 세마포는 0과 1 사이의 값만 가능, mutex 락과 유사하게 동작
- 상호 배제를 보장하기위해 이진 세마포가 사용되기도 한다
- 카운팅 세마포는 유한 개수를 가진 자원에 대한 접근을 제어하는데 사용

6.2 구현
- 봉쇄연산은 프로세스를 세마포에 연관된 대기큐에 넣고, 프로세스의 상태를 대기 상태로 전환
- 제어가 CPU 스케줄러로 넘어가고, 스케줄러는 다른 프로세스 실행을 위해 선택
<pre><code>
typedef struct{
  int value;
  struct process *list;
} semaphore;

void wait(semaphore *S){
  S->vlaue--;
  if(S->value <0){
    프로세스를 s->list에 넣음;
    block();
  }
}

void signal(semaphore *S){
S->value++;
  if(S->value <=0){
    S->list로부터 하나의 프로세스 P를 꺼낸다;
    wakeup(P);
  }
}
</code></pre>

- signal 연산은 프로세스 리스트에서 한 프로세스를 꺼내 프로세스를 깨워 줌.
- block 연산은 자기를 호출한 프로세스를 중지
- wakeup(P) 연산은 봉쇄된 프로세스 P의 실행을 재개시킨다
- 각 세마포는 정수 값과 프로세스 제어 블록의 리스트에 대한 포인터를 가지고 있다 
- 세마포가 원자적으로 실행되어야 한다는 것은 매우 중요!
- 두 프로세스가 동시에 wait와 signal 연산들을 실행할 수 없도록 반드시 보장해야 한다

6.3 교착 상태와 기아
- 대기 큐를 가진 세마포 구현은 두개 이상 프로세스들이 오로지 대기 중인 프로세스들 중 하나에 의해서만 야기 될 수 있는 사건을 무한정 기다리는 상황이 발생할 수 있다.
- signal() 연산의 실행을 의미하고 이런상태에서 프로세스들은 교착 상태라고 한다
- 무한 봉쇄 or 기아 => 프로세스들인 세마포에서 무한정 대기하는 것

7. 고전적인 동기화 문제들

7.1 유한 버퍼 문제
<pre><code>
int n;
semaphore mutex = 1;
semaphore empty = n;
semaphore full = 0;
do{
  wait(full);
  wait(mutex);
  // remove an item from buffer to nextc
  signal(mutex);
  signal(empty);
  // consum the item in nextc
} while(TRUE);
</code></pre>
- n개의 버퍼들로 구성된 풀이 있으며 각 버퍼들은 한 항목(item) 저장할 수 있다고 가정
- mutex 세마포는 상호 배젲 기능을 제공하며 1로 초기화
- empty는 비어 있는 버퍼 수, full은 꽉 찬 버퍼의 수
- 생산자가 소비자를 위해 꽉 찬 버퍼를 생산해내고 소비자는 생산자를 위해 비어 있는 버퍼를 생산

7.2 Readeers-Writers 문제
- writer와 다른 스레드가 동시 접근 시 혼란 야기
- wirter가 작업 동안 공유 데이터베이스에 배타적 접근 권한을 가질 필요가 있다

- writer가 공유 객체 사용의 허가를 엊지 못했다면 reader를 기다리게 해서 안된다.
- writer가 준비되면 가능한 빨리 쓰기를 수행할 것을 요구한다 -> 다른 새로운 reader들은 읽기 시작을 못한다
-> 해결안이 기아를 낳을 수 있다
- 첫번째 경우는 writer가 기아, 두번째는 reader가 기아 될 수 있다.
<pre><code>
semaphore rw_mutex = 1;
semaphore mutex = 1;
int read_count = 0;
//Writer 구조
do{
  wait(rw_mutex);
  // writeing is performed
  signal(rw_mutex);
} while(true);

// Reader 구조
do{
  wait(mutex);
  read_count++:
  if(read_count ==1)
    wait(rw_mutex);
  signal(mutex);
  // reading is performed
  wait(mutex);
  read_count--;
  if(read_count == 0)
  signal(rw_mutex);
  signal(mutex);
}while(true);
</code></pre>

- Reader-Wirter락이 유용한 경우
  - 공유 데이터를 읽기만 하는 프로세스와 쓰기만 하는 스레드를 식별하기 쉬운 응용
  - Writer보다 reader의 개수가 많은 용용
  
7.3 식사하는 철학자들 문제
<pre><code>
semaphore chopstick[5];
do{
  wait(chopstick[i]);
  wait(chopstick[(i+1) %5]);  
  // eat for awhile
  signal(chopstick[i]);
  signal(chopstick[(i+1) %5]);
  // think for awhile
} while(true);
</code></pre>
- 두 철학자가 동시에 식사하지 않음을 보장하나 교착 상태를 야기할 가능성이 있음

8. 모니터
- 세마포는 signal, wait를 바꿔쓰거나 잘못 사용할 경우, 빠트린 경우 교착 상태가 발생하게된다.

8.1 모니터 사용법
- 모니터 형은 모니터 내부에서 상호 배제가 보장되는 프로그래머가 정의한 일련의 연산자 집합을 포함하는 ADT
  - 변수들의 선언을 포함 -> 변수들의 값은 형에 해당하는 한 인스턴스 상태를 정의
  - 프로시저 or 함수들의 본체 포함
  - 다른 프로세스들이 직접 사용 불가
  - 모니터 내 정의된 함수만 오직 모니터 내 지역적으로 선언된 변수들과 형식 매개변수들에만 접근 가능
  - 모니터 내 지역변수는 오직 지역 변수만 가능
- 모니터는 모니터 안에 항상 하나의 프로세스만 활성되도록 보장해 준다
  - condition형의 변수로 동기화 제공
  - condition에 의해 호출될 수 있는 연산은 오직 wait와 signal 뿐이다
  - wait는 signal 호출때까지 일시중단되어야 함
  - signal은 정확히 하나의 일시중단 프로세스를 재개
  - Signal and wait : P는 Q가 모니터를 떠날 때까지 기다리거나 다른 조건을 기다린다
  - Signal and continue : Q는 P가 모니터를 떠날 때까지 기다리거나 다른 조건을 기다린다
8.2 모니터를 사용한 식사하는 철학자 해결안
<pre><code>
monitor DiningPhilosphers{
  enum{thinking, hungry, eating} state[5];
  condition self[5];  
  
  void pickup(int i){
    state[i] = HUNGRY;
    test(i);
    if(state[i] != EATING)
      self[i].wait();
  }
  void putdown(int i){
    state[i] = THINKING;
    test((i+4)%5);
    test((i+1)%5);
  }
  void test(int i ){
    if((state[(i+4)%5] != EATING && (state[i]== HUNGRY) && (state[i+1)%5]!= EATING)){
      state[i] = EATING;
      self[i].signal();
    }
  }
  initialization code(){
    for(int i = 0; i<5; i++)
      state[i] = THINKING;
    }
}
</code></pre>
- 식사하기전 pickup 연산을 반드시 호출해야 한다
- 식사 후에는 putdown 연산 호출

9. 대체 방안들

9.1 트랜잭션 메모리
- 메모리 트랜잭션 : 메모리 읽기와 쓰기 연산의 원자적인 연속적 순서
  - 한 트랜잭션의 모든 연산이 완수되면 메모리 트랜잭션은 확정
  - 그렇지 않으면 그 시점까지 완수된 모든 연산들은 취소되고 시작 이전의 상태로 roll-back
- atomic{S}가 추가
  - S 내 연산이 트랜잭션으로 실행된다는 것을 보장
- STM은 트랜잭션 블록 안에 검사 코드르르 삽입해 동작
  - 컴파일러에 의해 삽입되어 명령문들이 동시 시행 지점과 저수준 락킹이 필요한 지점을 검사하여 각 트랜잭션을 관리
- HTM은 개별 처릴기 캐시에 존재하는 공유 데이터 충돌을 해결하고 관리하기위해 HW 캐시 계층 구조와 캐시 일관성 프로토콜을 사용
  - 코드 계측이 필요 없고 STM보다 적은 오보헤드를 가진다.
  - 기존 캐시 계층 구조와 캐시 일관성 프로토콜을 트랜잭션 메모리를 지원하기위해 변경해야 한다
 
### 교착상태
- 한 프로세스 집합 내의 모든 프로세스가 집합 내의 다른 프로세스에 의해서만 발생 될 수 있는 사건을 기다리면 프로세스 집합은 교착 상태에 있다
2. 교착 상태의 특징
- 필요 조건
  - 상호 배제 : 최소한 하나의 자원이 비공유 모드로 점유되어야 한다
    - 비공유 모드에서는 한 번에 한 프로세스만이 그 자원을 사용할 수 있다
    - 다른 프로세스가 자원을 요청하면, 요청 프로세스는 자원이 방출될 때까지 반드시 지연되어야 함
  - 점유하며 대기 : 프로세스는 최소한 하나의 자원을 점유한 채, 현재 다른 프로세스에 의해 점유된 자원을 추가로 얻기 위해 반드시 대기해야 함
  - 비선점 : 자원들을 선점할 수 없어야 한다
  - 순환 대기
- 교착 상태가 발생되려면 4가지 조건이 성립되어야 함!
- 자원 할당 그래프
  - Pi -> Rj (요청 간선), Rj -> Pi (할당 간선)
  
  ![ex_screenshot](/res/os24.png)
  - 그래프가 사이클을 포함하면 교착상태가 존재할 수 있다
  - 각 자원 타입이 정확히 하나의 인스턴스만 가지면 하나의 사이클은 교착 상태가 발생함을 암시
  - 사이클이 있으며 교착상태가 아닌 자원 할당 그래프
  
    ![ex_screenshot](/res/os25.png)
    
3. 교착 상태 처리 방법
- 교착 상태를 예방하거나 회피
  - 필요 조건들 중 적어도 하나가 성립하지 않도록 보장하는 일련의 방법
  - 자원이 어떻게 요청될 수 있는지를 제한하며 교착상태를 예방
- 교착 상태 허용 후 회복
  - 사용할 자원에 대한 부가적 정보를 미리 제공할 것을 요구함
- 문제를 무시하고 발생하지 않은 척 
  - 다름 방법에 비해 비용이 적게 들지만 반드시 수작업 복구 방법이 있어야 함.

4. 교착상태 예방
- 상호 배제
  - 적어도 하나의 자원은 공유 불가능 자원이어야 함
  - 공유 자원들은 배타적 접근을 요구하지 안흥며 교착상태에 관련될 수 없다
- 점유하며 대기
  - 각 프로세스가 실행되기 전 자신의 모든 자원을 요청하고 할당받을 것을 요구하는 방법
  - 프로세스가 자원을 전혀 갖고 있지 않을 때만 자원을 요청할 수 있도록 허용 
  - 두 방법은 자원 이용도가 낮을 수 있고 기아 상태가 가능 하다
- 비선점 
  - 점유 프로세스가 즉시 할당할 수 없는 다른 자원을 요청하면 현재 점유하고 있는 모든 자원들이 선점
  - 한 프로세스가 자원 요청 시 사용 가능을 검사하고 가능 시 할당, 불가능 시 자원들이 추가 자원을 위해 대기하고 있는 다른 프로세스에 할당되어 있는지를 검사
  - mutex 락과 세마포 같은 자원에는 적용 불가
- 순환 대기
  - 모든 자원 타입들에게 전체적인 순서를 부여
  - 모든 동기화 객체의 순서를 정하고 이 기법을 응용 프로그램에 구현할 수 있다 (요청은 오름차순으로 요청되어야 함)

- 요청 방법에 제한을 두어 교착상태를 예방
- 필요조건 중 적어도 한가지는 성립되지 않도록 보장
-> 장치의 이용률이 저하되고 시스템 처리율이 감소된다!

5. 교착상태 회피
- 자원이 어떻게 요청될 지에 대한 추가 정보를 제공하도록 요구하는 것
- 각 프로세스가 자신이 필요로 하는 각 타입의 자원마다 최대 수를 선언하도록 요구 -> 교착상태에 들어가지 않을 알고리즘 가능
- 교착상태 회피 알고리즘 : 시스템에 순환 대기 상황이 발생하지 않도록 자원 할당 상태 검사
  - 자원 할당 상태는 가용 자원수, 할당 자원 수, 프로세스들의 최대 요구 수에 의해 정의
  
5.1 안전 상태
- 시스템 상태가 안전
  - 시스템이 어떤 순서로든 프로세스들이 요청하는 모든 자원을 교착상태를 야기시키지 않고 차례로 모두 할당 해 줄 수 있음을 뜻함
  - 안전 순서를 찾으면 안전하고 못찾으면 불안전하다
- 교착상태에 있는 시스템은 불안전한 상태에 있다
  - 불안전하다고 교착상태로 간다는 것의미 하지 않음, 교착 상태가 될 수 도 있음을 의미
- 기본 원칙은 시스템 상태가 항상 안전 상태를 떠나지 않도록 고수하는 것
- 자원의 이용률은 낮아지게 된다

5.2 자원 할당 그래프 알고리즘
- 예약간선 : Pi -> Rj, Pi가 미래에 자원 Rj를 요청할 것
  - 점선으로 표시
  - 요청하며 요청 간선으로 변환되고 방출하면 다시 예약 간선으로 변환
- 시스템에서 자원이 반드시 미리 예약되어야 한다
  - 모든 예약 간선들이 자원 할당 그래프에 표시되어야 함
- 사이클을 형성하지 않을 때에만 요청 허용

5.3 은행원 알고리즘
- 프로세스가 시작할 때 프로세스가 가지고 있어야 할 자원의 최대 개수를 자원 종류마다 신고해야 함
  - 총 자원의 보유수를 넘어서면 안됨
- 시스템이 자원을 할당 하고 있는 상태를 나타내는 자료구조 필요
  - Available : 각 종류별 가용 자원 개수를 나타내는 벡터, 크기 m
    - Available[j] = k 이면 현재 Rj를 k개 사용 가능
  - Max : 각 프로세스가 최대로 필요로 하는 자원 개수를 나타내는 행렬, 크기 n*m
    - Max[i,j] = k 이면 Pi가 Rj를 최대 k개 까지 요청 가능
  - Allocation : 각 프로세스에게 현재 나가 있는 자원 개수를 나타내는 행렬, 크기 n*m
    - Allocation[i,j] = k 이면 Pi가 Rj를 k개 사용 중
  - Need : 각 프로세스가 향후 요청할 수 있는 자원 개수를 나타내는 행렬, 크기 n*m
    - Need[i,j] = k 이면 Pi가 향후 Rj를 k개까지 더 요청할 수 있음
  - Need[i,j] = Max[i,j] - Allocation[i,j]
- 안전성 알고리즘
  - Work(크기 m인 벡터), Finish(크기 n인 벡터), Work = Avaliable로 초기값을 주고 Finisih[i] = false로 초기값을 준다 (step 1)
  - Finish[i]==false && Needi<=Work 인 i값을 찿는다, 못찾으면 step 4로 go(stpe 2)
  - Work = Work + Allocationi, Finish[i] = true -> go to step 2 (step 3)
  - 모든 i 값에 대해 Finish[i] = true이면 시스템은 안전상태 (step 4)
- 자원 요청 알고리즘
  - Requesti는 프로세스 Pi의 요청 백터, Requesti[j] == k이면 Pi가 Rj를 k개 까지 요청하고 있음을 의미
  - Pi가 자원 요청 시 조치
    - if Requesti <= Needi go to step 2, 아니면 시스템에 있는 개수보다 더 많이 요청했으므로 오류 처리 (step 1)
    - if Requesti <= Available go to step 3, 아니면 요청 자원이 당장은 없으므로 Pi를 기다림 (step 2)
    - 마치 Pi에게 자원을 할당해준 것 처럼 시스템 상태정보를 바꾸어 봄 (step 3)
      - Availabe = Available - Requesti j
      - Allocationi = Allocationoi + Reqeusti j
      - Needi = Needi - Requesti j 
      - 바뀐 상태가 안전하면 Pi에게 반영된 정보대로 자원 할당, 불안전하면 원상태로 복원되고 Pi은 Requesti각 만족되기를 기다려야함

6. 교착상태 탐지
- 교착상태가 발생했는지 결정하기 위해 시스템 상태를 검사하는 알고리즘
- 교착 상태로부터 회복하는 알고리즘
- 두 알고리즘을 반드시 지원해야 함!

- 대기 그래프가 사이클 포함 -> 교착상태 존재
- 교착상태 탐지하기 위해 시스템은 대기 그래프 유지 필요, 주기적으로 그래프에서 사이클 탐지 알고리즘 호출

7. 교착상태로부터 회복
- 순환 대기를 깨뜨리기 위해 단순히 한 개 이상의 프로세스 중지
- 교착상태에 있는 하나 이상의 프로세스들로부터 자원을 선점하는 것

7.1 프로세스 종료
- 종료된 프로세스에게 할당되었던 모든 자원을 시스템이회수한다
  - 교착 상태 프로세스 모두 중지 : 사이클을 깨뜨리지만 비용이 크다 
    - 오랫동안 연산했을 가능성이 크고 계산 결과를 반드시 폐기 해야 하며, 다시 계산을 수행해야 함
  - 교착상태가 제거될 때까지 한 프로세스 씩 중지
    - 각 프로세스 중지 때마다 교착상태 탐지 알고리즘 호출, 상당한 오버헤드 유발
- 프로세스 중지 시 유발되는 비용이 최소인 프로세스를 중지해야 한다
 
7.2 자원 선점
- 교착 상태가 깨어질 때까지 프로세스로부터 자원을 계속 선점해 다른 프로셋에게 주어야함 
- 고려사항
  - 희생자 선택 : 비용을 최소화하기 위해 선점 순서를 결정해야 함
    - 비용 요인으로 교착 상태 프로세스가 점유하는 자원 수, 지금까지 실행하는 데 소요된 시간 등 포함
  - 후퇴 : 필요 자원이 부족하면 안전한 상태로 후퇴하고 다시 시작해야 함
    - 시스템이 실행하는 모든 프로세스들의 상태에 대한 보다 많은 정보 유지할 것을 필요로함
  - 기아 상태 : 한전된 시간 동안만 희생자로 선정된다는 것을 보장해야 함
    - 비용 요소에 후퇴 회수를 포함 시키는 방법도 있음
    
### 메모리 관리 전략

- 모든 실행되는 명령어와 데이터들은 CPU가 직접적으로 접근 할 수 있는 주 메모리와 레지스터가 있어야한다
- 데이터가 메모리에 없다면 CPU가 그것들을 처리하기 전에 메모리로 이동시켜야 한다
- 레지스터들은 일반적으로 CPU 클록의 1사이클 내에 접근이 가능
  - 명령어 해독과 간단한 오퍼레이션을 클록 틱 당 하나 OR 그 이상의 속도로 처리
- 각각의 프로세스가 독립된 메모리를 가지도록 보장해야 한다
  - 개별적 프로세스 별 메모리 공간은 서로를 보호하고 병행 실행을 위해 여러 프로세스들이 메모리에 적재되기 하는 것이 필수적
  - 특정 프로세스만 접근할 수 있는 합법적 메모리 주소 영역을 설정하고 접근하도록 하는 것이 필요
- 기준과 상한이라 불리는 두 개의 레지스터들을 사용해 보호 기법을 제공한다
  - 기준 레지스터는 가장 자근 합법적인 물리 메모리 주소를 저장, 상항 레지스터는 주어진 영역의 크기를 저장
  - 두 레지스터는 여러가지 특권 명령을 사용하는 운영체제에 의해서만 로드 된다
  
  ![ex_screenshot](/res/os26.png)
  ![ex_screenshot](/res/os27.png)
  
1.2 주소의 할당
- 각 바인딩 과정은 한 주소 공간에서 다른 주소 공간으로 맵핑하는 것
- 컴파일 시간 바인딩
  - 프로세스가 메모리 내에 들어갈 위치를 알고 있고 컴파일러는 절대코드를 생성 할 수 있다
- 적재 시간 바인딩
  - 프로세스가 메모리 내 어디에 올지 컴파일 시 알지 못하면 컴파일러는 이진 코드를 재배치 가능 코드로 만들어야 함
  - loader가 주소를 계산해야함
- 실행 시간 바인딩

1.3 논리 대 물리주소 공간
- CPU가 생성하는 주소를 논리 주소, 메모리가 취급하게 되는 주소를 물리주소라 한다
- 컴파일 시 바인딩과 적재 시 바인딩 기법은 논리, 물리 주소가 같다
- 실행 시간 바인딩 기법에서는 두 주소가 다르며 이러한 경우 논리 주소를 가상 주소라 한다
- 프로그램에 의해 생성된 모든 논리 주소 집합을 논리 주소 공간, 논리 주소와 일치하는 모든 물리 주소 집합을 물리 주소 공간이라 함.
- 프로그램 실행 중에는 가상 주소를 물리 주소롤 바꾸어 줘야함 -> 변환 작업은 메모리 관리기에 의해 실행
- 기준 레지스터를 재배치 레지스터라 부름
- 참조된 메모리 주소의 실제 위치는 실제 실행 시간에 결정된다
  ![ex_screenshot](/res/OS28.png)

1.4 동적 적재
- 메모리 공간의 효율을 위해 동적 적재를 해야함
- 각 루틴은 호출되기 전까지 메모리에 올라오지 않고 재배치 가능한 상태로 디스크에서 대기
- main 프로그램이 올라와야 실행된다
- 루틴이 다른 루틴을 호출하면 적재 여부를 조사 
  - 적재되지 않았으면 재배치 가능 연결 적재기 불려 요구된 루틴을 메모리로 가져오고 변화를 테이블로 기록한다
- 루틴이 필요한 경우에만 적재된다는 것이 동적 적재의 장점
- 많은 양의 코드를 필요로 하는 경울 유용하다

1.5 동적 연결 및 공유 라이브러리
- 사용자 로그램이 실행될 때 연결되는 시스템 라이브러리
- 동적 연결은 실행 시기까지 미루어지는 것 ( 동적 적재는 로딩이 실행 시까지 미루어지는 것)
- 라이브러리를 부르는 곳마다 스텁이 생김
  - 스텁은 라이브러리를 어떻게 찾은 것인가를 알려주는 작은 코드 조각
- 스텁이 실행 될 때 스텁은 필요한 라이브러리 루틴이 이미 메모리에 존재하는가 검사, 없으면 디스크에서 가져옴
  - 스텁은 라이브러리 루틴의 번지수를 알아내게 되고 자신을 그 루틴의 번지로 대체 -> 다음 번에 동적 연결 필요 없이 루틴 수행
- 동적 연결은 라이브러리 루틴을 바꿀 때 유용

2. 스와핑
- 스와핑을 이용하면 동시에 실행하는 것이 가능해 다중 프로그래밍 정도를 증가 시킨다
2.1 기본 스와핑
- 메인 메모리와 예비 저장 장치 사이 프로세스를 이동
  - 예비 저장 장치로 보통 빠른 디스크 사용
  - 저장 장치의 크기는 모든 사용자의 메모리 이미지를 저장 할 수 있을 만큼 커야하고 직접 접근이 가능해야 함
- 스와핑 시스템은 문맥 교환 시간이 상당히 오래 걸림
- 스왑 시간의 대부분이 디스크 전송 시간 
  - 전송 시간은 스왑될 메모리의 크기와 비례
- 스왑 시간을 줄이기 위해 실제로 사용하는 부분을 스왑해야 한다
  - 효과적으로 이루어지기 위해 사용자는 메모리 요구 사항 변화가 있을 때마다 시스템에게 알려주어야 함
- 동적 메모리 요구 시스템에서는 운영체제에게 메모리 요구사항의 변화를 알려주는 request memory, release memory 같은 시스템 호출이 필요
- 한 프로세스를 스왑하기 원하면 완전히 휴지 상태에 있음을 확인해야 하는 제약이 있다

3. 연속 메모리 할당
- 주 메모리는 운영체제뿐 아니라 여러 사용자 프로세스도 수용해야 한다
  - 각 영역은 목적에 맞도록 효율적으로 관리되어 함
- 메모리는 일반적으로 두개로 나누어짐
  - 메모리에 상주하는 운영체제를 위한 것
  - 사용자 프로세스를 위한 것
  - 운영체제는 어느쪽에 위치할 수 있으며 결정에 영향을 미치는 중요 요인은 인터럽트 벡터이다.
  ![ex_screenshot](/res/os29.png)

3.1 메모리 보호
- 재배치 레지스터는 가장 작은 물리주소 값을 저장하고 상한 레지스터는 논리 주소의 범위 값을 저장한다
- 각각 논리 주소는 상한 레지스터가 지정한 범위 안에 존재해야 한다
- MMU는 동적으로 논리 주소에 재배치 레지스터 값을 더해 주소를 변환하는 역할을 한다
- CPU 스케줄러가 다음 수행 프로세스 선택 시 디스패처는 문맥 교환의 일환으로 재배치 레지스터와 상한 레지스터에 정확한 값을 적재한다
- 재배치 레지스터를 사용함으로 운영체제 크기는 실행 중이라도 얼마든지 변경 될 수 있다
  ![ex_screenshot](/res/os30.png)


3.2 메모리 할당 
- 간단한 공간 할당 방법은 메모리를 같은 고정 크기로 분할 하는 것
- 각 분할 마다 프로세스를 가지고 분할의 개수를 다중 프로그래밍 정도라 함
- 가변 분할 기법에서 운영체제는 메모리의 어떤 부분이 사용되고, 사용되지 않는지를 파악하는 테이블을 유지한다
  - 운영체제는 각 프로세스가 얼마나 요구하고 사용 가능 메모리 공간이 얼마인지 고려해 공간을 할당
  - 프로세스가 공간을 할당 받게되면, cpu를 할당 받기 위해 경쟁한다
  - 프로세스가 끝나면 메모리를 반납하고 운영체제는 다른 프로세스로 공간ㅇ르 채움
- 운영체제는 항상 놀고 있는 공간의 크기들과 입력 큐를 유지해야 한다
- 메모리에는 다양한 크기의 자유 공간이 여기저기 산재됨 -> 프로세스가 공간을 필요할 때 운영체제는 자유 공간들의 집합에서 적절한 것을 찾아내야 함
- 동적 메모리 할당 문제
  - 최초 적합 : 첫 번째 사용 가능한 가용 공간을 할당 
  - 최적 적합 : 사용 가능한 공간들 중 가장 작은 것 선택
  - 최악 적합 : 가장 큰 가용 공간을 선택 
  
3.3 단편화
- 외부 단편화는 유휴 공간들을 모두 합치면 충분한 공간이 되지만 그것들이 너무 작은 조각들로 여러 곳에 분산되어 있을 때 발생
  - 너무 많은 수의 매우 작은 조각들로 단편화 되어 있음 -> 문제가 매우 심각해질 수 있음
  - 최초 적합 or 최적 적합 전략 사용 결정은 단편화 크기에 영향을 받는다 
- 외부 단편화 해결 방법으로 압축이 있다
  - 메모리 모든 내용을 한군데로 몰고 모든 자유 공간들을 다른 한군데로 몰아 큰 블록을 만드는 것 
  - 프로세스들의 재배치가 실행시간에 동적으로 이루어지는 경우에만 가능
- 다른 방법으로 프로세스의 논리 주소 공간을 여러 비연속적 공간으로 나누어 필요 크기 공간이 가용해지는 경우 물리 메모리를 프로세스에 할당하는 방법
- 내부 단편화는 메모리를 아주 작은 공간들로 분할하고 프로세스가 요청하면 할당을 항상 이 분할된 크기의 정수 배로만 해주는 것이 보통이나 할당된 공간이 요구 공간보다 큰 경우 두 크기 사이 남는 부분이 단편화이다.

4. 세그먼테이션
- 세그먼트의 길이는 다양하며, 각 세그먼트 길이는 프로그램 목적에 따라 자동적으로 결정된다
- 세그먼트는 이름과 길이를 가지며 프로그램에서 사용되는 주소는 세그먼트 이름과 세그먼트 안에서의 오프셋을 모두 명시한다
  - 프로그래머는 모든 주소를 세그먼트 이름과 오프셋의 두부분으로 나누어 명시
- 논리주소는 <segment-number, offset>으로 구성
- 세그먼트 테이블의 각 항목은 세그먼트의 기준과 세그먼트 한계를 가진다
- 세그먼트 기준은 시작 주소, 세그먼트 한계는 길이를 명시
- 논리 주소는 세그먼트 번호s와 세그먼트 내에서 변위 d로 구성
  - 세그먼트 번호 s는 세그먼트 테이블에 대한 색인으로 사용
  - 변위d는 0과 세그먼트크기 사이의 값이어야 함
- 변위가 번위 안에 있으면 세그먼트 기준과 변위가 더해 원하는 바이트의 실제주소를 얻음
- 세그먼트 테이블은 기본적으로 기준/한계 레지스터 쌍들로 이루어진 배열
- 단편화에 따른 압축 작업이 필요하다
- 프로세스가 적재되는 물리 주소 공간이 연속적이지 않아도 적재를 허용

  ![ex_screenshot](/res/os31.png)
  ![ex_screenshot](/res/os32.png)

5. 페이징
- 외부 단편화를 방지하고 단편화에 따른 압축 작업이 필요 없다
- 물리메모리는 프레임이라 불리는 가타은 크기 블록으로 나누어진다
- 논리메모리는 페이지라 불리는 같은 크기의 블록으로 나누어 진다
- 프로세스가 실행 될 때 프로세스의 페이지는 파일 시스템 or 예비 저장 장치로부터 가용한 주 메모리 프레임으로 적재

  ![ex_screenshot](/res/os33.png)
- 모든 주소는 페이지 번호 p와 페이지 변위 d로 나누어진다
  - 페이지 번호는 페이지 테이블을 액세스 할 때 사용
- 페이지 테이블은 주 모메리에서 각 페이지가 점유하는 주소를 가진다
- 페이지 주소에 변위를 더하면 원하는 물리 주소가 된다
- p는 페이지 인덱스로 사용되며 d는 페이지내 변위로 사용된다
- 모든 논리 주소는 페이징 하드웨어에 의해 물리 주소로 사상

  ![ex_screenshot](/res/os34.png)
- 페이징 기법을 사용하면 외부 단편화가 발생하지 않으나 내부 단편화가 발생될 수 있다
- 페이지 크기가 작아지면 페이지 테이블 크기가 커지게 된다

  ![ex_screenshot](/res/os35.png)
- 운영체제는 메모리를 관리하기 때문에 물리 메모리의 자세한 할당에 대해 파악하고 있어야 한다
  - 어느 프레임에 할당되있고, 어느 프레임이 사용가능한지, 총 몇 프레임인지 등
  - 이러한 정보는 프레임 테이블에 있다
- 프레임 테이블은 각 프레임 당 하나의 항목을 가지며 그것이 놀고있는지, 할당되었는지, 어느 프로세스의 어느 페이지에 할당되었는지를 나타냄
- 운영체제는 모든 프로세스들의 주소들을 실제 주소로 사상할 수 있어야함
  - 각 사용자에 대해 페이지 테이블의 복사본을 유지해야 한다
  - 운영체제가 시스템 호출을 처리하기 위해 사용자 프로그램의 물리주소를 sw적으로 알아내야 할 때 사용
- 페이징은 context switch 시간을 증가시킨다!

5.2 하드웨어 지원
- 각 운영체제는 페이지 테이블을 저장하기 위한 고유 방법을 가진다
- 페이지 테이블을 가리키는 포인터는 프로세스의 다른 레지스터 값과 함께 프로세스 제어 블록에 저장된다
- 간단한 페이지 테이블은 레지스터 집합으로 구현
  - 메모리의 모든 액세스는 페이징 맵을 통해야 하므로 매핑의 효율이 중요!
  
 ![ex_screenshot](/res/os36.png)
- TLB : 매우 빠른 연관 메모리로 구성
  - 각 항목은 키와 값의 두부분으로 구성
  - TLB에 페이지 찾는 요청이 들어오면 찾고자 하는 페이지를 동시에 여러 개 내부 키와 비교
  - 같은 것이 있으면 대응 프레임 번호를 알려줌
  - TBL은 페이지 테이블의 일부분 저장된다
  - 페이지 번호가 연관 레지스터 TLB에서 찾아지지 않으면(TLB 미스) 페이지 테이블을 접근하기 위한 메모리 참조 발생
    - TLB가 가득 차있을 경우 기존 항목 중 교체될 항목을 선택해야함
  - 접근하는 메모리 페이지 번호가 TLB에서 발견된는 비율을 적중률이라고 한다
  
5.3 보호
- 각 페이지에 붙은 보호 비트에 의해 페이지가 보호된다
  - 이 비트들은 페이지 테이블에 속해 있다
  - 각 비트는 페이지가 읽고-쓰고 or 읽기 전용임을 정의할 수 있다
- 페이지 테이블의 각 엔트리에는 유효/무효 비트가 있다
  - 유효로 설정되면 페이지가 프로세스의 합법적 페이지
  - 무효로 설정되면 페이지는 프로세스의 논리 주소 공간에 속하지 않는다는 것을 의미
- 페이지 테이블 길이 레지스터
  - 프로세스가 제시한 주소가 유효한 범위 내에 있는지 확인 -> 모든 논리 주소 값이 PTLR 값과 비교
  - 오류 발생시 트랩 발생
  
6. 페이지 테이블 구조

6.1 계층적 페이징
- 2단계 페이징 기법 : 페이지 테이블 자체가 다시 페이지화 되는 것

    ![ex_screenshot](/res/os39.png) 
  - 논리 주소는 20 비트짜리 페이지 번호와 12비트 페이지 변위로 이루이진다
  - 페이지 번호는 다시 10비트 페이지 번호와 10비트 페이지 변위로 나누어진다
  
    ![ex_screenshot](/res/os37.png)
    ![ex_screenshot](/res/os38.png)
  - p1은 바깥 페이지 테이블 인덱스, p2는 안쪽 페이지 테이블의 페이지 내 변위
  - foward-mapped 페이지 테이블이라고도 부른다
  
6.2 해시 페이지 테이블

  ![ex_screenshot](/res/os39.png)
- 해시 페이지 테이블의 각 항목은 연결 리스트를 가지고 있다
- 각 원소는 세개의 필드를 가진다
  - 가상 페이지 번호
  - 사상되는 페이지 프레임 번호
  - 연결 리스트 상의 다음 원소 포인터
- 가상 주소 공간으로 부터 페이지 번호가 오면 그것을 해싱
  - 해시 페이지 테이블에서 연결 리스트를 따라가며 첫 원소와 가상 페이지 번호를 비교
  - 일치되면 대잉 페이지 프레임 번호를 가져와 물리 주소를 얻음
  - 아니면 반복
  
6.3 역 페이지 테이블

  ![ex_screenshot](/res/os40.png)
- 메모리 프레임마다 한 항목씩 할당
  - 각 항목은 프레임에 올라와 있는 페이지 주소, 페이지를 소유하는 프로세스 ID를 표시
  - 물리 프레임에 대응되는 항목만 테이블에 저장하기 때문에 메모리에서 훨씬 작은 공간을 점유
    - 주소 변환 시간이 더 오래 걸 릴수 있다
  - 물리 주소에 따라 정렬되어 있고 탐색은 가상 주소를 기준으로 하기에 테이블 전체를 탐색할 수 도 있다
    - 매우 오래 걸림
  - 해시 테이블을 사용하며 메모리 참조 횟수를 증가 시키게 된다
  - 역 페이지 테이블을 사용하는 시스템은 메모리 공유가 어렵다
  
### 가상 메모리
- 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법
  - 사용자 프로그램이 물리 메모리 보다 커져도 된다는 장점이 있다
  - 메모리 크기 제약으로부터 자유로워진다 
  - 파일의 공유를 쉽게 해주고 공유 메모리 구현을 가능하게 한다
  - 구현이 어렵고 잘못 사용 하게되면 성능이 저하될 수 있다 

1 배경
- 프로그램 일부분만 메모리에 올려놓고 실행할 경우 이점
  - 물리 메모리 크기에 의해 더이상 제약받지 않게 된다 -> 프로그래밍 작업이 간단해 진다
  - 각 사용자 프로그램이 더 작은 메모리를 차지하므로 더 많은 프로그램을 동시에 수행할 수 있게 된다
    - 응답 시간은 늘어나지 않으면서 CPU 이용률, 처리율이 높아진다
  - 프로그램을 메모리에 올리고 스왑하는 데 필요한 입출력 횟수가 줄어들기 때문에 프로그램들이 빨리 시행된다 
- 실제 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것
  - 작은 메모리를 가지고도 큰 가상 주소 공간을 프로그래머에게 제공할 수 있다
- 가상 주소 공간에 공백을 포함하는 가상 주소공간을 성긴 주소 공간이라 함
  - 성긴 주소 공간의 공백은 스택이나 힙 세그먼트가 확장될 때 사용되거나 프로그램 실행 중 동적으로 라이브러리를 링크할 필요가 있을 때 사용
- 페이지 공유를 통해 파일이나 메모리가 둘 OR 그 이상의 프로세스들에 의해 공유되는 것을 가능하게 한다
  - 시스템 라이브러리가 여러 프로세스들에게 공유 될 수 있다
  - 프로세스들이 메모리를 공유할 수 있다(가상 메모리는 다른 프로세스와 공유할 수 있는 영역을 만들 수 있도록 해줌)
  - 페이지는 시스템 호출을 통한 프로세스 생성 과정 중 공유될 수 있기 때문에 프로세스 생성 속도를 높일 수 있다
  
  ![ex_screenshot](/res/os42.jpg)

2 요구 페이징
- 초기에 필요한 것들만 적재하는 전략(실행 과정에서 실제로 필요해 질 때 적재된다)
- 게으른 스와퍼를 사용 
  - 페이지가 필요하지 않는 한 메모리에 적재하지 않는다
2.1 기본 개념
- 스왑 인 시 페이지는 프로세스가 다시 스왑 아웃 되기 전 실제 사용될 페이지들이 어떤 것인지 추측
- 페이저는 프로세스 전체를 스왑 인 하는 대신 실제 필요한 페이지들만 메모리로 읽어 온다
  - 시간 낭비와 메모리 공간 낭비를 줄일 수 있다
  
  ![ex_screenshot](/res/os43.jpg)
- 어느 페이지가 메모리에 올라와 있는지 구별할 수 있어야 한다
  - 유효/무효 비트 기법 사용
  - 유효하다 설정되면 해당 페이지가 메모리에 있다는 의미, 무효하면 해당 페이지가 유효하지 않거나 유효하나 디스크에 존재한다는 것
  
  ![ex_screenshot](/res/os44.png)
- 무효인 페이지에 접근하면 페이지 부재 트랩을 발생
  - 페이지 테이블을 이용한 주소 변환 과정에서 무효 비트를 발견하고 운영체제에게 트랩을 건다
- 페이지 부재 과정

  ![ex_screenshot](/res/os45.png)
  - 프로세스에 대한 내부 테이블을 검사해 메모리 참조가 유효한지를 알아낸다
  - 무효이면 프로세스 중단, 유효 시 페이지가 메모리에 없으면 디스크로부터 가져옴
  - 빈 공간(자유 프레임)을 찾는다
  - 디스크에 새로 할당된 프레임으로 해당 페이지를 읽어 온다
  - 읽기가 끝나면 페이지는 메모리에 있다는 것을 알리기 위해 페이지 테이블 갱신, 프로세스가 유지하고 있는 내부 테이블 수정
  - 트랩에 의해 중단된 명령어를 다시 수행
- 순수 요구 페이징 : 어떤 페이지가 필요해지기 전에는 겨결코 페이지를 메모리로 적재하지 않는 방법
- 요구 페이징을 위한 필수적 요구 사항은 페이지 부재 오류 처리 후에 명령어 처리를 다시 시작할 수 있어야 한다는 것이다

2.2 요구 페이지 성능
- 요구 페이징은 컴퓨터 시스템의 성능에 중요한 영향을 미친다
- 실질 접근 시간 = (1-p) * ma + p * 페이지 부재 시간 (p: 페이지 부재 확률)
- 페이지 부재 순서
  - 운영체제에 트랩 요청
  - 사용자 레지스터들과 프로세스 상태 저장
  - 인터럽트 원인이 페이지 부재임을 알아냄
  - 페이지 참조가 유효한 것인지 확인하고 디스크에 있는 페이지 위치를 알아냄
  - 디스크에 자유 프레임으로 읽기 요구
    - 읽기 차례가 올때까지 대기 큐에서 기다림
    - 디스크에서 찾는 시간과 회전 지연 시간 동안 기다림
    - 메모리 내 지정된 프레임으로 데이터 전송 시작
  - 기다리는 동안 CPU는 다른 사용자에게 할당
  - 디스크가 다 읽었다고 인터럽트를 건다
  - 다른 사용자 레지스터들과 프로세스 상태 저장
  - 인터럽트가 디스크로부터 왔다는 것을 알아냄
  - 새 페이지가 메모리로 올라왔다는 것을 페이지 테이블과 다른 테이블에 기록
  - CPU가 자기 차례로 오기까지 기다림
  - CPU 차례가 오면 위에서 저장시켜 둔 레지스터들, 프로세스 상태, 새로운 페이지 테이블을 복원시키고 인터럽트 되었던 명령어 다시 실행
- 페이지 부재 시간은 3개의 큰 구성 요소로 이루어짐
  - 인터럽트 처리
  - 페이지 읽기
  - 프로세스 재시작
- 실제 접근 시간은 페이지 부재율에 비례한다

4. 페이지 교체

4.1 기본적 페이지 교체
- 빈 프레임이 없다면 현재 사용되고 있지 않는 프레임을 찾아 비워버린다
- 프레임 내용을 스왑 공간에 쓰고 페이지가 메모리에 더 이상 존재하지 않는 다는 것을 나타내기 위해 페이지 테이블을 변화시킴으로 프레임을 비어있게 한다
- 페이지 부재 서비스 루틴
  - 디스크에서 필요한 페이지의 위치를 알아낸다
  - 빈 페이지 프레임을 찾는다
    - 빈 페이지 프레임이 있으면 사용
    - 없다면 희생될 프레임을 선정하기 위해 페이지 교체 알고리즘을 가동
    - 희생될 페이지를 디스크에 기록, 관련 테이블 수정
  - 빼앗을 프레임에 새 페이지를 읽어오고 테이블 수정
  - 페이지 부재가 발생한 시점에서부터 사용자 프로세스를 계속

![ex_screenshot](/res/os46.png)

- 페이지 교체는 요구 페이징의 기본이다
- 요구 페이징 시스템의 두가지 문제는 프레임 할당 알고리즘과 페이지 교체 알고리즘

4.2 FIFO 페이지 교체
- 페이지 교체 시 메모리에 올라온지 가장 오래된 페이지를 내쫒는다
- 페이지 참조열 : 7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1

  ![ex_screenshot](/res/os47.jpg)
- 참조열에 따라 성능이 달라지며 항상 좋지 않음
- Belady의 모순 : 프로세스에게 프레임ㅇ르 더 주어도 오히려 페이지 부재율은 더 증가하는 현상

4.3 최적 페이지 교체
- 앞으로 가장 오랜 동안 사용되지 않을 페이지를 찾아 교체하라
- 할당된 프레임 수가 고정된 경우 가장 낮은 페이지 부재율을 보장한다

  ![ex_screenshot](/res/os48.jpg)
- 프로세스가 앞으로 메모리를 어떻게 참조할 것인지 미리 알아야 하기에 잘 사용되지 않음

4.4 LRU 페이지 교체
- 가장 오랜 기간 동안 사용되지 않은 페이지 교체
- 각 페이지 마다 마지막 사용 시간을 유지 한다
- 시간 순서 파악 방법
  - 계수기 : 각 페이지 항목마다 사용 시간 필드를 넣고 CPU에 논리적인 시계나 계수기를 추가한다
  - 스택: 페이지가 참조될 때마다 페이지 번호는 스택 중간에서 제거되 TOP에 놓는다
  
  ![ex_screenshot](/res/os49.jpg)
- 최적 교체, LRU 교체는 Belady 모순 현상을 야기하지 않음 -> 스택 알고리즘이라 부른다

4.5 LRU 근사 페이지 알고리즘
- 참조 비트를 사용한다
- 부가적 참조비트 알고리즘
  - 일정 간격마다 참조 비트를 기록함으로 선후 관계 정보를 얻을 수 있다
  - 각 페이지에 대해 8비트 참조 비트 할당
  - 일정 시간 간격마다 운영체제 참조비트를 시프트 (EX 00000000 -> 9번 구간동안 사용되지 않음)
- 2차 기회 알고리즘
  - 기본은 FIFO 교체 알고리즘 
  - 페이지가 선택될 때마다 참조 비트를 확인
  - 참조 비트가 0이면 교체, 1이면 다시 한번 기회를 주고 다음 페이지로 넘어감
  
  ![ex_screenshot](/res/os50.png)
- 개선된 2차 기회 알고리즘
  - 참조 비트와 변경 비트 사용
    - (0,0) : 최근에 사용되지도 변경되지도 않은 경우 ( 교체하기 가장 좋은 페이지 )
    - (0,1) : 최근에 사용되지 않았지만 변경은 된 경우 
    - (1,0) : 최근에 사용 되었으나 변경 되지 않은 경우
    - (1,1) : 최근에 사용 되었고 변경도 된 경우 
  - 가장 낮은 등급을 가지면서 처음 만난 페이지를 교체한다

4.6 계수-기반 페이지 교체
- LFU 알고리즘 : 참조 횟수가 가장 작은 페이지 교체
- MFU 알고리즘 : 가장 작은 참조 회수를 가진 페이지가 가장 최근 참조된것이고 앞으로 사용될 것이라는 판단에 근거한 것
- 잘 사용되지 않음

4.7 페이지 - 버퍼링 알고리즘
- 가용 프레임 여러 개를 풀로 가지고 있다가 페이지 부재 발생 시 교체될 페이지를 찾지만 교체될 페이지 내용을 디스크에 기록하기 전 가용 프레임에 새로운 페이지를 먼저 읽어 들이는 방법
- 페이지가 쓰여지길 기다리지 않고 프로세스가 가능한 빨리 시작 될 수 있도록 함
- 교체될 페이자가 다쓰여지면 그 프레임이 가용 프레임 풀에 추가

- 변경된 페이지 리스트를 유지하는 방법
- 가용 프레임 풀을 유지하나 풀 속 각 프레임의 원래 임자 페이지가 누구인지 기억해 놓는 것

5. 프레임 할당

5.1 최소 프레임 할당 수
- 각 프로세스에 할당되는 프레임 수가 줄어들면 페이지 부재율은 증가하고 프로세스 실행은 늦어지게 된다
- 프로세스 당 최소 프레임 수는 명령어 집합 아키텍처에 의해 결정되고 최대 할당 수는 가용 물리 메모리에 의해 결정

5.2 할당 알고리즘
- 균등 할당 : 모든 프로세스에 똑같이 할당
- 비례 할당 방식 : 가용 메모리를 각 프로세스 크기 비율에 맞추어 할당
- 다중 프로그래밍 정도에 따라 할당 되는 양이 달라진다

5.3 전역 대 지역 할당
- 전역 교체는 프로세스가 교체할 프레임을 다른 프로세스에 속한 프레임을포함한 모든 프레임을 대상으로 찾는 경우
- 지역 교체는 각 프로세스가 자기에게 할당된 프레임들 중에서만 교체될 희생자를 선택하는 경우
- 지역 교체 방법에서 할당된 프레임 수는 변하지 않지만 전역 교체는 변할 수 있다
- 전역 교체는 한 프로세스가 자신의 페이지 부재율을 완전히 조절할 수 없다

6. 스레싱
- 과도한 페이징 작업을 스레싱이라 하며 심각한 성능을 초래한다
- 운영체제는 CPU의 이용률을 감시한다
- CPU 이용률이 낮아지면 새로운 프로세스에 시스템을 추가해 다중 프로그래밍 정도를 높인다
- 다중 프로그래밍 정도가 높아짐에 따라 CPU 이용률도 높아진다
- 최대값에 도달하기 까지 증가하고 정도가 그 이상으로 커지게 되면 스레싱이 일어나고 CPU 이용률을 급격히 떨어진다
-> CPU 이용률을 높이고 스레싱을 중지시키기 위해 다중 프로그래밍 정도를 낮춰야만 한다

  ![ex_screenshot](/res/os51.png)
- 스레싱 상을 방지하기 위해서 각 프로세스가 필요로 하는 최소한의 프레임 개수를 보장해야 한다

6.2 작업 집합 모델 
- 지역성을 토대로 하고 있다
  - 지역성 모델 : 프로세스가 실행될 때 어떤 특정한 지역에서만 메모리를 집중적으로 참조함을 말함. 집중적으로 함께 참조되는 페이지들의 집합을 의미
- 작업 집합의 정확도는 델타값 선택에 따라 좌우한다
- 델타값이 작으면 전체 지역을 포함하지 못할 것이고 너무 크면 여러 지역성을 과도하게 수용할 것
- 가장 중요한 요소는 집합의 크기 이다
- 각 프로세스는 작업 집합 내 페이지를 활발히 사용한다
  - 요구량이 시스템이 보유한 메모리 크기보다 커지면 스레싱을 유발
- 운영체제는 각 프로세스의 잡업 집합을 감시하며 프로세스에게 작업 집합 크기에 맞는 충분한 프레임을 할당한다
  - 가능한 최대 다중 프로그래밍의 정도를 유지하면서 스레싱을 방지할 수 있게 해준다
  - CPU의 이용률도 최적화 된다
- 작업 집합을 추적하는 일이 가장 어려운 점이다

6.3 페이지 부재 빈도
- 페이지 결함 비율을 측정해 프레임을 할당하는 방식
- 스레싱은 페이지 부재율이 높은 것을 의미한다
- 페이지 부재율이 높으면 프로세스가 더 많은 프레임을 필요로 한다는 것
- 낮으면 많은 프레임을 가지고 있다는 것
- 페이지 부재율일 상한을 넘으면 프레임을 더 할당하고 하한보다 낮으면 프레임 수를 줄인다

  ![ex_screenshot](/res/os52.png)

8. 커널 메모리 할당

8.1 버디 시스템
- 물리적으로 연속된 페이지들로 이루어진 고정된 크기의 세그먼트로부터 메모리를할당
- 2의 거듭제곱 단위로 할당
- 서로 인접한 버디들이 손쉽게 하나의 큰 세그먼트로 합쳐 질 수 있다는 이점이 있고 할당된 세그먼트 내 단편화를 가져올 수 있다는 단점이 있다

  ![ex_screenshot](/res/os53.png)

8.2 슬랩 할당
- 슬랩이라는 하나 OR 그 이상의 연속된 페이지들로 구성
- 캐시는 하나 이상의 슬랩들로 구성된다
- 각 캐시는 커널 자료구조의 각 instantiation에 해당하는 객체들로 채워져있다
- 슬랩 할당 알고리즘은 커널 객체를 저장하기 위해 캐시를 사용하고 캐시 내 객체 수는 슬랩 크기에 좌우한다

  ![ex_screenshot](/res/os54.png)
- 단편화에 의한 낭비되는 메모리가 없다
- 메모리 요청이 빠르게 처리된다

9. 기타 고려 사항

9.1 프리 페이징
- 과도한 페이지 부재를 방지하기 위한 기법으로 관련된 모든 페이지를 사전에 한꺼번에 메모리 내로 가져오는 기법
9.2 페이지 크기
- 페이지 크기 감소는 페이지 수를 증가하고 페이지 테이블 크기를 증가시킨다
- 할당해준 메모리 사용 효율을 위해서는 작은 페이지가 좋다
- 내부 단편화를 최소화 하기 위해서는 작은 페이지가 좋다

- 디스크 입출력 시간 효율을 좋게 하려면 페이지가 크기 되는 것이 유리
- 작은 페이지를 갖는 경우 지역성이 향상되어 전체 입출력은 더 줄어들 것
- 작은 페이지 시스템에서 필요 정보만 선별해 가져오면 정밀도가 좋아딘다

- 페이지 부재 횟수를 줄이기 위해서는 큰 페이지가 좋다
  - 페이지 부재 발생하면 많은 오버헤드를 유발 

9.3 TLB Reach
- TLB로부터 액세스할 수 있는 메모리 공간의 크기
  - TLB에 있는 항목수에 페이지 크기를 곱한 것
- TLB 크기를 두배로 늘이면 TLB Reach도 두배 늘어난다
- 다른방법은 페이지 크기를 늘리든가 여러 가지 페이지 크기를 허용하는 방법이다

9.4 역 페이지 테이블
- 페이지 이블이 차지하는 메모리공간을 줄이기 위함
- <process-id, page-number>의해 인덱스 되며 물리메모리마다 한 항목을 가짐
- 각 페이지 프레임이 어떤 가상 메모리 페이지가 저장되어 있는지 정보만 유지하면 되므로 필요한 물리 메모리양을 줄인다

### 파일 시스템
- 운영체제는 컴퓨터 시스템을 편리하게 사용하기 위해 저장된 정보에 대한 일관된 논리적 관점을 제공하고 저장 장치의 물리적 특징을 추상화해 논리적 저장 단위, 파일을 정의 한다

1.1 파일 속성
- 이름 : 사람이 읽을 수 있는 형태로 유지된 유일한 정보
- 식별자
- 타입
- 위치 : 파일이 존재하는 장치와 장치 내 위치에 대한 포인터
- 크기 : 파일의 현재 크기, 최대 허용 가능 크기가 속성에 포함
- 보호 : 접근 제어 정보
- 시간, 날짜, 사용자 식별 : 생성, 최근 변경, 최근 사용을 유지하고 자료는 보호, 보안 및 사용자 감시를 위해 사용

- 모든 파일에 대한 정보는 보조 저장 장치에 상주하는 디렉터리 구조에 의해 유지된다, 디렉터리 항목은 파일 이름과 고유 식별자로 구성된다

1.2 파일 연산
- 파일 생성
- 파일 쓰기
- 파일 읽기
- 파일 안에서 위치 재설정
- 파일 삭제
- 파일 절단

2. 접근 방법
- 파일은 정보를 저장하고, 정보는 반드시 접근되어 컴퓨터 메모리로 읽혀져야 한다

2.1 순차 접근
- 가장 간단한 접근 방법
- 저장되어 있는 레코드 순서로 접근
- 읽으면 자동적으로 현재 위치를 추적하는 파일 포인터가 자동적으로 증가(쓰기도 유사하게 동작)
2.2 직접 접근
- 파일은 고정 길이의 논리 레코드 집합으로 정의되고 직접 접근 파일은 어떤 블록이라도 직접 액세스할 수 있다
- 임의 블록을 읽거나 쓸 수 있게 한다
- 대규모 정보를 다루는데 유용
- 파일 연산이 블록 번호 파라미터를 포함할 수 있도록 수정되어야 한다
- 상대 블록 번호 사용

3. 디렉터리와 디스크 구조

3.2 디렉터리 
- 디렉터리 연산
  - 파일 찾기
  - 파일 생성
  - 파일 삭제
  - 디렉터리 나열
  - 파일의 재명명
  - 파일 시스템의 순회

3.3 1단계 디렉터리

  ![ex_screenshot](/res/os55.png)
- 모든 파일이 다 같이 한 개의 디렉터리 밑에 있다
- 파일이 많아지거나 다수의 사용자가 사용하는 시스템에는 심각한 제약을 가짐
- 같은 디렉터리에 있는 모든 파일이 존재함으로 각 파일들은 유일한 이름을 가져야 한다

3.4 2단계 디렉터리

  ![ex_screenshot](/res/os56.png)
- 각 사용자는 UFD 디렉터리를 갖고, 각 디렉터리에는 오직 한사람의 파일만 저장
- 사용자 작업이 시작되거나, 시스템에 사용자가 로그인 등을 통해 접속하면 시스템은 마스터 파일 디렉터리(MFD)를 먼저 탐색
- MFD는 사용자 이름이나 계정 번호로 색인되어 있고 각 엔트리는 사용자의 UFD를 가리킨다
- 시스템은 UFD를 생성하고 삭제할 수 있어야 한다 -> 사용자 이름과 회계 정보를 가지고 특수 시스템 프로그램을 수행
  - 새로운 UFD를 생성하고 MFD에 그 항을 추가 
  - 일반 사용자에게는 금지되어야 하고 시스템 관리자만이 가능해야 할 것
- 한 사용자의 UFD를 다른 사용자가 액세스 할 수 없는 장점있다
- 두 사용자가 한 파일을 공유하는 경우 문제 발생 -> UFD접근을 허용하지 않으면 공유 불가능
- 특정한 파일을 지칭하기위해서는 사용자 이름과 파일명을 사용해 경로명을 사용

3.5 트리 구조 디렉터리

  ![ex_screenshot](/res/os57.png)
- 일반 사용자들에게 자신의 서브 디렉터리를 얼마든지 만들 수 있도록 한다
- 가장 일반적인 디렉터리 구조
- 최상위에 하나의 루트 디렉터리가 존재
- 시스템 내 모든 파일은 고유 경로명을 가진다
- 디렉터리는 하부에 다시 디렉터리나 파일을 가질 수 있다
- 디렉터리의 각 항목은 한 비트를 사용해 항목이 나타내는 파일이 일반 파일인지 디렉터리 파일인지 구분
- 각 프로세스는 현재 디렉터리를 가짐
  - 파일의 참조가 일어나면 현재 디렉터리 먼저 검색
- 경로명에는 절대 경로명과 상대 경로명이 존재
  - 절대 경로명 : 루트에서부터 지정된 파일까지의 경로가 명시된 것
  - 상대 경로명 : 현재 디렉터리를 기준으로 목적하는 파일까지의 경로를 지정한 것
  
3.6 비순환 그래프 디렉터리

  ![ex_screenshot](/res/os58.png)
- 디렉터리들이 서브디렉터리들과 파일을 공유할 수 있도록 허용하는 구조
- 똑같은 파일이나 서브디렉터리가 서로 다른 서브디렉터리에 있을 수 있다
- 트리 구조 디렉터리 방식을 일반화 한 것
- 공유를 위해 디렉터리나 파일을 복사하면 안 됨 -> 공유 파일의 작업이 다른 사람의 작업에 영향을 줄 수 있음
- 공유 파일은 여러 가지 방법으로 구현
  - 링크라는 새로운 디렉터리 항목을 만드는 것
    - 링크 : 다른 파일이나 서브디렉터리를 가리키는 포인터
    - 절대 or 상대 경로명으로 구현될 수 있다
    - 파일에 참조가 일어날 경우 디렉터리를 검색, 디렉터리가 링크로 표시되었다면 실제 파일 이름은 링크 정보에 포함
    - 실제 파일에 대한 경로 이름을 사용하면서 링크를 해석
    - 링크는 디렉터리 항목의 형식을 통해 쉽게 구분될 수 있고 간접적 포인터로 지칭
  - 디렉터리들이 모든 항목 내용을 복사해 가지고 있는 방법
    - 두 개의 항목은 동일하고 같은 것
    - 복사본과 원래 것이 구분이 안됨
    - 디렉터리 항목을 복사하는데 또 하나의 디렉터리를 변경하면 다른 동일한 복사본 항목도 함께 바뀌어야 하는 일관성 문제가 발생
- 파일은 여러 개의 절대 경로명을 가질 수 있다 ( 다른 파일이름이 같은 파일을 가리킬 수 있다 )
- 파일을 검색하고 파일에 대한 참조의 존재 여부를 결정하는 알고리즘이 비교적 간단

3.7 일반 그래프 디렉터리
  ![ex_screenshot](/res/os59.png)
- 기존 트리에 새로운 링크를 추가하면 트리구조는 파괴되고 일반적 그래프 구조가 될 수 있다

4. 파일 시스템 마운팅
- 파일이 사용되기 전 열리는 것처럼 파일 시스템은 프로세스들에 의해 사용되기전 마운트 되어야 한다
- 디렉터리 구조는 다양한 파티션으로부터 만들어 질 수 있는데, 각 파이션들이 마운트되어야 파일 시스템 네임 스페이스 안에서 이용 가능하다
- 마운트 과정
  - 운영체제에게 디바이스 이름, 파일 시스템을 부착할 수 있는 파일 구조내의 위치가 주어짐
  - 몇 운영체제는 파일 시스템의 유형이 제공되어야 하고 다른 운영체제는 장치의 구조를 검사해 파일 시스템의 유형을 결정
  - 마운트 포인트는 마운트 되는 파일 시스템에 부착될 비어 있는 디렉터리이다
  - 운영체제는 디바이스가 유효란 파일 시스템을 포함하는지 확인(디바이스 드라이버가 디바이스 디렉터리를 읽고 유효한 포맷을 가지는지 확인하도록 요청하며 이루어짐)
  - 운영체제는 파일 시스템이 지정된 마운트 포인트에 마운트되었음을 디렉터리 구조에 기록
  - 이 기법은 운영체제가 디렉터리 구조를 순회하고 파일 시스템을 적절히 전환할 수 있게하고 파일시스템의 유형도 필요에 따라 적절히 전환할 수 있게 한다

5. 파일 공유
- 파일 공유는 공동 작업을 원하거나 결과를 얻기 위해 요구되는 노력을 줄이기를 원하는 사용자에게 중요하다

5.1 다수의 사용자
- 여러 사용자 수용 시, 파일 공유, 파일 네이밍, 파일 보호가 중요해진다
- 디렉터리 구조가 사용자 파일 공유를 허용하면 시스템은 파일 공유를 중재해야 한다
- 시스템은 파일과 디렉터리에 대해 단일 사용자 시스템보다 더 많은 속성을 가져야 한다
  - 소유자는 파일 속성을 변경하거나 파일 접근 허용, 파일과 디렉터리에 대해 가장 많은 제어 권한을 가지고 있는 사용자
  - 그룹 속성은 파일에 접근을 공유할 수 있는 사용자들을 정의
- 주어진 파일 또는 디렉터리의 소유자와 그룹 ID들은 다른 파일 속성과 함께 저장
  - 사용자가 파일 연산 요구 시, 사용자 ID를 소유자 속성과 비교한 후 요청 사용자가 파일의 주인 인지를 결정

5.2 원격 파일 시스템

- 클라이언트 서버 모델
  - 원격 파일 시스템은 컴퓨터가 하나 이상의 원격 시스템으로부터 하나 이상의 파일 시스템을 마운트 하도록 허용
    - 파일을 가진 컴퓨터를 서버, 파일에 접근하기 원하는 컴퓨터를 클라이언트
  - 서버는 클라이언트에게 자원 사용가능함을 공지하고 정확하게 어느 자원과 어느 클라이언트인지 명시
  - 파일은 보통 파티션이나 서브디렉터리 레벨에서 명시된다 
  - 서버는 대개 볼륨이나 디렉터리 수준에서 사용 가능한 파일을 명시
  - 원격 파일 시스템이 마운트되면, 파일 연산 요청은 DFS(분산 파일 시스템) 프로토콜을 통해 네트워크를 거쳐 서버로 보내짐
    - 파일 열기 요청은 사용자의 ID와 함께 보내진다
  - 서버는 사용자가 요청 파일의 접근 권한을 가지고 있는지 결정하기 위해 표준 접근 검사를 적용한다
    - 요청이 허용되면 파일 핸들이 클라이언트 응용에 전달되고 응용은 읽거나, 쓰거나, 파일에 대한 다른 연산을 수행할 수 있다
  - 클라이언트는 접근이 끝날 때 파일을 닫음
  - 운영체제는 로컬 파일 시스템 마운트에 적용하는 의미와 유사한 의미를 적용하지만 떼에 따라서는 다른 의미를 사용할 수 있다

- 분산 정보 시스템
  - 원격 컴퓨팅을 위해 필요한 정보에 단일화된 접근을 제공하기 위해 고안
  - 도메인 네임 시스템(DNS)은 전체 인터넷 호스트 이름을 네트워크 주소로 변환하는 서비스를 제공
  - 다른 분산 정보 시스템은 분산 설비를 위해 사용자 이름/패스워드/사용자 ID/그룹 ID의 공간을 제공한다

5.3 일관성의 의미
- 파일 공유를 지원하는 파일 시스템을 평가하는 데 있어 중요한 요소
  - 시스템 특성 중 하나로 동시에 공유 파일에 접근하는 여러 사용자의 의미를 명시
  - 한 사용자에 의한 데이터 변경이 언제 다른 사용자에 의해 관찰될지를 지정
- 열기와 닫기 연산 사이의 일련의 접근은 하나의 파일 세션이다

6. 보호
- 신뢰성은 일반적으로 파일의 복사본에 의해 제공

6.1 접근의 유형
- 보호 기법은 가능한 파일 접근 유형을 제한함으로써 통제된 접근을 제공한다. 그중 하나가 접근 유형이다
- 몇 가지 다른 유형의 연산들이 통제될 수 있다
  - 읽기 : 파일로부터 읽기
  - 쓰기 : 파일에 쓰기
  - 실행 : 파일을 메모리에서 읽어와 실행
  - 추가 : 파일의 끝에 새로운 정보를 첨부
  - 삭제 : 파일을 지우고 사용공간을 반납
  - 리스트 : 파일 속성, 이름 등 출력

6.2 접근 제어
- 사용자 신원에 따라 특정 파일에 대한 접근 허용 여부를 결정하는 것
- 여러 사용자는 각 파일과 디렉터리에 대해 서로 다른 접근이 필요할 수 있다
- 각 파일과 디렉터리에 접근 제어 리스트를 연관해 두는 것이 신원에 기반한 접근을 구현하는 일반적인 방법
  - 이 리스트는 파일을 누가 어떤 연산을 위해 사용할 수 있는지 기술
  - 사용자가 특정 파일에 대한 접근 요청 시 운영체제는 파일의 접근리스트를 검사해 허용 여부를 결정
  - 사용자의 요청이 리스트에 포함되었다면 접근은 허용되지만 보호 위반이 발생하면 사용자 작업 파일에 대한 접근이 거부
- 복잡한 접근 방법을 가능하게 하는 장점이 있다
- 접근 리스트의 주요 문제점은 리스트의 길이

- 시스템은 사용자 리스트를 미리 알수 없다
- 디렉터리 항목이 가변 크기가 되어 버려 결과적으로 보다 복잡한 공간 관리 문제가 발생
-> 접근 리스트를 간소화 함으로써 해결될 수 있다

- 접근 리스트 길이를 간결하게 하기 위해 많은 시스템은 모든 사용자들을 세가지부류로 분류한다
  - 소유자 : 파일을 생성한 사용자
  - 그룹 : 파일을 공유해 파일에 대한 유사한 접근을 필요로 하는 사용자들의 집합
  - 모든 사람 : 시스템이 있는 모든 다른 사용자들
  - 소유자, 그룹, 모든 사람 접근 제어 기법과 결합하는 것
  - 허가 및 접근 리스트가 엄격하게 통제되어야 한다

### 파일 시스템 구현
4. 파일 시스템 마운팅
- 파일이 사용되기 전 열리는 것처럼 파일 시스템은 프로세스들에 의해 사용되기 전 장착 되어야 한다
- 마운트 과정
  - 운영체제에게 장치 이름과 파일 시스템을 부착할 수 있는 파일 구조 내의 위치가 주어진다, 마운트 포인트는 장착되는 파일 시스템이 부착될 비어있는 디렉토리
  - 운영체제는 장치가 유효한 파일 시스템을 포함하는 지 확인, 그 과정은 장치 드라이버가 장치 디렉토리를 읽고 디렉토리가 유효한 포맷을 가지는 지 확인하도록 요청함으로써 이루어진다
  - 운영체제는 파일 시스템이 지정된 마운트 포인트에 장착되었음을 디렉토리 구조에 기록, 이 기법은 운영체제가 디렉토리 구조를 순회하고 파일 시스템을 적절히 교체할 수 있게 한다
 ![ex_screenshot](/res/os60.png)
  - 시스템은 파일을 포함하고 있는 디렉토리에 대해 장착을 허가하지 않거나 장착된 파일 시스템만 디렉토리에서 사용가능하게 하고 기존 파일들은 탈착될 때까지 사용 불가능하게 만들 수 있다
  - 탈착 후에는 장착되었던 파일 시스템은 끝나고 기존 파일들이 다시 사용 가능

- 파일 시스템 구조
  - 디스크는 여러 개의 파일을 저장하는데 다음 두 가지 중요 특성을 가진다
    - 디스크는 추가 장소를 사용하지 않고 재기록이 가능, 디스크로부터 한 블록을 읽고 변경하여 같은 장소에 재기록 가능
    - 디스크에 있는 임의의 블록의 정보를 직접 접근 할 수 있다
      - 임의 파일을 순차적, 무작위 방법으로 쉽게 접근할 수 있다
      - 한 파일로부터 다른 파일로 전환이 요구 될 때 읽기-쓰기 헤드를 이동시키고 디스크가 회전하는 동안 기다리면 된다
  - 디스크는 한 번에 한바이트를 전송하는 대신 입/출력 효율을 향상시키기위해 메모리와 디스크간 입/출력 전송은 블록 단위로 실행
    - 각 블록은 하나 이상의 섹터
    - 디스크 드라이브에 따라 섹터는 32바이트 ~ 4096 바이트까지 사용하지만 일반적으로 512 바이트 사용
  - 디스크를 보다 효율적으로 편리하게 사용하기 위해서 운영체제는 디스크 내에 반드시 하나 이상의 파일 시스템을 구성
  - 파일 시스템은 크게 상이한 두 가지 설계 문제를 제기
    - 파일 시스템이 사용자에게 어떻게 보여야 할지 정의하는 것, 속성, 디렉토리 구조, 파이에 허용되는 연산 등을 포함
    - 논리 파일 시스템을 물리적인 보조 저장 장치로 매핑하는 알고리즘 자료 구조를 만드는 것
  - 파일 시스템 자체는 통상 여러 수준으로 구성, 각 수준은 저수준의 기능을 이용하며 고수준을 위한 새 기능을 구현
  ![ex_screenshot](/res/os61.png)
    - 장치 드라이버 : 최저 수준인 입/출력 제어 루틴들과 인터럽트 핸들러로 이루어져 있으며, 메모리와 디스크 시스템간의 정보 전송을 담당
    - 기본 파일 시스템 : 적절한 장치 드라이브에게 디스크 상의 물리 블록을 읽고 쓰도록 일반적 명령을 내린다
      - 각 디스크 블록은 숫자로 표시된 디스크 주소에 의해 식별
    - 파일 구성 모듈 : 파일의 논리 블록과 물리 블록들 양쪽을 알고 있어야 하며 사용되는 파일 구성 모듈은 파일 할당 유형과 파일 위치를 앎으로 파일에 대한 논리 블록 주소를 물리 블록 주소로 변환 할 수 있다
      - 파일 구성 모듈은 어느 디스크 공간이 비어있는지를 파악하는 자유 공간 관리자도 포함하고 있어 파일 구성 모듈이 요구 할 때 이들 블록을 제공한다
    - 논리 파일 시스템 : 메타데이터 정보를 관리
      - 메타데이터는 파일 내용자체인 자료를 제외한 모든 파일 시스템 구조를 말함
      - 파일 구조는 파일 제어 블록을 통해 유지
      - 파일 제어 블록은 소유, 허가, 파일 내용의 위치를 포함하여 파일에 관한 정보를 가지고 있다
   
- 파일 할당 방법
  - 디스크의 직접 접근 특성이 파일 구현에 융통성을 허용한다
  - 연속 할당 : 각 파일이 디스크 내에서 연속적 공간을 차지하도록 요구
    - 디스크 주소들은 디스크 상에 선형 순서를 정의한다
    - 한 파일의 연속할당은 디스크 주소와 길이로 정의, 파일 길이가 n블록이고 블록 b에서 시작한다면 파일은 블록 b, b+1, ... 등을 차지
    - 각 파일을 위한 디렉토리 항목은 파일의 디스크내 시작 블록 주소와 파일의 크기만 표시하면 된다
    ![ex_screenshot](/res/os62.png)
    - 연속적 할당된 파일의 접근은 쉽다 -> 가장 최근 참고된 주소를 기억했다가 필요 시 다음 블록을 읽어 들이면 된다
    - 새로운 파일을 위한 가용 공간을 찾는 일이 문제 -> 자유 공간을 관리하기 위해 선택된 시스템이 작업을 담당
    - 연속 할당 문제는 동적 공간 할당 문제의 특정 응용으로 볼 수 있다
      - 자유 공간 리스트에서 크기 n의 공간을 할당하는 방법
      - 최초 적합과 최적 적합이 가용 공간 중 할당 공간을 선택하는 가장 일반적인 전략
      - 모두 외부 단편화 문제가 발생
    - 파일을 위해 얼마나 많은 공간을 주어야 할지 결정하는 것
      - 파일이 생성 시 필요한 공간읠 크기를 알아야만 할당 가능
      - 기존 파일을 복사하는 경우를 제외하고 파일의 크기를 예측하는 것은 어려움
      - 공간을 미리 안다고 하더라도 선할당은 비효율적 -> 내부 단편화로 낭비될 수 있다
  - 연결 할당
    - 각 파일은 디스크 블록의 연결 리스트
    - 파일의 디스크 블록들이 디스크 내에 흩어져 있다
    - 디렉토리는 파일의 첫 번째와 마지막 블록에 대한 포인터를 가지고 있다
    - 새 파일을 생성하려면 단순히 디렉토리 내 새로운 항목을 만든다
    - 연속 할당의 경우 각 디렉토리 항목은 파일의 첫 디스크 블록에 대한 포인터를 가짐
      - 포인터는 처음에 빈 파일을 표시하기 위해 nil 값으로 초기화
      - 파일 쓰기가 일어나면 자유 공간 관리 시스템은 자유 블록을 할당받아 쓰기 실행 후 파일 끝에 연결한다
    ![ex_screenshot](/res/os63.png)
    - 연결 할당의 경우 외부 단편화 없고 모든 블록들은 크기가 같기에 자유 공간 리스트의 어떤 자유 블록을 이용해도 무방
    - 파일 크기고 미리 고정될 필요 없다, 커질 수 있으며 주기적으로 밀집화 할 필요 없다
    - 순차적 접근 파일에만 효과적이다
      - 포인터를 접근할 때마다 디스크 읽기와 몇 번의 탐색이 필요하므로 직접 접근에는 비효율적
    - 포인터를 관리하기 위한 추가 공간이 필요
      - 블록들을 클러스터로 구성해 클러스터 단위로 할당하는 것을로 문제를 해결
    - 신뢰성 -> 포인터를 이용해 관리하다 보니 포인터를 잃어버리거나 잘못된 포인터 주소를 가지면 결국 모든 자료를 잃게됨
      - 이중 연결 리스트를 사용하거나 각 블록마다 파일이름과 상대 블록 등을 저장하는 방법을 쓸 수 있으나 많은 오버헤드 유발
    - 파일 할당 테이블을 사용하는 것
      - FAT 테이블은 각 디스크 블록마다 한 개의 항목을 가지고있고 이 항목은 디스크 블록 번호를 색인으로 찾는다
    - FAT 할당 기법은 FAT가 캐시되지 않으면 상당한 수의 디스크 찾기를 유발 할 수 있다
      - FAT를 읽기 위해 디스크 헤드를 반드시 파티션의 시작 부분으로 움직여 찾고자 하는 블록의 주소를 알아내야 하고 그 블록이 있는 곳으로 다시 이동해야 한다
      - 최악의 경우 각 블록을 찾을 때마다 두 번의 이동이 일어나야 한다
      - 디스크 헤드가 FAT의 정보를 읽어 임의의 블록의 위치를 알아 낼 수있기 때문에 임의 접근 시간이 개선된다
     ![ex_screenshot](/res/os64.png)
  
  - 색인 할당
    - 모든 포인터들을 하나의 장소 즉, 색인 블록으로 관리함으로써 문제를 해결한다
    - 각 파일들은 디스크 블록 주소를 모아 놓은 배열인 색인 블록을 가진다
    - 색인 블록의 i번째 항목은 파일의 i번째 블록을 가리킨다
    - 디렉토리는 색인 블록의 주소를 가지고 있다
    - i번째 블록을 읽기 위해서는 색인 블록 항목에 있는 i번째 항목에서 포인터를 얻어 블록을 읽는다 (페이징과 유사)
    ![ex_screenshot](/res/os65.png)
    - 추가 공간 요구가 있을 경우 디스크 상의 임의의 자유 공간을 사용할 수 있기 때문에 외부 단편화 없이 직접 접근을 제공
    - 공간 낭비 문제가 있다 -> 색인 블록의 포인터 오베헤드가 크다
    - 각 파일들은 하나의 색인 블록을 가지므로 색인 블록 크기는 가능한 작은 것이 좋다(너무 작으면 큰 파일에 대해 충분한 공간을 가질 수 없음)
    - 문제점 보완 기법
      - 연결 기법 : 하나의 색인 블록은 통상 한 디스크 블록, 파일의 크기가 크면 여러 개 색일 블록들을 연결 시킨다
      - 다단계 색인 : 첫 수준의 색인 블록은 여러 개의 두 번째 수준 색인 블록들에 대한 포인터를 가진다
      - 결합 기법 : 디렉토리 내 색인 블록이 15개의 포인터를 가진다, 포인터들의 처음 12개는 직접 블록을 가리킨다
        - 다음 3개의 포인터는 간접 블록 주소로서 첫 번째 포인터는 단일 간접 블록을 통해 간접적으로 파일의 블록을 찾을 수 있다
        - 두번 째 포인터는 이중 간접 블록, 마지막 포인터는 삼중 간접 블록을 통해 간접적으로 파일 블록을 찾는 형식

### 디스크 스케줄링
